{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c996397-1bfb-4efd-b4c9-d558c96ee355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotation files: 65166\n",
      "Number of label files: 64639\n",
      "Number of image files: 64639\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "model_folder = 'clothing-detection-ecommerce-dataset-master'  # Root folder containing dataset and Annotations\n",
    "annotation_dir = os.path.join(model_folder, 'annotations')  # Directory where annotation JSON files are located\n",
    "dataset_dir = os.path.join(model_folder, 'dataset')  # Directory containing images\n",
    "labels_dir = 'ecommerce_dataset/labels'  # Directory where YOLO label files are located\n",
    "images_dir = 'ecommerce_dataset/images'  # Directory to copy relevant images\n",
    "log_file_path = 'missing_categories_log.txt'  # Path to save the log file\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(labels_dir, exist_ok=True)\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "\n",
    "# Count the number of files in the annotation directory and labels directory\n",
    "annotation_files_count = sum([len(files) for r, d, files in os.walk(annotation_dir)])\n",
    "label_files_count = sum([len(files) for r, d, files in os.walk(labels_dir)])\n",
    "image_files_count = sum([len(files) for r, d, files in os.walk(images_dir)])\n",
    "\n",
    "print(f\"Number of annotation files: {annotation_files_count}\")\n",
    "print(f\"Number of label files: {label_files_count}\")\n",
    "print(f\"Number of image files: {image_files_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e53679b-b62c-4af8-bdbf-4152aaf549e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    'topwear': [\n",
    "        'camisetas', 'bodies', 'jerseys', 'camisas', 'camiseta-interior', \n",
    "        'polos', 'sudaderas', 'vestidos', 'cardigans', \n",
    "        'camisas-y-blusas', 'lenceria', 'banadores', 'bufandas', 'trajes', 'reloj',\n",
    "        'sombreros', 'gorras', 'gorros', 'guantes', 'gafas', 'paraguas', 'cinturones', \n",
    "        'corbatas', 'bisuteria', 'medias', 'calcetines', 'panuelos', 'bolsos-y-mochilas',\n",
    "        'carteras', 'abrigos', 'botines', 'shirts', 'jackets', 'dresses','vestes', 'coats'\n",
    "    ],\n",
    "    'bottomwear': [\n",
    "        'monos', 'jeans', 'pantalones', 'braguitas', 'shorts', 'faldas', 'calzoncillos',\n",
    "        'trousers', 'skirts', 'jumpsuits', 'swimwear'\n",
    "    ],\n",
    "    'footwear': [\n",
    "        'botas', 'zapatos', 'tacones', 'chanclas', 'sandalias', 'zapatillas', 'alpargatas', 'shoes',\n",
    "        'boots', 'sportshoes'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Map original categories to class IDs\n",
    "class_id_mapping = {\n",
    "    'topwear': 0,\n",
    "    'bottomwear': 1,\n",
    "    'footwear': 2,\n",
    "}\n",
    "\n",
    "# underwear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b0763e0-4db3-4d72-aaf5-bd28925056e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Log missing categories\n",
    "missing_categories_log = []\n",
    "\n",
    "# Process each annotation file\n",
    "for annotation_file in os.listdir(annotation_dir):\n",
    "    if annotation_file.endswith('.json'):\n",
    "        with open(os.path.join(annotation_dir, annotation_file)) as f:\n",
    "            data = json.load(f)\n",
    "            img_path = data['file_name']  \n",
    "            img_full_path = os.path.join(model_folder, img_path)  \n",
    "            \n",
    "            if not os.path.exists(img_full_path):\n",
    "                print(f\"Image file {img_full_path} not found, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Open image to get dimensions\n",
    "            img = Image.open(img_full_path)\n",
    "            img_width, img_height = img.size\n",
    "            img.close()\n",
    "\n",
    "            yolo_annotations = []\n",
    "            for box in data['arr_boxes']:\n",
    "                category = box['class']\n",
    "                class_id = None\n",
    "                \n",
    "                for main_category, subcategories in category_mapping.items():\n",
    "                    if category in subcategories:\n",
    "                        class_id = str(class_id_mapping[main_category])  # Ensure class_id is a string\n",
    "                        break\n",
    "\n",
    "                if class_id is None:\n",
    "                    missing_categories_log.append(category)\n",
    "                    continue\n",
    "\n",
    "                # Get bounding box coordinates\n",
    "                x_center = (box['x'] + box['width'] / 2) / img_width  # Normalize x_center\n",
    "                y_center = (box['y'] + box['height'] / 2) / img_height  # Normalize y_center\n",
    "                width = box['width'] / img_width  # Normalize width\n",
    "                height = box['height'] / img_height  # Normalize height\n",
    "\n",
    "                # Ensure class_id is converted to string for YOLO format\n",
    "                yolo_annotations.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
    "\n",
    "            if yolo_annotations:\n",
    "                base_name = os.path.splitext(annotation_file)[0]\n",
    "                output_file_path = os.path.join(labels_dir, base_name + '.txt')\n",
    "                with open(output_file_path, 'w') as out_f:\n",
    "                    out_f.write('\\n'.join(yolo_annotations))\n",
    "                \n",
    "                # Copy image to new directory\n",
    "                new_img_path = os.path.join(images_dir, base_name + '.png')\n",
    "                shutil.copy(img_full_path, new_img_path)\n",
    "\n",
    "# Save missing categories to log file\n",
    "if missing_categories_log:\n",
    "    with open(log_file_path, 'w') as log_f:\n",
    "        log_f.write('\\n'.join(set(missing_categories_log)))\n",
    "\n",
    "print(\"Conversion completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c5d065c-a5f1-44c9-9a67-cab54c0f81ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define directories\n",
    "images_dir = 'ecommerce_dataset/images'\n",
    "labels_dir = 'ecommerce_dataset/labels'\n",
    "\n",
    "train_images_dir = 'ecommerce_dataset/train/images'\n",
    "val_images_dir = 'ecommerce_dataset/val/images'\n",
    "test_images_dir = 'ecommerce_dataset/test/images'\n",
    "\n",
    "train_labels_dir = 'ecommerce_dataset/train/labels'\n",
    "val_labels_dir = 'ecommerce_dataset/val/labels'\n",
    "test_labels_dir = 'ecommerce_dataset/test/labels'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(train_images_dir, exist_ok=True)\n",
    "os.makedirs(val_images_dir, exist_ok=True)\n",
    "os.makedirs(test_images_dir, exist_ok=True)\n",
    "\n",
    "os.makedirs(train_labels_dir, exist_ok=True)\n",
    "os.makedirs(val_labels_dir, exist_ok=True)\n",
    "os.makedirs(test_labels_dir, exist_ok=True)\n",
    "\n",
    "# Get list of all image files\n",
    "image_files = [f for f in os.listdir(images_dir) if f.endswith('.png')]\n",
    "\n",
    "# Shuffle the image files\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Calculate split indices\n",
    "train_split = int(train_ratio * len(image_files))\n",
    "val_split = int((train_ratio + val_ratio) * len(image_files))\n",
    "\n",
    "# Split the data\n",
    "train_files = image_files[:train_split]\n",
    "val_files = image_files[train_split:val_split]\n",
    "test_files = image_files[val_split:]\n",
    "\n",
    "# Function to move files\n",
    "def move_files(files, src_image_dir, dest_image_dir, src_label_dir, dest_label_dir):\n",
    "    for file in files:\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "        label_file = base_name + '.txt'\n",
    "        \n",
    "        # Move image file\n",
    "        shutil.move(os.path.join(src_image_dir, file), os.path.join(dest_image_dir, file))\n",
    "        \n",
    "        # Move corresponding label file\n",
    "        shutil.move(os.path.join(src_label_dir, label_file), os.path.join(dest_label_dir, label_file))\n",
    "\n",
    "# Move the files to the respective directories\n",
    "move_files(train_files, images_dir, train_images_dir, labels_dir, train_labels_dir)\n",
    "move_files(val_files, images_dir, val_images_dir, labels_dir, val_labels_dir)\n",
    "move_files(test_files, images_dir, test_images_dir, labels_dir, test_labels_dir)\n",
    "\n",
    "print(\"Dataset split completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b94c3ff1-31ab-4a16-aa82-2435278425b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 45247\n",
      "Number of train lables: 45247\n",
      "Number of val images: 12928\n",
      "Number of val lables: 12928\n",
      "Number of test images: 6464\n",
      "Number of test lables: 6464\n"
     ]
    }
   ],
   "source": [
    "train_images_dir = 'ecommerce_dataset/train/images'\n",
    "val_images_dir = 'ecommerce_dataset/val/images'\n",
    "test_images_dir = 'ecommerce_dataset/test/images'\n",
    "\n",
    "train_labels_dir = 'ecommerce_dataset/train/labels'\n",
    "val_labels_dir = 'ecommerce_dataset/val/labels'\n",
    "test_labels_dir = 'ecommerce_dataset/test/labels'\n",
    "\n",
    "# Count the number of files in the annotation directory and labels directory\n",
    "train_image_files_count = sum([len(files) for r, d, files in os.walk(train_images_dir)])\n",
    "val_image_files_count = sum([len(files) for r, d, files in os.walk(val_images_dir)])\n",
    "test_image_files_count = sum([len(files) for r, d, files in os.walk(test_images_dir)])\n",
    "\n",
    "train_labels_files_count = sum([len(files) for r, d, files in os.walk(train_labels_dir)])\n",
    "val_labels_files_count = sum([len(files) for r, d, files in os.walk(val_labels_dir)])\n",
    "test_labels_files_count = sum([len(files) for r, d, files in os.walk(test_labels_dir)])\n",
    "\n",
    "\n",
    "print(f\"Number of train images: {train_image_files_count}\")\n",
    "print(f\"Number of train lables: {train_labels_files_count}\")\n",
    "\n",
    "print(f\"Number of val images: {val_image_files_count}\")\n",
    "print(f\"Number of val lables: {val_labels_files_count}\")\n",
    "\n",
    "print(f\"Number of test images: {test_image_files_count}\")\n",
    "print(f\"Number of test lables: {test_labels_files_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48970f8c-311a-422e-b6de-7e45f9b5a811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
