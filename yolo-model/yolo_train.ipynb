{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c54a6d0-ae45-4f2c-bcd9-fdd2230ced35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset YAML file created at: data.yaml\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset configuration file\n",
    "data = \"\"\"\n",
    "train: ../ecommerce_dataset/train/images\n",
    "val: ../ecommerce_dataset/val/images\n",
    "\n",
    "nc: 3  # number of classes\n",
    "names: ['Topwear', 'Bottomwear', 'Footwear']  # class names\n",
    "\"\"\"\n",
    "\n",
    "yaml_file_path = 'data.yaml'\n",
    "with open(yaml_file_path, 'w') as f:\n",
    "    f.write(data)\n",
    "\n",
    "print(f\"Dataset YAML file created at: {yaml_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6d3e93c-74f4-45bb-8363-c04c79528cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.45 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.41 🚀 Python-3.11.7 torch-2.3.1 CPU (Apple M1)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_da\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/val/labels.cache\n",
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G     0.8794      1.037      1.219         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      12928      23825      0.844      0.816      0.891      0.655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G     0.8399     0.6066      1.183         26        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      12928      23825      0.909      0.914      0.956      0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G     0.8081     0.5503       1.16         33        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      12928      23825      0.916      0.931      0.969       0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      0.777      0.501      1.135         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      12928      23825      0.935      0.937      0.976      0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G     0.7468     0.4609      1.113         28        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      12928      23825      0.941      0.941      0.978      0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G     0.7264     0.4325      1.096         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      12928      23825      0.943       0.95       0.98       0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G     0.7071     0.4069      1.083         28        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      12928      23825      0.952       0.95      0.983      0.817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G     0.6933     0.3891      1.072         27        640:  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8n.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# load a pretrained model (recommended for training)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Use the model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)  \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mval()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ultralytics/engine/model.py:650\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 650\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    651\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py:204\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_train(world_size)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py:381\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp):\n\u001b[1;32m    380\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[0;32m--> 381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(batch)\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m world_size\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:101\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03mForward pass of the model on a single scale. Wrapper for `_forward_once` method.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): The output of the network.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:282\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_criterion()\n\u001b[0;32m--> 282\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(preds, batch)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:102\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:120\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_once(x, profile, visualize, embed)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:141\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 141\u001b[0m x \u001b[38;5;241m=\u001b[39m m(x)  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    142\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ultralytics/nn/modules/block.py:240\u001b[0m, in \u001b[0;36mC2f.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    238\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    239\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ultralytics/nn/modules/conv.py:50\u001b[0m, in \u001b[0;36mConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    184\u001b[0m     bn_training,\n\u001b[1;32m    185\u001b[0m     exponential_average_factor,\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m    187\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:2509\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2507\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2510\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m   2511\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# First Training\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load inital model\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Use the model\n",
    "model.train(data=\"data.yaml\", epochs=10, batch=16)  # train the model\n",
    "metrics = model.val()  # evaluate model performance on the validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1df412e3-ba37-4406-99d0-016ca494c4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.48 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.41 🚀 Python-3.11.7 torch-2.3.1 CPU (Apple M1)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo_best.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_da\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/val/labels.cache\n",
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         0G     0.8278     0.5615      1.142         54        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      12928      23765      0.957      0.959      0.987      0.816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5         0G     0.8051     0.4955      1.124         55        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      12928      23765      0.961       0.96      0.988      0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5         0G     0.7961      0.487      1.118         56        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      12928      23765      0.956      0.964      0.988      0.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5         0G     0.7752     0.4595      1.104         54        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      12928      23765      0.961      0.965      0.989      0.831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5         0G      0.761     0.4395        1.1         63        640:  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo_best.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# load my trained model \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Use the model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)  \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mval()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ultralytics/engine/model.py:650\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 650\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    651\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py:204\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_train(world_size)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py:389\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    385\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items\n\u001b[1;32m    386\u001b[0m     )\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    391\u001b[0m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    527\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[1;32m    268\u001b[0m     tensors,\n\u001b[1;32m    269\u001b[0m     grad_tensors_,\n\u001b[1;32m    270\u001b[0m     retain_graph,\n\u001b[1;32m    271\u001b[0m     create_graph,\n\u001b[1;32m    272\u001b[0m     inputs,\n\u001b[1;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Second training - take the best weight\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo_best.pt\")  # load my trained model \n",
    "\n",
    "# Use the model\n",
    "model.train(data=\"data.yaml\", epochs=5, batch=16)  # train the model\n",
    "metrics = model.val()  # evaluate model performance on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25086076-588c-49b1-ad44-dfd1dff85f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/box_loss</th>\n",
       "      <th>train/cls_loss</th>\n",
       "      <th>train/dfl_loss</th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>val/box_loss</th>\n",
       "      <th>val/cls_loss</th>\n",
       "      <th>val/dfl_loss</th>\n",
       "      <th>lr/pg0</th>\n",
       "      <th>lr/pg1</th>\n",
       "      <th>lr/pg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.87940</td>\n",
       "      <td>1.03680</td>\n",
       "      <td>1.2190</td>\n",
       "      <td>0.84398</td>\n",
       "      <td>0.81623</td>\n",
       "      <td>0.89132</td>\n",
       "      <td>0.65537</td>\n",
       "      <td>0.84532</td>\n",
       "      <td>0.72621</td>\n",
       "      <td>1.1900</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.83994</td>\n",
       "      <td>0.60657</td>\n",
       "      <td>1.1833</td>\n",
       "      <td>0.90932</td>\n",
       "      <td>0.91383</td>\n",
       "      <td>0.95644</td>\n",
       "      <td>0.74946</td>\n",
       "      <td>0.73781</td>\n",
       "      <td>0.46530</td>\n",
       "      <td>1.1055</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.000858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.80807</td>\n",
       "      <td>0.55028</td>\n",
       "      <td>1.1597</td>\n",
       "      <td>0.91554</td>\n",
       "      <td>0.93082</td>\n",
       "      <td>0.96862</td>\n",
       "      <td>0.76991</td>\n",
       "      <td>0.70308</td>\n",
       "      <td>0.42138</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.77698</td>\n",
       "      <td>0.50105</td>\n",
       "      <td>1.1353</td>\n",
       "      <td>0.93492</td>\n",
       "      <td>0.93677</td>\n",
       "      <td>0.97560</td>\n",
       "      <td>0.78916</td>\n",
       "      <td>0.68129</td>\n",
       "      <td>0.37828</td>\n",
       "      <td>1.0595</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.001005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.74682</td>\n",
       "      <td>0.46090</td>\n",
       "      <td>1.1129</td>\n",
       "      <td>0.94084</td>\n",
       "      <td>0.94136</td>\n",
       "      <td>0.97771</td>\n",
       "      <td>0.79894</td>\n",
       "      <td>0.66150</td>\n",
       "      <td>0.35726</td>\n",
       "      <td>1.0435</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  epoch        train/box_loss        train/cls_loss  \\\n",
       "0                     1               0.87940               1.03680   \n",
       "1                     2               0.83994               0.60657   \n",
       "2                     3               0.80807               0.55028   \n",
       "3                     4               0.77698               0.50105   \n",
       "4                     5               0.74682               0.46090   \n",
       "\n",
       "         train/dfl_loss  metrics/precision(B)     metrics/recall(B)  \\\n",
       "0                1.2190               0.84398               0.81623   \n",
       "1                1.1833               0.90932               0.91383   \n",
       "2                1.1597               0.91554               0.93082   \n",
       "3                1.1353               0.93492               0.93677   \n",
       "4                1.1129               0.94084               0.94136   \n",
       "\n",
       "       metrics/mAP50(B)   metrics/mAP50-95(B)          val/box_loss  \\\n",
       "0               0.89132               0.65537               0.84532   \n",
       "1               0.95644               0.74946               0.73781   \n",
       "2               0.96862               0.76991               0.70308   \n",
       "3               0.97560               0.78916               0.68129   \n",
       "4               0.97771               0.79894               0.66150   \n",
       "\n",
       "           val/cls_loss          val/dfl_loss                lr/pg0  \\\n",
       "0               0.72621                1.1900              0.000476   \n",
       "1               0.46530                1.1055              0.000858   \n",
       "2               0.42138                1.0750              0.001146   \n",
       "3               0.37828                1.0595              0.001005   \n",
       "4               0.35726                1.0435              0.000863   \n",
       "\n",
       "                 lr/pg1                lr/pg2  \n",
       "0              0.000476              0.000476  \n",
       "1              0.000858              0.000858  \n",
       "2              0.001146              0.001146  \n",
       "3              0.001005              0.001005  \n",
       "4              0.000863              0.000863  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'results.csv'\n",
    "results_df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe to understand its structure\n",
    "results_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e78f9b8c-ec25-4cf6-b8fa-6abba8528601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Strip the extra spaces from column names\n",
    "results_df.columns = results_df.columns.str.strip()\n",
    "\n",
    "# Plot training and validation losses\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "\n",
    "\n",
    "# Training and Validation Losses:\n",
    "\n",
    "# 1. Train Box Loss: This is the loss related to the bounding box predictions during training. It measures how well the predicted bounding boxes match the ground truth boxes.\n",
    "# 2. Train Class Loss: This is the loss related to the classification of objects within the bounding boxes during training. It measures how well the model predicts the correct class for each object.\n",
    "\n",
    "# 4. Val Box Loss: Similar to the train box loss, but calculated on the validation dataset to assess how well the model generalizes to unseen data.\n",
    "# 5. Val Class Loss: Similar to the train class loss, but calculated on the validation dataset.\n",
    "\n",
    "\n",
    "# Training losses\n",
    "plt.plot(results_df['epoch'], results_df['train/box_loss'], label='Train Box Loss')\n",
    "plt.plot(results_df['epoch'], results_df['train/cls_loss'], label='Train Class Loss')\n",
    "\n",
    "# Validation losses\n",
    "plt.plot(results_df['epoch'], results_df['val/box_loss'], label='Val Box Loss', linestyle='--')\n",
    "plt.plot(results_df['epoch'], results_df['val/cls_loss'], label='Val Class Loss', linestyle='--')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8738951e-9a7d-42f0-8e49-c889921e3147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Metrics: \n",
    "# Precision (B): Precision is the ratio of true positive detections to the total number of positive detections (true positives + false positives). A high precision indicates that the model has a low false positive rate.\n",
    "# Recall (B): Recall is the ratio of true positive detections to the total number of actual objects (true positives + false negatives). A high recall indicates that the model has a low false negative rate.\n",
    "\n",
    "# Plot precision, recall, and mAP metrics\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.plot(results_df['epoch'], results_df['metrics/precision(B)'], label='Precision (B)')\n",
    "plt.plot(results_df['epoch'], results_df['metrics/recall(B)'], label='Recall (B)')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Precision, Recall Metrics')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080ab645-7d4d-4ddb-8548-dbb243a53af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation of Plots\n",
    "\n",
    "# 1. Training and Validation Losses:  \n",
    "# Ideally, both training and validation losses should decrease over time. A significant gap between training and validation losses might indicate overfitting.\n",
    "\n",
    "\n",
    "# 2. Precision, Recall, and mAP Metrics: \n",
    "# These metrics help in understanding the quality of the model's predictions.\n",
    "# High precision and recall values indicate good detection performance, while high mAP values indicate good localization accuracy. \n",
    "# Tracking these metrics over epochs helps in evaluating how the model's detection capabilities improve during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "170b74f5-889b-4211-a9ed-f840f71f9f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_1613.png: 640x512 1 Bottomwear, 80.8ms\n",
      "Speed: 1.9ms preprocess, 80.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_1613.png\n",
      "Annotations: [(1, 0.5113104432821274, 0.35918740183115005, 0.48621729016304016, 0.3587755411863327)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botines_102.png: 640x448 1 Footwear, 64.4ms\n",
      "Speed: 1.6ms preprocess, 64.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_botines_102.png\n",
      "Annotations: [(2, 0.511227197945118, 0.6435196995735168, 0.8508267253637314, 0.4249598979949951)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_1812.png: 640x480 1 Topwear, 69.5ms\n",
      "Speed: 2.4ms preprocess, 69.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_pantalones_1812.png\n",
      "Annotations: [(0, 0.4995266944169998, 0.4838864076882601, 0.8574856221675873, 0.8508810065686703)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3989.png: 640x512 1 Topwear, 75.3ms\n",
      "Speed: 1.7ms preprocess, 75.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_3989.png\n",
      "Annotations: [(0, 0.40474648773670197, 0.5554878860712051, 0.5722815692424774, 0.7467946708202362)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4223.png: 640x448 1 Topwear, 67.5ms\n",
      "Speed: 1.5ms preprocess, 67.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisetas_4223.png\n",
      "Annotations: [(0, 0.5367260724306107, 0.6324359327554703, 0.8373251855373383, 0.7351281344890594)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4183.png: 640x512 1 Topwear, 75.6ms\n",
      "Speed: 1.8ms preprocess, 75.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_4183.png\n",
      "Annotations: [(0, 0.4866265468299389, 0.48854510486125946, 0.8452140465378761, 0.6701706945896149)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5880.png: 640x544 1 Topwear, 77.6ms\n",
      "Speed: 1.7ms preprocess, 77.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisetas_5880.png\n",
      "Annotations: [(0, 0.4959811270236969, 0.4968457370996475, 0.6938236355781555, 0.5874311625957489)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4415.png: 640x448 1 Bottomwear, 63.2ms\n",
      "Speed: 1.2ms preprocess, 63.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_pantalones_4415.png\n",
      "Annotations: [(1, 0.5029642730951309, 0.5033506620675325, 0.502002090215683, 0.9124087356030941)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_1699.png: 640x480 1 Topwear, 70.7ms\n",
      "Speed: 2.2ms preprocess, 70.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_1699.png\n",
      "Annotations: [(0, 0.4979272708296776, 0.4925414454191923, 0.8731435090303421, 0.8648702837526798)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_1265.png: 640x512 1 Topwear, 1 Bottomwear, 72.8ms\n",
      "Speed: 1.7ms preprocess, 72.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_1265.png\n",
      "Annotations: [(1, 0.7763646841049194, 0.7527862787246704, 0.3433969020843506, 0.300126314163208), (0, 0.7537163197994232, 0.576705813407898, 0.49256736040115356, 0.5950770378112793)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_324.png: 640x480 1 Bottomwear, 67.0ms\n",
      "Speed: 2.8ms preprocess, 67.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_faldas_324.png\n",
      "Annotations: [(1, 0.4796464815735817, 0.4696086347103119, 0.5548897236585617, 0.6840510964393616)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4731.png: 640x448 1 Topwear, 1 Bottomwear, 2 Footwears, 65.3ms\n",
      "Speed: 2.0ms preprocess, 65.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jeans_4731.png\n",
      "Annotations: [(2, 0.38933536410331726, 0.8299928307533264, 0.11908036470413208, 0.1584850549697876), (2, 0.4644920527935028, 0.9309634268283844, 0.17918545007705688, 0.11396342515945435), (0, 0.5031049773097038, 0.13593557476997375, 0.6930492073297501, 0.24510526657104492), (1, 0.4848249554634094, 0.47750185430049896, 0.45401227474212646, 0.70457723736763)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_331.png: 640x512 1 Bottomwear, 2 Footwears, 78.8ms\n",
      "Speed: 2.5ms preprocess, 78.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_331.png\n",
      "Annotations: [(2, 0.2379322648048401, 0.6518536806106567, 0.4758645296096802, 0.16111493110656738), (2, 0.5112134218215942, 0.7526211440563202, 0.6147369146347046, 0.22135335206985474), (1, 0.4984827861189842, 0.33417537808418274, 0.6439324170351028, 0.6683507561683655)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_1415.png: 640x512 1 Topwear, 1 Bottomwear, 1 Footwear, 73.1ms\n",
      "Speed: 1.8ms preprocess, 73.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_1415.png\n",
      "Annotations: [(2, 0.634338766336441, 0.85243159532547, 0.09564787149429321, 0.12327909469604492), (0, 0.6146686673164368, 0.24368850886821747, 0.21514666080474854, 0.17013683915138245), (1, 0.6648123413324356, 0.5004043579101562, 0.5309463441371918, 0.3761941194534302)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_2386.png: 640x512 1 Bottomwear, 72.6ms\n",
      "Speed: 1.7ms preprocess, 72.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_2386.png\n",
      "Annotations: [(1, 0.5039926469326019, 0.5083763003349304, 0.47471195459365845, 0.9475462436676025)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4622.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 74.8ms\n",
      "Speed: 1.8ms preprocess, 74.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_4622.png\n",
      "Annotations: [(2, 0.5342802703380585, 0.8540505170822144, 0.10580843687057495, 0.16178464889526367), (2, 0.21544627100229263, 0.824707418680191, 0.10684280097484589, 0.18331772089004517), (0, 0.48826436698436737, 0.19110077619552612, 0.4543609917163849, 0.38220155239105225), (1, 0.43262671679258347, 0.5094304531812668, 0.5059086233377457, 0.5586325228214264)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_3272.png: 640x512 1 Topwear, 1 Bottomwear, 73.1ms\n",
      "Speed: 1.8ms preprocess, 73.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_3272.png\n",
      "Annotations: [(1, 0.468081958591938, 0.9289518892765045, 0.5120365470647812, 0.14209622144699097), (0, 0.5188116878271103, 0.5719325989484787, 0.6188700497150421, 0.658980518579483)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5068.png: 640x640 1 Topwear, 92.0ms\n",
      "Speed: 2.5ms preprocess, 92.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_sudaderas_5068.png\n",
      "Annotations: [(0, 0.5018267333507538, 0.5131650418043137, 0.6866443753242493, 0.8808166086673737)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_572.png: 640x512 1 Bottomwear, 2 Footwears, 73.5ms\n",
      "Speed: 1.8ms preprocess, 73.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_572.png\n",
      "Annotations: [(2, 0.48707354068756104, 0.94674351811409, 0.08570146560668945, 0.10651296377182007), (2, 0.21635238826274872, 0.9438555836677551, 0.10427138209342957, 0.10571181774139404), (1, 0.3441540598869324, 0.5588829815387726, 0.3855266571044922, 0.632935106754303)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1074.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 73.0ms\n",
      "Speed: 1.8ms preprocess, 73.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_1074.png\n",
      "Annotations: [(2, 0.7580976188182831, 0.9026986062526703, 0.08097821474075317, 0.13954168558120728), (2, 0.6990348696708679, 0.8948348164558411, 0.08058774471282959, 0.14271044731140137), (0, 0.7160811424255371, 0.21881896257400513, 0.29913628101348877, 0.1950477957725525), (1, 0.6560840308666229, 0.4980810135602951, 0.6878319382667542, 0.4112354815006256), (0, 0.6853655576705933, 0.4145621955394745, 0.5955384969711304, 0.5677445530891418)]\n",
      "Detections: ['original_image', 'topwear', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_38.png: 640x640 1 Bottomwear, 88.8ms\n",
      "Speed: 2.8ms preprocess, 88.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_shorts_38.png\n",
      "Annotations: [(1, 0.5035635679960251, 0.507219897583127, 0.772382527589798, 0.8947642110288143)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2750.png: 640x512 1 Topwear, 1 Bottomwear, 1 Footwear, 74.2ms\n",
      "Speed: 1.8ms preprocess, 74.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_2750.png\n",
      "Annotations: [(2, 0.4363204091787338, 0.9602687060832977, 0.1277177631855011, 0.0735432505607605), (1, 0.7198402583599091, 0.5718354880809784, 0.3353058695793152, 0.28022080659866333), (0, 0.7150499671697617, 0.363901786506176, 0.46939364075660706, 0.41534389555454254)]\n",
      "Detections: ['original_image', 'topwear', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1248.png: 640x512 1 Bottomwear, 84.9ms\n",
      "Speed: 2.2ms preprocess, 84.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_1248.png\n",
      "Annotations: [(1, 0.5130223855376244, 0.5094581972807646, 0.5861500054597855, 0.9218206144869328)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_4117.png: 640x480 1 Bottomwear, 69.8ms\n",
      "Speed: 1.8ms preprocess, 69.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_4117.png\n",
      "Annotations: [(1, 0.5012938529253006, 0.4988630563020706, 0.4929454028606415, 0.9771240651607513)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_800.png: 640x512 1 Topwear, 1 Bottomwear, 73.5ms\n",
      "Speed: 1.6ms preprocess, 73.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_800.png\n",
      "Annotations: [(1, 0.3375121057033539, 0.9055868685245514, 0.36906808614730835, 0.18882626295089722), (0, 0.43797165900468826, 0.5733192563056946, 0.5918389409780502, 0.7045589685440063)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2097.png: 640x512 1 Topwear, 1 Bottomwear, 72.4ms\n",
      "Speed: 2.0ms preprocess, 72.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_2097.png\n",
      "Annotations: [(1, 0.7031716555356979, 0.797371506690979, 0.47851577401161194, 0.38682496547698975), (0, 0.7245460897684097, 0.47902539372444153, 0.5509078204631805, 0.5163072943687439)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_2907.png: 640x512 1 Topwear, 1 Bottomwear, 77.6ms\n",
      "Speed: 1.8ms preprocess, 77.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_2907.png\n",
      "Annotations: [(1, 0.6133400797843933, 0.8632254302501678, 0.5726261138916016, 0.2735491394996643), (0, 0.5961273908615112, 0.47865258902311325, 0.6775530576705933, 0.5781088024377823)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_polos_492.png: 416x640 1 Topwear, 59.8ms\n",
      "Speed: 2.4ms preprocess, 59.8ms inference, 0.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Processing dataset_polos_492.png\n",
      "Annotations: [(0, 0.4911920428276062, 0.5690703094005585, 0.4421076774597168, 0.8372649550437927)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1266.png: 640x512 1 Bottomwear, 76.3ms\n",
      "Speed: 1.7ms preprocess, 76.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_1266.png\n",
      "Annotations: [(1, 0.4952993392944336, 0.5037082433700562, 0.5275824069976807, 0.9047961235046387)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1496.png: 640x512 1 Topwear, 2 Footwears, 73.5ms\n",
      "Speed: 1.8ms preprocess, 73.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_1496.png\n",
      "Annotations: [(2, 0.2654395028948784, 0.8935180604457855, 0.10748590528964996, 0.1161145567893982), (2, 0.19459118694067, 0.8874139189720154, 0.10759307444095612, 0.12404310703277588), (0, 0.2402230128645897, 0.45082055032253265, 0.399827316403389, 0.6573069393634796)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1772.png: 640x480 1 Topwear, 68.4ms\n",
      "Speed: 2.0ms preprocess, 68.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jeans_1772.png\n",
      "Annotations: [(0, 0.4977882541716099, 0.509777769446373, 0.8447418138384819, 0.814010888338089)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4865.png: 640x512 1 Topwear, 2 Footwears, 79.0ms\n",
      "Speed: 1.8ms preprocess, 79.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4865.png\n",
      "Annotations: [(2, 0.5409323871135712, 0.8699546754360199, 0.10346370935440063, 0.12107688188552856), (2, 0.26195888966321945, 0.8630159199237823, 0.09500856697559357, 0.14208561182022095), (0, 0.4354794919490814, 0.49438241124153137, 0.5331389307975769, 0.7315378785133362)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_1999.png: 640x480 1 Topwear, 67.8ms\n",
      "Speed: 2.1ms preprocess, 67.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jerseys_1999.png\n",
      "Annotations: [(0, 0.49933264404535294, 0.4678768068552017, 0.6382517069578171, 0.6541163623332977)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_1026.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 76.4ms\n",
      "Speed: 1.8ms preprocess, 76.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_1026.png\n",
      "Annotations: [(2, 0.37726421654224396, 0.8985862135887146, 0.09708508849143982, 0.12765538692474365), (2, 0.28470729291439056, 0.8788532614707947, 0.09358581900596619, 0.1501445770263672), (0, 0.34577417373657227, 0.23999586701393127, 0.26531392335891724, 0.18324881792068481), (1, 0.3069767877459526, 0.5073938965797424, 0.37532801926136017, 0.4033709764480591), (0, 0.3088158369064331, 0.4335094690322876, 0.3871358633041382, 0.5598044395446777)]\n",
      "Detections: ['original_image', 'topwear', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_2176.png: 640x480 1 Topwear, 65.2ms\n",
      "Speed: 2.2ms preprocess, 65.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_pantalones_2176.png\n",
      "Annotations: [(0, 0.5036058500409126, 0.45049554109573364, 0.8720604032278061, 0.8719513416290283)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_1728.png: 640x480 1 Topwear, 70.3ms\n",
      "Speed: 2.7ms preprocess, 70.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jerseys_1728.png\n",
      "Annotations: [(0, 0.4874616265296936, 0.37916038930416107, 0.5692723989486694, 0.5196817219257355)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_917.png: 640x448 1 Topwear, 66.9ms\n",
      "Speed: 1.1ms preprocess, 66.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_917.png\n",
      "Annotations: [(0, 0.4920526556670666, 0.4978208839893341, 0.9274797812104225, 0.9287663102149963)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_1720.png: 640x480 1 Topwear, 1 Bottomwear, 67.8ms\n",
      "Speed: 2.5ms preprocess, 67.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_trajes_1720.png\n",
      "Annotations: [(0, 0.5931036546826363, 0.20919084548950195, 0.8137926906347275, 0.4183816909790039), (1, 0.6342499703168869, 0.527281254529953, 0.7114703953266144, 0.9231740832328796)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_3137.png: 640x512 1 Topwear, 73.5ms\n",
      "Speed: 1.7ms preprocess, 73.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_3137.png\n",
      "Annotations: [(0, 0.48928043246269226, 0.5102749615907669, 0.9153786301612854, 0.8656140267848969)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_3404.png: 640x512 1 Topwear, 1 Bottomwear, 75.9ms\n",
      "Speed: 1.8ms preprocess, 75.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_3404.png\n",
      "Annotations: [(1, 0.5613027513027191, 0.9028772115707397, 0.5069862008094788, 0.1888725757598877), (0, 0.47695954889059067, 0.5760129243135452, 0.7026856690645218, 0.7401627004146576)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_2577.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 86.9ms\n",
      "Speed: 1.8ms preprocess, 86.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_2577.png\n",
      "Annotations: [(2, 0.3588089048862457, 0.8752670288085938, 0.1442844271659851, 0.14578330516815186), (2, 0.45969247817993164, 0.7891775667667389, 0.1565544605255127, 0.17705363035202026), (1, 0.39012789726257324, 0.443418487906456, 0.4436628818511963, 0.7251003086566925)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_3397.png: 640x512 1 Topwear, 1 Bottomwear, 77.9ms\n",
      "Speed: 2.6ms preprocess, 77.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_3397.png\n",
      "Annotations: [(1, 0.5369210094213486, 0.8829123675823212, 0.31692734360694885, 0.22014397382736206), (0, 0.5691954270005226, 0.5518551915884018, 0.8616091459989548, 0.6982288658618927)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5184.png: 640x480 1 Topwear, 66.8ms\n",
      "Speed: 1.9ms preprocess, 66.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_5184.png\n",
      "Annotations: [(0, 0.5051960931159556, 0.48346665501594543, 0.9816143540665507, 0.8788427710533142)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_3002.png: 640x640 1 Topwear, 1 Bottomwear, 88.7ms\n",
      "Speed: 1.7ms preprocess, 88.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_camisetas_3002.png\n",
      "Annotations: [(1, 0.4907849282026291, 0.8553002774715424, 0.328153520822525, 0.2893994450569153), (0, 0.5172523260116577, 0.4929075241088867, 0.4227193593978882, 0.5037894248962402)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_4049.png: 640x512 1 Topwear, 1 Bottomwear, 71.7ms\n",
      "Speed: 1.8ms preprocess, 71.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_4049.png\n",
      "Annotations: [(1, 0.5871834605932236, 0.8945163488388062, 0.501994401216507, 0.2102346420288086), (0, 0.5379592627286911, 0.5103424787521362, 0.7858896553516388, 0.7612336874008179)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_3161.png: 640x512 1 Topwear, 1 Bottomwear, 75.9ms\n",
      "Speed: 2.0ms preprocess, 75.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_3161.png\n",
      "Annotations: [(1, 0.4771163761615753, 0.9028099775314331, 0.43204396963119507, 0.18397235870361328), (0, 0.46556253731250763, 0.5462083518505096, 0.587105005979538, 0.6781237721443176)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_3020.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 74.7ms\n",
      "Speed: 1.8ms preprocess, 74.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_3020.png\n",
      "Annotations: [(2, 0.43686988949775696, 0.8924109637737274, 0.1748531460762024, 0.08202475309371948), (2, 0.2778369411826134, 0.8709194660186768, 0.18541254103183746, 0.08787798881530762), (1, 0.4408819228410721, 0.44653652608394623, 0.2320229709148407, 0.22172978520393372), (0, 0.47662730515003204, 0.2671946510672569, 0.42107924818992615, 0.2686309367418289)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5068.png: 640x512 1 Bottomwear, 75.7ms\n",
      "Speed: 1.7ms preprocess, 75.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_5068.png\n",
      "Annotations: [(1, 0.5007978901267052, 0.49963261373341084, 0.5937258750200272, 0.8920319937169552)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2291.png: 640x512 1 Topwear, 1 Bottomwear, 75.0ms\n",
      "Speed: 1.9ms preprocess, 75.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_2291.png\n",
      "Annotations: [(1, 0.5842391401529312, 0.7612609267234802, 0.5302761495113373, 0.4443463087081909), (0, 0.6190085858106613, 0.4990220367908478, 0.5004370510578156, 0.5080730319023132)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4160.png: 640x512 1 Bottomwear, 2 Footwears, 74.2ms\n",
      "Speed: 1.9ms preprocess, 74.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4160.png\n",
      "Annotations: [(2, 0.49371013045310974, 0.8159866333007812, 0.14721041917800903, 0.12459135055541992), (2, 0.8200207948684692, 0.8204644322395325, 0.1700810194015503, 0.1679929494857788), (1, 0.6167886853218079, 0.3526899069547653, 0.44994163513183594, 0.6382981836795807)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5027.png: 640x544 1 Topwear, 1 Bottomwear, 76.9ms\n",
      "Speed: 2.5ms preprocess, 76.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sudaderas_5027.png\n",
      "Annotations: [(1, 0.4938061386346817, 0.8094425797462463, 0.37753555178642273, 0.37653088569641113), (0, 0.49714820086956024, 0.4147290885448456, 0.5396598875522614, 0.5352031588554382)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_2549.png: 640x640 1 Bottomwear, 93.6ms\n",
      "Speed: 1.9ms preprocess, 93.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_pantalones_2549.png\n",
      "Annotations: [(1, 0.49867740273475647, 0.4952087849378586, 0.39264529943466187, 0.9580434858798981)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_1641.png: 640x480 1 Topwear, 2 Bottomwears, 69.8ms\n",
      "Speed: 1.6ms preprocess, 69.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jerseys_1641.png\n",
      "Annotations: [(1, 0.5164371654391289, 0.8715075850486755, 0.6284827142953873, 0.2569848299026489), (0, 0.5314105451107025, 0.45199592411518097, 0.5571824908256531, 0.6824494302272797)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_2375.png: 640x640 2 Bottomwears, 2 Footwears, 107.0ms\n",
      "Speed: 1.8ms preprocess, 107.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_pantalones_2375.png\n",
      "Annotations: [(2, 0.480315238237381, 0.7300394773483276, 0.12017852067947388, 0.18668580055236816), (2, 0.3976168930530548, 0.8834348917007446, 0.1313379406929016, 0.19140243530273438), (1, 0.452864333987236, 0.4255560673773289, 0.3145834505558014, 0.6957162544131279)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5560.png: 640x512 1 Topwear, 1 Bottomwear, 76.9ms\n",
      "Speed: 2.4ms preprocess, 76.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_5560.png\n",
      "Annotations: [(1, 0.5133242607116699, 0.7590500116348267, 0.4923654794692993, 0.45196354389190674), (0, 0.48355356603860855, 0.5096693634986877, 0.47704415023326874, 0.636122465133667)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_2868.png: 640x480 1 Topwear, 70.2ms\n",
      "Speed: 1.7ms preprocess, 70.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_vestidos_2868.png\n",
      "Annotations: [(0, 0.4953577592968941, 0.5269074589014053, 0.6034602969884872, 0.7881226241588593)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_231.png: 640x448 1 Topwear, 67.6ms\n",
      "Speed: 1.2ms preprocess, 67.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_231.png\n",
      "Annotations: [(0, 0.5007109101861715, 0.5103628486394882, 0.9301752932369709, 0.735061913728714)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2427.png: 640x512 1 Bottomwear, 2 Footwears, 75.3ms\n",
      "Speed: 2.1ms preprocess, 75.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_2427.png\n",
      "Annotations: [(2, 0.4774661511182785, 0.9391976594924927, 0.07904365658760071, 0.09742820262908936), (0, 0.4675648361444473, 0.3340250626206398, 0.21823439002037048, 0.20685772597789764), (1, 0.48710396885871887, 0.573904350399971, 0.25451451539993286, 0.647348016500473)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_2619.png: 640x512 1 Bottomwear, 2 Footwears, 76.7ms\n",
      "Speed: 1.9ms preprocess, 76.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_2619.png\n",
      "Annotations: [(2, 0.20012754201889038, 0.6286055445671082, 0.40025508403778076, 0.19677209854125977), (2, 0.5251908898353577, 0.6865797638893127, 0.6217879056930542, 0.30960726737976074), (1, 0.3797917030751705, 0.2979791760444641, 0.7087288573384285, 0.5959583520889282)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_319.png: 640x544 1 Topwear, 1 Bottomwear, 77.0ms\n",
      "Speed: 2.0ms preprocess, 77.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_abrigos_319.png\n",
      "Annotations: [(1, 0.47354865819215775, 0.9405046701431274, 0.48544178903102875, 0.11899065971374512), (0, 0.5293774008750916, 0.5721246004104614, 0.6669272184371948, 0.8110510110855103)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_1474.png: 640x448 1 Topwear, 65.4ms\n",
      "Speed: 1.8ms preprocess, 65.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jerseys_1474.png\n",
      "Annotations: [(0, 0.4900945909321308, 0.49616700410842896, 0.7405756935477257, 0.7745422124862671)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_719.png: 640x448 1 Bottomwear, 67.4ms\n",
      "Speed: 1.2ms preprocess, 67.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_trajes_719.png\n",
      "Annotations: [(1, 0.4957208186388016, 0.4890170395374298, 0.7066002786159515, 0.9194372296333313)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4514.png: 640x512 1 Topwear, 1 Bottomwear, 88.6ms\n",
      "Speed: 2.9ms preprocess, 88.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4514.png\n",
      "Annotations: [(1, 0.20776678621768951, 0.8963350355625153, 0.41553357243537903, 0.20608240365982056), (0, 0.31107938289642334, 0.5698931515216827, 0.6221587657928467, 0.6798984408378601)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1830.png: 640x512 1 Topwear, 1 Bottomwear, 77.9ms\n",
      "Speed: 1.7ms preprocess, 77.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_1830.png\n",
      "Annotations: [(1, 0.6964179426431656, 0.8942034244537354, 0.4733973443508148, 0.2097759246826172), (0, 0.5955199748277664, 0.5539936423301697, 0.7736814916133881, 0.7149572372436523)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_2164.png: 640x448 1 Topwear, 66.0ms\n",
      "Speed: 1.3ms preprocess, 66.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_2164.png\n",
      "Annotations: [(0, 0.48958395258523524, 0.4994516521692276, 0.9705459210090339, 0.7852899730205536)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_bodies_355.png: 640x512 1 Topwear, 1 Bottomwear, 76.1ms\n",
      "Speed: 2.0ms preprocess, 76.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_bodies_355.png\n",
      "Annotations: [(0, 0.7250542938709259, 0.48437580466270447, 0.38046473264694214, 0.4303085207939148), (1, 0.6910397857427597, 0.7930026948451996, 0.4274066984653473, 0.40296608209609985)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5085.png: 640x544 1 Topwear, 79.6ms\n",
      "Speed: 1.7ms preprocess, 79.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisetas_5085.png\n",
      "Annotations: [(0, 0.5097641292959452, 0.5023745745420456, 0.9218449704349041, 0.7918929159641266)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_3893.png: 640x480 1 Topwear, 70.7ms\n",
      "Speed: 1.9ms preprocess, 70.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisetas_3893.png\n",
      "Annotations: [(0, 0.4929930567741394, 0.35410095751285553, 0.7315871715545654, 0.527654618024826)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4596.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 78.4ms\n",
      "Speed: 1.7ms preprocess, 78.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4596.png\n",
      "Annotations: [(2, 0.4224480986595154, 0.9099980592727661, 0.07843708992004395, 0.1443803310394287), (2, 0.1479208506643772, 0.898898720741272, 0.12282823771238327, 0.12894964218139648), (0, 0.3817823827266693, 0.26139113306999207, 0.2380637526512146, 0.1969395875930786), (1, 0.33074861019849777, 0.6043684482574463, 0.419366255402565, 0.5041295289993286)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_887.png: 640x512 1 Topwear, 1 Bottomwear, 72.6ms\n",
      "Speed: 1.9ms preprocess, 72.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_887.png\n",
      "Annotations: [(1, 0.3098438885062933, 0.9078395664691925, 0.5022235102951527, 0.184320867061615), (0, 0.3493386507034302, 0.5643571615219116, 0.6986773014068604, 0.7925349473953247)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_4131.png: 640x512 1 Topwear, 1 Bottomwear, 75.2ms\n",
      "Speed: 1.8ms preprocess, 75.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_4131.png\n",
      "Annotations: [(1, 0.395026758313179, 0.889234334230423, 0.40880700945854187, 0.22081798315048218), (0, 0.3874075897037983, 0.5237927883863449, 0.6304762586951256, 0.6133169233798981)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5063.png: 640x512 1 Topwear, 1 Bottomwear, 87.4ms\n",
      "Speed: 1.9ms preprocess, 87.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_5063.png\n",
      "Annotations: [(1, 0.5337471514940262, 0.8973734974861145, 0.4508756101131439, 0.19538486003875732), (0, 0.5167099088430405, 0.5455941706895828, 0.6750198900699615, 0.6850803792476654)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5140.png: 640x448 1 Bottomwear, 63.3ms\n",
      "Speed: 2.3ms preprocess, 63.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_pantalones_5140.png\n",
      "Annotations: [(1, 0.4982549101114273, 0.49603360891342163, 0.4959544837474823, 0.8827036619186401)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5885.png: 640x480 3 Bottomwears, 69.1ms\n",
      "Speed: 1.8ms preprocess, 69.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_pantalones_5885.png\n",
      "Annotations: [(1, 0.5736811980605125, 0.5048253387212753, 0.836682990193367, 0.9880321323871613)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_1978.png: 640x512 1 Topwear, 1 Bottomwear, 75.8ms\n",
      "Speed: 2.6ms preprocess, 75.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_1978.png\n",
      "Annotations: [(1, 0.5841629952192307, 0.8835004568099976, 0.43944790959358215, 0.22423934936523438), (0, 0.5781728476285934, 0.5282159596681595, 0.5983516275882721, 0.6405745446681976)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_3368.png: 640x480 1 Topwear, 69.3ms\n",
      "Speed: 1.7ms preprocess, 69.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_sudaderas_3368.png\n",
      "Annotations: [(0, 0.50003382563591, 0.487456351518631, 0.8553897738456726, 0.8645750880241394)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1899.png: 640x512 1 Topwear, 1 Bottomwear, 75.4ms\n",
      "Speed: 2.5ms preprocess, 75.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_1899.png\n",
      "Annotations: [(1, 0.6402624547481537, 0.8911975622177124, 0.40984052419662476, 0.20103442668914795), (0, 0.6665152311325073, 0.5135211199522018, 0.6036961078643799, 0.6922716200351715)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5508.png: 640x448 1 Topwear, 1 Bottomwear, 2 Footwears, 67.4ms\n",
      "Speed: 1.6ms preprocess, 67.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_pantalones_5508.png\n",
      "Annotations: [(2, 0.5182835906744003, 0.8865977227687836, 0.20346549153327942, 0.1653624176979065), (2, 0.28880392014980316, 0.8910293877124786, 0.2939821779727936, 0.1666213870048523), (0, 0.5201070383191109, 0.09694215981289744, 0.5637752860784531, 0.16907512489706278), (1, 0.4562981203198433, 0.4157191962003708, 0.5973915904760361, 0.6662172377109528)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4525.png: 640x448 1 Topwear, 67.8ms\n",
      "Speed: 1.2ms preprocess, 67.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_vestidos_4525.png\n",
      "Annotations: [(1, 0.5012271925806999, 0.7100260853767395, 0.5845018774271011, 0.47311675548553467), (0, 0.4899867922067642, 0.49557216465473175, 0.7807929217815399, 0.9383374154567719)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_477.png: 640x480 1 Bottomwear, 84.5ms\n",
      "Speed: 1.8ms preprocess, 84.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_pantalones_477.png\n",
      "Annotations: [(1, 0.5036209374666214, 0.5015469044446945, 0.5020793378353119, 0.9891871511936188)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_140.png: 640x480 1 Footwear, 70.8ms\n",
      "Speed: 2.2ms preprocess, 70.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas_140.png\n",
      "Annotations: [(2, 0.5, 0.4892289936542511, 1.0, 0.4553448557853699)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_3936.png: 640x512 1 Topwear, 1 Bottomwear, 76.4ms\n",
      "Speed: 2.0ms preprocess, 76.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_3936.png\n",
      "Annotations: [(1, 0.3597305789589882, 0.874725729227066, 0.45215384662151337, 0.23183447122573853), (0, 0.3779982700943947, 0.5215072631835938, 0.613123819231987, 0.5672726631164551)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_1855.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 84.2ms\n",
      "Speed: 1.9ms preprocess, 84.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_1855.png\n",
      "Annotations: [(2, 0.858303427696228, 0.8991268873214722, 0.12306761741638184, 0.16702568531036377), (2, 0.6750776171684265, 0.8804672062397003, 0.14023041725158691, 0.19104915857315063), (0, 0.7820126414299011, 0.27806946635246277, 0.21669578552246094, 0.19697046279907227), (1, 0.7804892063140869, 0.4499891996383667, 0.24339830875396729, 0.2459275722503662)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4239.png: 640x512 1 Bottomwear, 2 Footwears, 85.8ms\n",
      "Speed: 2.4ms preprocess, 85.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4239.png\n",
      "Annotations: [(2, 0.5705127716064453, 0.8127107322216034, 0.29219913482666016, 0.1503869891166687), (2, 0.2661565840244293, 0.8867725133895874, 0.28385037183761597, 0.15679311752319336), (1, 0.4851248264312744, 0.43559888005256653, 0.4158138036727905, 0.7425615191459656)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_1882.png: 640x512 1 Bottomwear, 85.1ms\n",
      "Speed: 1.8ms preprocess, 85.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_1882.png\n",
      "Annotations: [(1, 0.49463000148534775, 0.4548143669962883, 0.7753375321626663, 0.4825214296579361)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_1471.png: 640x512 1 Topwear, 1 Bottomwear, 1 Footwear, 83.7ms\n",
      "Speed: 1.9ms preprocess, 83.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_1471.png\n",
      "Annotations: [(2, 0.7694770693778992, 0.8531341552734375, 0.14605236053466797, 0.09246182441711426), (0, 0.700315922498703, 0.2098204270005226, 0.21416550874710083, 0.18179349601268768), (1, 0.7035493850708008, 0.4713338613510132, 0.27588820457458496, 0.39950108528137207)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_3775.png: 640x512 1 Bottomwear, 2 Footwears, 88.3ms\n",
      "Speed: 2.2ms preprocess, 88.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_3775.png\n",
      "Annotations: [(2, 0.3399364836513996, 0.5786508321762085, 0.567298911511898, 0.26863861083984375), (2, 0.6628059446811676, 0.6485869586467743, 0.4750744700431824, 0.38294821977615356), (1, 0.533827543258667, 0.24321602284908295, 0.834716796875, 0.46921297907829285)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4275.png: 640x448 1 Topwear, 1 Bottomwear, 81.3ms\n",
      "Speed: 2.2ms preprocess, 81.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisetas_4275.png\n",
      "Annotations: [(1, 0.4668941795825958, 0.8949523568153381, 0.4481300711631775, 0.21009528636932373), (0, 0.5076982006430626, 0.5312684327363968, 0.6301090270280838, 0.6036013066768646)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1786.png: 640x480 1 Topwear, 72.0ms\n",
      "Speed: 2.0ms preprocess, 72.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jeans_1786.png\n",
      "Annotations: [(0, 0.5001731850206852, 0.5213502496480942, 0.870991162955761, 0.8514974415302277)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1514.png: 640x512 1 Bottomwear, 75.3ms\n",
      "Speed: 2.1ms preprocess, 75.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_1514.png\n",
      "Annotations: [(1, 0.5001079589128494, 0.4920228458940983, 0.47997280955314636, 0.7467716261744499)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_956.png: 640x544 1 Topwear, 1 Bottomwear, 85.9ms\n",
      "Speed: 1.6ms preprocess, 85.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_abrigos_956.png\n",
      "Annotations: [(1, 0.6124347448348999, 0.9273098409175873, 0.4864225387573242, 0.14538031816482544), (0, 0.5343519002199173, 0.5757606029510498, 0.680141419172287, 0.7857322692871094)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_2576.png: 640x512 1 Topwear, 1 Bottomwear, 78.6ms\n",
      "Speed: 1.7ms preprocess, 78.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_2576.png\n",
      "Annotations: [(0, 0.49738358706235886, 0.4523372910916805, 0.8410253673791885, 0.7207512333989143)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_tacones_336.png: 640x512 2 Footwears, 76.0ms\n",
      "Speed: 1.9ms preprocess, 76.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_tacones_336.png\n",
      "Annotations: [(2, 0.6621889621019363, 0.583157017827034, 0.35496601462364197, 0.4379065930843353), (2, 0.3040859326720238, 0.5721282660961151, 0.41746826469898224, 0.4876938462257385)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_609.png: 640x448 1 Topwear, 1 Bottomwear, 2 Footwears, 67.4ms\n",
      "Speed: 1.5ms preprocess, 67.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_pantalones_609.png\n",
      "Annotations: [(2, 0.6464654803276062, 0.9142532348632812, 0.1581517457962036, 0.1305680274963379), (2, 0.4000184237957001, 0.9172888398170471, 0.27197617292404175, 0.12085795402526855), (1, 0.5212080925703049, 0.5040351897478104, 0.49420204758644104, 0.7870350778102875)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_5371.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 87.1ms\n",
      "Speed: 2.0ms preprocess, 87.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_5371.png\n",
      "Annotations: [(2, 0.230866439640522, 0.9062747955322266, 0.18387190997600555, 0.10981881618499756), (2, 0.5410304963588715, 0.8824824690818787, 0.21157020330429077, 0.13634181022644043), (0, 0.32985401526093483, 0.16269747912883759, 0.4712287113070488, 0.31479302048683167), (1, 0.3775634095072746, 0.5492177307605743, 0.45168067514896393, 0.61961430311203)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_1318.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 76.6ms\n",
      "Speed: 2.1ms preprocess, 76.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_1318.png\n",
      "Annotations: [(2, 0.5976344048976898, 0.8753114938735962, 0.13641458749771118, 0.1187673807144165), (2, 0.4230223000049591, 0.8339882791042328, 0.1671406626701355, 0.1326325535774231), (0, 0.47936253249645233, 0.12116575241088867, 0.6595303118228912, 0.24233150482177734), (1, 0.46823664009571075, 0.44890737533569336, 0.36666664481163025, 0.7508680820465088)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5488.png: 640x480 1 Topwear, 68.8ms\n",
      "Speed: 2.3ms preprocess, 68.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_5488.png\n",
      "Annotations: [(0, 0.4992574602365494, 0.443390429019928, 0.8278619945049286, 0.8681920766830444)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_2214.png: 640x512 1 Bottomwear, 2 Footwears, 74.2ms\n",
      "Speed: 2.2ms preprocess, 74.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_2214.png\n",
      "Annotations: [(2, 0.21265259385108948, 0.5864217281341553, 0.42530518770217896, 0.1960756778717041), (2, 0.5230246931314468, 0.6793590784072876, 0.628565639257431, 0.3373527526855469), (1, 0.38756705820560455, 0.2748791575431824, 0.6838463246822357, 0.5081745386123657)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_49.png: 640x448 1 Bottomwear, 62.3ms\n",
      "Speed: 1.9ms preprocess, 62.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jeans_49.png\n",
      "Annotations: [(1, 0.48884405195713043, 0.49747224152088165, 0.6604691445827484, 0.9305437505245209)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_4294.png: 640x512 1 Topwear, 1 Bottomwear, 80.9ms\n",
      "Speed: 8.5ms preprocess, 80.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_4294.png\n",
      "Annotations: [(1, 0.6076189875602722, 0.9094281792640686, 0.4715214967727661, 0.1811436414718628), (0, 0.5328879728913307, 0.5462974458932877, 0.6630957573652267, 0.7144326865673065)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_153.png: 640x448 1 Topwear, 1 Bottomwear, 63.4ms\n",
      "Speed: 2.0ms preprocess, 63.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_sudaderas_153.png\n",
      "Annotations: [(1, 0.4240685701370239, 0.9436804950237274, 0.5641199350357056, 0.11263900995254517), (0, 0.4716902608051896, 0.5613053143024445, 0.9124131929129362, 0.7354118227958679)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_4817.png: 640x512 1 Topwear, 1 Bottomwear, 75.1ms\n",
      "Speed: 2.1ms preprocess, 75.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_4817.png\n",
      "Annotations: [(1, 0.7759506106376648, 0.8554804027080536, 0.4480987787246704, 0.2890391945838928), (0, 0.6959830969572067, 0.5231999456882477, 0.6080338060855865, 0.5474933981895447)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5465.png: 640x512 1 Topwear, 1 Bottomwear, 75.9ms\n",
      "Speed: 2.2ms preprocess, 75.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_5465.png\n",
      "Annotations: [(1, 0.5322276204824448, 0.8557727336883545, 0.5325010120868683, 0.2797107696533203), (0, 0.6305183619260788, 0.5628078132867813, 0.5917514860630035, 0.6393997371196747)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_3572.png: 640x640 1 Topwear, 91.8ms\n",
      "Speed: 2.0ms preprocess, 91.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_sudaderas_3572.png\n",
      "Annotations: [(0, 0.5019713714718819, 0.5011997949331999, 0.6025996059179306, 0.922416303306818)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4722.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 76.8ms\n",
      "Speed: 2.2ms preprocess, 76.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_4722.png\n",
      "Annotations: [(2, 0.6184253692626953, 0.8133238554000854, 0.18030643463134766, 0.10067152976989746), (2, 0.8337720632553101, 0.8275408148765564, 0.17207980155944824, 0.10878777503967285), (0, 0.7109167277812958, 0.14377960562705994, 0.34330087900161743, 0.2601376175880432), (1, 0.7215482294559479, 0.5029124468564987, 0.34857088327407837, 0.5477215349674225)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5774.png: 640x480 1 Topwear, 80.3ms\n",
      "Speed: 2.1ms preprocess, 80.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_sudaderas_5774.png\n",
      "Annotations: [(0, 0.5045322403311729, 0.3314773887395859, 0.690684512257576, 0.42460301518440247)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1407.png: 640x512 1 Bottomwear, 2 Footwears, 77.6ms\n",
      "Speed: 2.2ms preprocess, 77.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_1407.png\n",
      "Annotations: [(2, 0.7073620855808258, 0.680378258228302, 0.27030426263809204, 0.33665716648101807), (2, 0.3099954389035702, 0.5974599123001099, 0.4736052230000496, 0.29519641399383545), (1, 0.611436665058136, 0.2597617506980896, 0.6959798336029053, 0.5191460847854614)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5363.png: 640x416 1 Topwear, 63.6ms\n",
      "Speed: 1.6ms preprocess, 63.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 416)\n",
      "Processing dataset_abrigos_5363.png\n",
      "Annotations: [(0, 0.5083258487284184, 0.5014218538999557, 0.8782523199915886, 0.6415986120700836)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_3969.png: 640x640 1 Footwear, 94.2ms\n",
      "Speed: 2.1ms preprocess, 94.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_3969.png\n",
      "Annotations: [(2, 0.4989428259432316, 0.6001635044813156, 0.8179240748286247, 0.37820401787757874)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_1249.png: 640x544 1 Topwear, 79.7ms\n",
      "Speed: 1.8ms preprocess, 79.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_abrigos_1249.png\n",
      "Annotations: [(0, 0.48555266112089157, 0.5061821490526199, 0.5983257442712784, 0.6494823396205902)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_4699.png: 640x448 1 Topwear, 1 Bottomwear, 66.7ms\n",
      "Speed: 1.9ms preprocess, 66.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_4699.png\n",
      "Annotations: [(1, 0.5206542462110519, 0.7602521181106567, 0.4682774841785431, 0.3043558597564697), (0, 0.498169869184494, 0.4793904721736908, 0.5551345944404602, 0.4292089343070984)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_1729.png: 640x512 1 Topwear, 1 Bottomwear, 87.3ms\n",
      "Speed: 1.9ms preprocess, 87.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_1729.png\n",
      "Annotations: [(1, 0.37236034870147705, 0.8968375325202942, 0.4492819309234619, 0.2025514841079712), (0, 0.4341551810503006, 0.5500633716583252, 0.4566449820995331, 0.7452806234359741)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_2572.png: 640x512 1 Topwear, 1 Bottomwear, 74.1ms\n",
      "Speed: 2.0ms preprocess, 74.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_2572.png\n",
      "Annotations: [(0, 0.5367264375090599, 0.5807246118783951, 0.7252367287874222, 0.7603976428508759)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_1303.png: 640x480 1 Topwear, 71.9ms\n",
      "Speed: 2.1ms preprocess, 71.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas_1303.png\n",
      "Annotations: [(0, 0.4938161373138428, 0.37381336838006973, 0.49162721633911133, 0.4511411637067795)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_2517.png: 640x512 1 Topwear, 1 Bottomwear, 78.1ms\n",
      "Speed: 2.2ms preprocess, 78.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_2517.png\n",
      "Annotations: [(1, 0.5980848968029022, 0.8926356434822083, 0.38031119108200073, 0.2147287130355835), (0, 0.595015324652195, 0.5001353621482849, 0.740199014544487, 0.6548850536346436)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_2617.png: 640x512 1 Topwear, 77.6ms\n",
      "Speed: 2.1ms preprocess, 77.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_2617.png\n",
      "Annotations: [(0, 0.2715578458737582, 0.6310449689626694, 0.533762498293072, 0.694731742143631)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4832.png: 640x544 1 Bottomwear, 81.5ms\n",
      "Speed: 1.7ms preprocess, 81.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_jeans_4832.png\n",
      "Annotations: [(1, 0.5106755346059799, 0.49739301577210426, 0.41644325852394104, 0.773855559527874)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4421.png: 640x512 1 Topwear, 2 Footwears, 92.7ms\n",
      "Speed: 2.5ms preprocess, 92.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4421.png\n",
      "Annotations: [(2, 0.2654947265982628, 0.8598171472549438, 0.08084072172641754, 0.10671234130859375), (2, 0.5337938964366913, 0.8535013496875763, 0.09903746843338013, 0.08935338258743286), (0, 0.39638081938028336, 0.5050820261240005, 0.3678425997495651, 0.7084328830242157)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4843.png: 640x512 1 Topwear, 1 Bottomwear, 75.7ms\n",
      "Speed: 2.0ms preprocess, 75.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4843.png\n",
      "Annotations: [(1, 0.5649580210447311, 0.9031913578510284, 0.44124308228492737, 0.19361728429794312), (0, 0.6181996166706085, 0.5177150517702103, 0.6517072319984436, 0.6913052499294281)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5428.png: 640x512 2 Topwears, 1 Bottomwear, 2 Footwears, 73.9ms\n",
      "Speed: 1.8ms preprocess, 73.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_5428.png\n",
      "Annotations: [(2, 0.5936417877674103, 0.8783279061317444, 0.09211283922195435, 0.12174797058105469), (2, 0.47611434757709503, 0.8938106596469879, 0.09254834055900574, 0.12685555219650269), (0, 0.5585165321826935, 0.32923220843076706, 0.30117303133010864, 0.29654480516910553), (1, 0.52996826171875, 0.6435353308916092, 0.2805277109146118, 0.41037067770957947)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatos_895.png: 640x512 1 Bottomwear, 2 Footwears, 74.9ms\n",
      "Speed: 1.9ms preprocess, 74.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatos_895.png\n",
      "Annotations: [(2, 0.3452148400247097, 0.7092788219451904, 0.5376911237835884, 0.25633788108825684), (2, 0.5371380597352982, 0.5457247048616409, 0.4252184331417084, 0.3963176906108856), (1, 0.47361492086201906, 0.26317912340164185, 0.8917695488780737, 0.5263582468032837)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1967.png: 640x448 1 Bottomwear, 65.8ms\n",
      "Speed: 2.0ms preprocess, 65.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jeans_1967.png\n",
      "Annotations: [(1, 0.49379831552505493, 0.4894311297684908, 0.5573946237564087, 0.8876467011868954)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2120.png: 640x448 1 Topwear, 68.2ms\n",
      "Speed: 1.3ms preprocess, 68.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jerseys_2120.png\n",
      "Annotations: [(0, 0.47706884890794754, 0.4979032278060913, 0.8977339118719101, 0.5941206216812134)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2439.png: 640x512 1 Topwear, 1 Bottomwear, 91.5ms\n",
      "Speed: 2.1ms preprocess, 91.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_2439.png\n",
      "Annotations: [(1, 0.5343789756298065, 0.8525276184082031, 0.49251192808151245, 0.2837477922439575), (0, 0.6149856448173523, 0.5273060500621796, 0.5156422853469849, 0.5150205492973328)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_3632.png: 640x512 1 Topwear, 1 Bottomwear, 78.4ms\n",
      "Speed: 1.9ms preprocess, 78.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_3632.png\n",
      "Annotations: [(1, 0.4717540219426155, 0.8357552886009216, 0.49700509011745453, 0.32199740409851074), (0, 0.6315670609474182, 0.5064267516136169, 0.5466868877410889, 0.4579411745071411)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_2249.png: 640x512 1 Topwear, 73.8ms\n",
      "Speed: 1.8ms preprocess, 73.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_2249.png\n",
      "Annotations: [(0, 0.49893419817090034, 0.5028651505708694, 0.8181771263480186, 0.6852050721645355)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1698.png: 640x544 1 Bottomwear, 79.4ms\n",
      "Speed: 2.3ms preprocess, 79.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_jeans_1698.png\n",
      "Annotations: [(1, 0.49811142683029175, 0.5077914446592331, 0.3771708011627197, 0.7336479723453522)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_2195.png: 640x640 1 Topwear, 1 Bottomwear, 2 Footwears, 92.6ms\n",
      "Speed: 2.0ms preprocess, 92.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_pantalones_2195.png\n",
      "Annotations: [(2, 0.5973370969295502, 0.9104757905006409, 0.14617496728897095, 0.1320350170135498), (2, 0.3307361304759979, 0.8994893431663513, 0.22908282279968262, 0.12173283100128174), (1, 0.5141248106956482, 0.527833878993988, 0.36920857429504395, 0.7434080839157104)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1258.png: 640x640 1 Footwear, 102.7ms\n",
      "Speed: 2.0ms preprocess, 102.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_1258.png\n",
      "Annotations: [(2, 0.4902915358543396, 0.5255111455917358, 0.8329951763153076, 0.4964148998260498)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_3978.png: 640x512 1 Topwear, 1 Bottomwear, 76.1ms\n",
      "Speed: 2.0ms preprocess, 76.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_3978.png\n",
      "Annotations: [(1, 0.4764139801263809, 0.9083444476127625, 0.4084185063838959, 0.1833111047744751), (0, 0.5040372163057327, 0.5761120170354843, 0.6452518403530121, 0.6783495247364044)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_3159.png: 640x512 1 Topwear, 1 Bottomwear, 78.2ms\n",
      "Speed: 2.2ms preprocess, 78.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_3159.png\n",
      "Annotations: [(1, 0.5300261527299881, 0.9073323607444763, 0.5049459636211395, 0.18533527851104736), (0, 0.49756480753421783, 0.621706560254097, 0.7641074359416962, 0.69289430975914)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_917.png: 640x512 1 Topwear, 1 Bottomwear, 75.6ms\n",
      "Speed: 2.0ms preprocess, 75.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_917.png\n",
      "Annotations: [(1, 0.40064793825149536, 0.936525821685791, 0.44579970836639404, 0.12694835662841797), (0, 0.4662597831338644, 0.5775469690561295, 0.8569491989910603, 0.7453372180461884)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_4017.png: 640x512 1 Topwear, 1 Bottomwear, 77.6ms\n",
      "Speed: 1.9ms preprocess, 77.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_4017.png\n",
      "Annotations: [(1, 0.2677256166934967, 0.9023645222187042, 0.5354512333869934, 0.19527095556259155), (0, 0.36899247765541077, 0.5583315044641495, 0.5619913935661316, 0.6567897498607635)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_1976.png: 640x512 1 Topwear, 1 Bottomwear, 92.9ms\n",
      "Speed: 1.9ms preprocess, 92.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_1976.png\n",
      "Annotations: [(1, 0.6635831892490387, 0.8988994359970093, 0.40334922075271606, 0.19674885272979736), (0, 0.6911537945270538, 0.5174433439970016, 0.4918978810310364, 0.6824609339237213)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_363.png: 640x480 1 Topwear, 69.9ms\n",
      "Speed: 1.5ms preprocess, 69.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas_363.png\n",
      "Annotations: [(0, 0.4971362426877022, 0.48220711946487427, 0.7833310216665268, 0.894171953201294)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_140.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 77.9ms\n",
      "Speed: 1.9ms preprocess, 77.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_140.png\n",
      "Annotations: [(2, 0.5634062886238098, 0.9346973896026611, 0.1016777753829956, 0.09499263763427734), (2, 0.3773375153541565, 0.9190256893634796, 0.20615696907043457, 0.09019249677658081), (1, 0.5093488842248917, 0.6608117818832397, 0.3146359622478485, 0.5104398727416992), (0, 0.5317737460136414, 0.32519878447055817, 0.412731409072876, 0.41738149523735046)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4935.png: 640x512 1 Topwear, 76.4ms\n",
      "Speed: 2.0ms preprocess, 76.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4935.png\n",
      "Annotations: [(0, 0.7271911203861237, 0.5060857534408569, 0.39988547563552856, 0.7614781856536865)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_2161.png: 640x512 1 Topwear, 2 Footwears, 75.1ms\n",
      "Speed: 1.9ms preprocess, 75.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_2161.png\n",
      "Annotations: [(2, 0.5157738775014877, 0.9426783919334412, 0.14384928345680237, 0.09856486320495605), (2, 0.619588702917099, 0.8396463990211487, 0.11087173223495483, 0.14032936096191406), (1, 0.5255249589681625, 0.547486424446106, 0.2812711298465729, 0.10819518566131592), (0, 0.5128806084394455, 0.3612770438194275, 0.34439900517463684, 0.4165271520614624)]\n",
      "Detections: ['original_image', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4537.png: 640x512 1 Topwear, 1 Bottomwear, 88.9ms\n",
      "Speed: 1.9ms preprocess, 88.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4537.png\n",
      "Annotations: [(1, 0.24548222497105598, 0.8635320067405701, 0.34412284940481186, 0.2637139558792114), (0, 0.2819746732711792, 0.4861748591065407, 0.5639493465423584, 0.6451251953840256)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5811.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 75.9ms\n",
      "Speed: 1.9ms preprocess, 75.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_5811.png\n",
      "Annotations: [(2, 0.629109114408493, 0.95538529753685, 0.11999958753585815, 0.07588428258895874), (2, 0.38444001972675323, 0.9534394145011902, 0.11646488308906555, 0.08036720752716064), (0, 0.4754847288131714, 0.24371814727783203, 0.2102656364440918, 0.20013535022735596), (1, 0.499088779091835, 0.6563196182250977, 0.40218254923820496, 0.6435655355453491)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2131.png: 640x512 1 Topwear, 1 Bottomwear, 76.5ms\n",
      "Speed: 1.8ms preprocess, 76.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_2131.png\n",
      "Annotations: [(1, 0.7683674991130829, 0.9406112432479858, 0.456637442111969, 0.11455214023590088), (0, 0.6071107462048531, 0.5959248542785645, 0.7857785075902939, 0.6993144750595093)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_776.png: 640x480 1 Topwear, 71.5ms\n",
      "Speed: 1.9ms preprocess, 71.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas-y-blusas_776.png\n",
      "Annotations: [(0, 0.49922893196344376, 0.40822821855545044, 0.5825652331113815, 0.5664383172988892)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_1551.png: 640x448 1 Topwear, 1 Bottomwear, 2 Footwears, 69.4ms\n",
      "Speed: 1.5ms preprocess, 69.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_pantalones_1551.png\n",
      "Annotations: [(2, 0.6038152575492859, 0.8546832203865051, 0.21499228477478027, 0.14891231060028076), (2, 0.30287300050258636, 0.8328660130500793, 0.32524773478507996, 0.11977458000183105), (0, 0.6026665270328522, 0.12649059295654297, 0.7262666821479797, 0.2446516454219818), (1, 0.527128666639328, 0.4761331379413605, 0.5058894753456116, 0.6701719164848328)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4548.png: 640x512 1 Topwear, 1 Bottomwear, 93.8ms\n",
      "Speed: 1.9ms preprocess, 93.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_4548.png\n",
      "Annotations: [(1, 0.3705459460616112, 0.9032055735588074, 0.48853524029254913, 0.19358885288238525), (0, 0.34882935881614685, 0.5496233850717545, 0.6976587176322937, 0.6715299785137177)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1459.png: 640x512 1 Topwear, 1 Bottomwear, 75.6ms\n",
      "Speed: 2.1ms preprocess, 75.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_1459.png\n",
      "Annotations: [(1, 0.496195450425148, 0.8662308156490326, 0.524302214384079, 0.26446205377578735), (0, 0.5114998295903206, 0.5018278360366821, 0.8163626044988632, 0.7030375003814697)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5886.png: 640x512 1 Topwear, 77.0ms\n",
      "Speed: 1.7ms preprocess, 77.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_5886.png\n",
      "Annotations: [(0, 0.49149954319000244, 0.5502051040530205, 0.5498664379119873, 0.6634783893823624)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_3509.png: 640x512 1 Topwear, 79.0ms\n",
      "Speed: 1.8ms preprocess, 79.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_3509.png\n",
      "Annotations: [(0, 0.5095357000827789, 0.5001193135976791, 0.8146602511405945, 0.6998758614063263)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2477.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 77.2ms\n",
      "Speed: 1.8ms preprocess, 77.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_2477.png\n",
      "Annotations: [(2, 0.7790693044662476, 0.8970511853694916, 0.1002659797668457, 0.12492769956588745), (2, 0.5181289166212082, 0.893384575843811, 0.19125202298164368, 0.10710585117340088), (1, 0.7918698489665985, 0.45150846242904663, 0.2917643189430237, 0.1601189374923706), (0, 0.7894265353679657, 0.29575615376234055, 0.4211469292640686, 0.3709261566400528)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_3894.png: 640x640 1 Footwear, 109.0ms\n",
      "Speed: 1.9ms preprocess, 109.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_3894.png\n",
      "Annotations: [(2, 0.495555579662323, 0.48311641812324524, 0.3256288766860962, 0.1556437611579895)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatos_1216.png: 640x512 1 Bottomwear, 2 Footwears, 79.4ms\n",
      "Speed: 2.0ms preprocess, 79.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatos_1216.png\n",
      "Annotations: [(2, 0.8058516979217529, 0.6543003618717194, 0.23270976543426514, 0.2507409453392029), (2, 0.3173262644559145, 0.6365429759025574, 0.5234691761434078, 0.211539626121521), (1, 0.6355142593383789, 0.24569632858037949, 0.6940774917602539, 0.45971013605594635)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4302.png: 640x512 1 Topwear, 77.7ms\n",
      "Speed: 1.7ms preprocess, 77.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_4302.png\n",
      "Annotations: [(0, 0.48615653067827225, 0.5612286925315857, 0.6369106620550156, 0.7208770513534546)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_4265.png: 640x544 1 Topwear, 79.2ms\n",
      "Speed: 1.8ms preprocess, 79.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_abrigos_4265.png\n",
      "Annotations: [(0, 0.5040639489889145, 0.4814402014017105, 0.6350634396076202, 0.5538584887981415)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_3273.png: 640x448 1 Topwear, 1 Bottomwear, 2 Footwears, 67.7ms\n",
      "Speed: 2.1ms preprocess, 67.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jeans_3273.png\n",
      "Annotations: [(2, 0.3831990659236908, 0.856480062007904, 0.12603354454040527, 0.12350618839263916), (2, 0.8148998618125916, 0.8587570786476135, 0.12469780445098877, 0.13247287273406982), (0, 0.5305055379867554, 0.09948046132922173, 0.4291532039642334, 0.15687564760446548), (1, 0.5450023710727692, 0.4507184587419033, 0.5510227084159851, 0.700679786503315)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_1409.png: 640x448 1 Topwear, 1 Bottomwear, 69.3ms\n",
      "Speed: 1.9ms preprocess, 69.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jerseys_1409.png\n",
      "Annotations: [(1, 0.4740618169307709, 0.887501448392868, 0.5838978886604309, 0.22499710321426392), (0, 0.5298157408833504, 0.5264168381690979, 0.6288262456655502, 0.5481358766555786)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4791.png: 640x512 1 Topwear, 1 Bottomwear, 78.4ms\n",
      "Speed: 1.9ms preprocess, 78.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4791.png\n",
      "Annotations: [(1, 0.509932816028595, 0.8936468064785004, 0.4766901731491089, 0.1751309037208557), (0, 0.5942455679178238, 0.53104467689991, 0.566690057516098, 0.6416731774806976)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botas_348.png: 640x512 1 Bottomwear, 2 Footwears, 79.6ms\n",
      "Speed: 1.9ms preprocess, 79.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_botas_348.png\n",
      "Annotations: [(2, 0.773002952337265, 0.6760806441307068, 0.30705875158309937, 0.32139790058135986), (2, 0.33510833233594894, 0.40983879566192627, 0.47681643068790436, 0.7325683832168579), (1, 0.6227030530571938, 0.2846251428127289, 0.7479948252439499, 0.5538318753242493)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_139.png: 640x544 1 Topwear, 1 Bottomwear, 81.4ms\n",
      "Speed: 1.8ms preprocess, 81.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_shorts_139.png\n",
      "Annotations: [(1, 0.5547462329268456, 0.4401688911020756, 0.73859603703022, 0.6628276631236076)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_2886.png: 640x512 1 Topwear, 1 Bottomwear, 92.4ms\n",
      "Speed: 2.0ms preprocess, 92.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_2886.png\n",
      "Annotations: [(1, 0.6960864067077637, 0.8761371970176697, 0.36585915088653564, 0.24772560596466064), (0, 0.7231548577547073, 0.6211225837469101, 0.5275683104991913, 0.6735823452472687)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botas_544.png: 640x512 2 Footwears, 75.9ms\n",
      "Speed: 1.9ms preprocess, 75.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_botas_544.png\n",
      "Annotations: [(2, 0.34307702630758286, 0.4779663681983948, 0.41318686306476593, 0.5201631784439087)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5773.png: 640x512 1 Topwear, 78.1ms\n",
      "Speed: 1.8ms preprocess, 78.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_5773.png\n",
      "Annotations: [(0, 0.4794536307454109, 0.43448877334594727, 0.6171737760305405, 0.5686542987823486)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5086.png: 640x512 1 Topwear, 1 Bottomwear, 78.5ms\n",
      "Speed: 1.9ms preprocess, 78.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_5086.png\n",
      "Annotations: [(1, 0.4027540534734726, 0.9136871695518494, 0.4903618395328522, 0.17262566089630127), (0, 0.47833985462784767, 0.5927656888961792, 0.7176035568118095, 0.6299594640731812)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_5127.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 90.6ms\n",
      "Speed: 1.8ms preprocess, 90.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_5127.png\n",
      "Annotations: [(2, 0.5209710001945496, 0.8612244129180908, 0.11473333835601807, 0.12814545631408691), (2, 0.3644651025533676, 0.7615673840045929, 0.10933628678321838, 0.16333800554275513), (0, 0.48815491795539856, 0.06083758920431137, 0.28858405351638794, 0.12167517840862274), (1, 0.4989791065454483, 0.49344972521066666, 0.32373782992362976, 0.6084711998701096)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4654.png: 640x512 1 Topwear, 1 Bottomwear, 76.8ms\n",
      "Speed: 1.8ms preprocess, 76.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4654.png\n",
      "Annotations: [(1, 0.5305850654840469, 0.9132289886474609, 0.5848492085933685, 0.17354202270507812), (0, 0.46455109119415283, 0.5886237472295761, 0.755407452583313, 0.715641051530838)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3205.png: 640x480 1 Topwear, 71.8ms\n",
      "Speed: 1.8ms preprocess, 71.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_vestidos_3205.png\n",
      "Annotations: [(0, 0.4916987493634224, 0.5118893533945084, 0.5557850450277328, 0.8296529948711395)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_tacones_712.png: 640x512 2 Footwears, 78.2ms\n",
      "Speed: 1.8ms preprocess, 78.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_tacones_712.png\n",
      "Annotations: [(2, 0.6560799479484558, 0.5704259872436523, 0.3582897186279297, 0.3941326141357422), (2, 0.38430458307266235, 0.5981733798980713, 0.42783594131469727, 0.4324444532394409)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_185.png: 640x448 1 Bottomwear, 76.7ms\n",
      "Speed: 2.0ms preprocess, 76.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jeans_185.png\n",
      "Annotations: [(1, 0.49578576534986496, 0.48726259358227253, 0.5138391405344009, 0.8868870995938778)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_467.png: 640x480 1 Bottomwear, 71.5ms\n",
      "Speed: 1.9ms preprocess, 71.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_faldas_467.png\n",
      "Annotations: [(1, 0.49343694001436234, 0.49384017288684845, 0.4902142137289047, 0.7474759519100189)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_2151.png: 640x448 1 Topwear, 1 Bottomwear, 2 Footwears, 70.4ms\n",
      "Speed: 1.9ms preprocess, 70.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jeans_2151.png\n",
      "Annotations: [(2, 0.27690354734659195, 0.8918858766555786, 0.16398195922374725, 0.15496408939361572), (2, 0.6932210326194763, 0.9121860265731812, 0.16740965843200684, 0.15762758255004883), (1, 0.4015568755567074, 0.44963476061820984, 0.604155607521534, 0.782586395740509)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_123.png: 640x640 1 Topwear, 91.1ms\n",
      "Speed: 2.7ms preprocess, 91.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_camisetas_123.png\n",
      "Annotations: [(0, 0.4858640432357788, 0.5120939780026674, 0.7016295194625854, 0.9337062500417233)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4282.png: 640x512 1 Bottomwear, 90.9ms\n",
      "Speed: 1.7ms preprocess, 90.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_4282.png\n",
      "Annotations: [(1, 0.523341104388237, 0.5538035780191422, 0.4471292793750763, 0.7063595950603485)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1976.png: 640x480 1 Bottomwear, 72.0ms\n",
      "Speed: 1.9ms preprocess, 72.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jeans_1976.png\n",
      "Annotations: [(1, 0.5049245804548264, 0.47365331649780273, 0.5709550678730011, 0.8464041948318481)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5145.png: 640x544 1 Topwear, 78.9ms\n",
      "Speed: 1.8ms preprocess, 78.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisetas_5145.png\n",
      "Annotations: [(0, 0.49153701215982437, 0.4941892623901367, 0.7121774405241013, 0.5961161851882935)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_756.png: 640x544 1 Bottomwear, 81.5ms\n",
      "Speed: 1.8ms preprocess, 81.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_pantalones_756.png\n",
      "Annotations: [(1, 0.5197722464799881, 0.5444305986166, 0.47717639803886414, 0.661302000284195)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_1195.png: 640x512 1 Topwear, 1 Bottomwear, 92.7ms\n",
      "Speed: 2.3ms preprocess, 92.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_1195.png\n",
      "Annotations: [(0, 0.6104728281497955, 0.6215647459030151, 0.6752280592918396, 0.7111551761627197)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5093.png: 640x512 1 Bottomwear, 80.1ms\n",
      "Speed: 1.8ms preprocess, 80.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_5093.png\n",
      "Annotations: [(1, 0.5041075050830841, 0.4947618991136551, 0.3997759222984314, 0.7003642022609711)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_206.png: 640x480 1 Topwear, 74.9ms\n",
      "Speed: 1.7ms preprocess, 74.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas_206.png\n",
      "Annotations: [(0, 0.494174562394619, 0.3912046402692795, 0.5047667771577835, 0.45457711815834045)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_275.png: 640x512 1 Topwear, 90.3ms\n",
      "Speed: 1.8ms preprocess, 90.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_275.png\n",
      "Annotations: [(0, 0.4989648088812828, 0.4797505885362625, 0.7034322768449783, 0.6355591714382172)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatos_1028.png: 640x512 3 Footwears, 80.6ms\n",
      "Speed: 1.8ms preprocess, 80.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatos_1028.png\n",
      "Annotations: [(2, 0.6193902492523193, 0.6528782248497009, 0.5018224716186523, 0.28809845447540283)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2472.png: 640x512 1 Topwear, 1 Bottomwear, 79.4ms\n",
      "Speed: 1.8ms preprocess, 79.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_2472.png\n",
      "Annotations: [(1, 0.4191724583506584, 0.7903225421905518, 0.4387073665857315, 0.22711873054504395), (0, 0.4643639996647835, 0.5018866509199142, 0.6015175431966782, 0.4994530975818634)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_3913.png: 640x544 1 Bottomwear, 82.3ms\n",
      "Speed: 1.7ms preprocess, 82.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_jeans_3913.png\n",
      "Annotations: [(1, 0.4995659291744232, 0.4967150539159775, 0.43860942125320435, 0.7912993729114532)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_750.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 90.4ms\n",
      "Speed: 1.8ms preprocess, 90.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_750.png\n",
      "Annotations: [(2, 0.5412040948867798, 0.8852224349975586, 0.1350153684616089, 0.15727698802947998), (2, 0.4279220551252365, 0.7542219161987305, 0.11688527464866638, 0.20172512531280518), (0, 0.4791003316640854, 0.10583023354411125, 0.6498941481113434, 0.209980346262455), (1, 0.4842728525400162, 0.4808986522257328, 0.38028571009635925, 0.7678343579173088)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_2025.png: 640x512 1 Topwear, 1 Bottomwear, 77.6ms\n",
      "Speed: 1.9ms preprocess, 77.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_2025.png\n",
      "Annotations: [(0, 0.5017007440328598, 0.565155379474163, 0.6747982800006866, 0.7443766742944717)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_3950.png: 640x512 1 Topwear, 1 Bottomwear, 82.2ms\n",
      "Speed: 1.9ms preprocess, 82.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_3950.png\n",
      "Annotations: [(0, 0.517826534807682, 0.5554510354995728, 0.6070687025785446, 0.6605193614959717)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_2504.png: 640x640 1 Footwear, 96.0ms\n",
      "Speed: 2.1ms preprocess, 96.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_2504.png\n",
      "Annotations: [(2, 0.5017123073339462, 0.5924095511436462, 0.8035890161991119, 0.3814648389816284)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_192.png: 640x512 1 Bottomwear, 96.4ms\n",
      "Speed: 1.9ms preprocess, 96.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_192.png\n",
      "Annotations: [(1, 0.6730504482984543, 0.4789017140865326, 0.43553033471107483, 0.6273834109306335)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatos_109.png: 640x480 1 Footwear, 73.1ms\n",
      "Speed: 1.9ms preprocess, 73.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_zapatos_109.png\n",
      "Annotations: [(2, 0.49584823846817017, 0.7549766302108765, 0.6499758958816528, 0.16551601886749268)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_1346.png: 640x640 1 Topwear, 92.9ms\n",
      "Speed: 2.4ms preprocess, 92.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_camisas_1346.png\n",
      "Annotations: [(0, 0.49895018339157104, 0.5121786780655384, 0.6893438100814819, 0.9756426438689232)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_5155.png: 640x512 1 Topwear, 1 Bottomwear, 1 Footwear, 76.0ms\n",
      "Speed: 1.8ms preprocess, 76.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_5155.png\n",
      "Annotations: [(2, 0.5043949782848358, 0.8885897994041443, 0.21852165460586548, 0.16906535625457764), (0, 0.47511689364910126, 0.13700613379478455, 0.34834328293800354, 0.2740122675895691), (1, 0.5223148167133331, 0.5290908664464951, 0.33835262060165405, 0.6453516781330109)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_744.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 91.8ms\n",
      "Speed: 1.8ms preprocess, 91.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_744.png\n",
      "Annotations: [(2, 0.5905046463012695, 0.884622722864151, 0.20061957836151123, 0.17678207159042358), (2, 0.38515739142894745, 0.8689026236534119, 0.2397395670413971, 0.18800139427185059), (1, 0.48976045846939087, 0.32340386509895325, 0.4854944944381714, 0.35986143350601196)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_1776.png: 640x512 1 Topwear, 1 Bottomwear, 75.7ms\n",
      "Speed: 1.9ms preprocess, 75.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_1776.png\n",
      "Annotations: [(1, 0.540162205696106, 0.8277537226676941, 0.5070743560791016, 0.32886970043182373), (0, 0.5331718921661377, 0.47778724133968353, 0.7513905763626099, 0.5772590935230255)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1296.png: 640x512 1 Bottomwear, 2 Footwears, 78.9ms\n",
      "Speed: 1.9ms preprocess, 78.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_1296.png\n",
      "Annotations: [(2, 0.4992358982563019, 0.7054381817579269, 0.9984717965126038, 0.41167178750038147), (1, 0.5, 0.2919720709323883, 1.0, 0.5839441418647766)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_2557.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 79.7ms\n",
      "Speed: 1.5ms preprocess, 79.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_2557.png\n",
      "Annotations: [(2, 0.38139142096042633, 0.8686591386795044, 0.11049619317054749, 0.11795258522033691), (2, 0.0699087530374527, 0.8714883029460907, 0.1398175060749054, 0.1269558072090149), (0, 0.3699156753718853, 0.18469640612602234, 0.5284157767891884, 0.3693928122520447), (1, 0.30151984095573425, 0.47681528329849243, 0.48092859983444214, 0.6627122163772583)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_2586.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 99.4ms\n",
      "Speed: 1.9ms preprocess, 99.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_2586.png\n",
      "Annotations: [(2, 0.6694527864456177, 0.9117444753646851, 0.0910271406173706, 0.12415683269500732), (2, 0.9087409973144531, 0.917901873588562, 0.09367716312408447, 0.13602304458618164), (0, 0.7673803567886353, 0.2443658411502838, 0.22987961769104004, 0.25387340784072876), (1, 0.7621893286705017, 0.5248025059700012, 0.27947962284088135, 0.37330806255340576)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5997.png: 640x544 1 Topwear, 80.8ms\n",
      "Speed: 1.9ms preprocess, 80.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_vestidos_5997.png\n",
      "Annotations: [(0, 0.5026704594492912, 0.5093518942594528, 0.5762281566858292, 0.670405775308609)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatos_1342.png: 640x512 1 Bottomwear, 2 Footwears, 79.7ms\n",
      "Speed: 1.8ms preprocess, 79.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatos_1342.png\n",
      "Annotations: [(2, 0.24313026294112206, 0.5027648359537125, 0.24066198617219925, 0.3978533446788788), (2, 0.6334982961416245, 0.6810767650604248, 0.39413490891456604, 0.2872636318206787), (1, 0.635460838675499, 0.2507314682006836, 0.6485364735126495, 0.5014629364013672)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_567.png: 416x640 1 Topwear, 72.2ms\n",
      "Speed: 1.9ms preprocess, 72.2ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Processing dataset_camisetas_567.png\n",
      "Annotations: [(0, 0.5010308623313904, 0.5249969027936459, 0.33293652534484863, 0.9145119860768318)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4278.png: 640x512 1 Topwear, 1 Bottomwear, 79.5ms\n",
      "Speed: 1.6ms preprocess, 79.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4278.png\n",
      "Annotations: [(1, 0.23591857589781284, 0.859211266040802, 0.4076656810939312, 0.281577467918396), (0, 0.4840390682220459, 0.48261815309524536, 0.9680781364440918, 0.6759805679321289)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_2951.png: 640x512 1 Topwear, 1 Bottomwear, 78.4ms\n",
      "Speed: 1.8ms preprocess, 78.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_2951.png\n",
      "Annotations: [(1, 0.38620948791503906, 0.8900166749954224, 0.5406798124313354, 0.21996665000915527), (0, 0.37687142565846443, 0.5225891023874283, 0.6118540391325951, 0.5698929727077484)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_236.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 94.7ms\n",
      "Speed: 1.9ms preprocess, 94.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_236.png\n",
      "Annotations: [(2, 0.7087289988994598, 0.9070802628993988, 0.08231526613235474, 0.15807050466537476), (2, 0.7720226943492889, 0.9305170476436615, 0.09619766473770142, 0.138965904712677), (1, 0.7273330390453339, 0.44986435770988464, 0.3046322464942932, 0.2417040467262268), (0, 0.6650066673755646, 0.2517043873667717, 0.2855655550956726, 0.2677263170480728)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_2100.png: 640x512 1 Topwear, 1 Bottomwear, 98.9ms\n",
      "Speed: 1.9ms preprocess, 98.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_2100.png\n",
      "Annotations: [(1, 0.4365650936961174, 0.879010796546936, 0.42634595930576324, 0.2314389944076538), (0, 0.3960824944078922, 0.4918505400419235, 0.6403888985514641, 0.664137989282608)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_1595.png: 640x512 2 Topwears, 1 Bottomwear, 2 Footwears, 79.8ms\n",
      "Speed: 1.9ms preprocess, 79.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_1595.png\n",
      "Annotations: [(2, 0.5844881236553192, 0.8210220634937286, 0.08775454759597778, 0.14795225858688354), (2, 0.831039309501648, 0.8256751000881195, 0.14316058158874512, 0.129818856716156), (1, 0.5778045952320099, 0.39416104555130005, 0.31242507696151733, 0.19887161254882812), (0, 0.5612255781888962, 0.27284275740385056, 0.3953264057636261, 0.34087373316287994)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_4035.png: 640x640 1 Footwear, 95.6ms\n",
      "Speed: 2.0ms preprocess, 95.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_4035.png\n",
      "Annotations: [(2, 0.5021582096815109, 0.582218736410141, 0.8190094530582428, 0.38123422861099243)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_1671.png: 640x512 1 Bottomwear, 2 Footwears, 90.9ms\n",
      "Speed: 1.9ms preprocess, 90.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_1671.png\n",
      "Annotations: [(2, 0.599330723285675, 0.8586126267910004, 0.11077344417572021, 0.10322707891464233), (2, 0.8548437356948853, 0.9072689116001129, 0.1978689432144165, 0.12978583574295044), (1, 0.6751937121152878, 0.49751272797584534, 0.38466575741767883, 0.6945671439170837)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_701.png: 640x512 2 Footwears, 76.1ms\n",
      "Speed: 1.9ms preprocess, 76.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sandalias_701.png\n",
      "Annotations: [(2, 0.31146130338311195, 0.5757519751787186, 0.3922261521220207, 0.43950971961021423), (2, 0.6102132201194763, 0.6310740113258362, 0.5686467885971069, 0.4036133289337158)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2060.png: 640x640 1 Bottomwear, 96.9ms\n",
      "Speed: 2.5ms preprocess, 96.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_shorts_2060.png\n",
      "Annotations: [(1, 0.49583943001925945, 0.5531138479709625, 0.8872564770281315, 0.8232883810997009)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4754.png: 640x544 1 Topwear, 95.0ms\n",
      "Speed: 1.8ms preprocess, 95.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisetas_4754.png\n",
      "Annotations: [(0, 0.5117535889148712, 0.4918522909283638, 0.5119004845619202, 0.6006500571966171)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5184.png: 640x480 1 Bottomwear, 71.1ms\n",
      "Speed: 1.8ms preprocess, 71.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_pantalones_5184.png\n",
      "Annotations: [(1, 0.5026854574680328, 0.3323882818222046, 0.5001087784767151, 0.2434166669845581)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_458.png: 640x640 1 Bottomwear, 93.1ms\n",
      "Speed: 2.5ms preprocess, 93.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_shorts_458.png\n",
      "Annotations: [(1, 0.49517540633678436, 0.500898003578186, 0.7819109261035919, 0.8989162445068359)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5850.png: 640x544 1 Topwear, 94.7ms\n",
      "Speed: 1.8ms preprocess, 94.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_vestidos_5850.png\n",
      "Annotations: [(0, 0.500746563076973, 0.492952611297369, 0.4478789269924164, 0.7781581357121468)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_302.png: 640x640 1 Bottomwear, 91.1ms\n",
      "Speed: 2.6ms preprocess, 91.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_shorts_302.png\n",
      "Annotations: [(1, 0.4956294894218445, 0.5063161998987198, 0.6257848739624023, 0.9641201198101044)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_2421.png: 640x512 1 Bottomwear, 2 Footwears, 79.5ms\n",
      "Speed: 1.9ms preprocess, 79.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_2421.png\n",
      "Annotations: [(2, 0.4318133741617203, 0.7613121867179871, 0.1140190064907074, 0.14346039295196533), (2, 0.3071606457233429, 0.8686428666114807, 0.11491662263870239, 0.17313003540039062), (1, 0.36740078777074814, 0.39313679933547974, 0.37166889011859894, 0.6934131383895874)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_33.png: 640x512 1 Bottomwear, 88.1ms\n",
      "Speed: 1.8ms preprocess, 88.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_33.png\n",
      "Annotations: [(1, 0.5038901120424271, 0.5025324821472168, 0.3698650300502777, 0.9949350357055664)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1385.png: 640x512 1 Topwear, 2 Footwears, 76.1ms\n",
      "Speed: 1.6ms preprocess, 76.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_1385.png\n",
      "Annotations: [(2, 0.4939604550600052, 0.8199181258678436, 0.09311315417289734, 0.12928563356399536), (2, 0.22485799342393875, 0.8169815540313721, 0.10369126498699188, 0.13300108909606934), (0, 0.4245740920305252, 0.258419968187809, 0.2664491832256317, 0.21392326056957245), (1, 0.46372921764850616, 0.506472259759903, 0.4325738847255707, 0.40537816286087036), (0, 0.4637543186545372, 0.4319911301136017, 0.4523404389619827, 0.5649535059928894)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_82.png: 640x480 1 Bottomwear, 68.9ms\n",
      "Speed: 1.6ms preprocess, 68.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jeans_82.png\n",
      "Annotations: [(1, 0.49658194929361343, 0.5009687691926956, 0.5026282519102097, 0.9772129952907562)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_2705.png: 640x480 1 Topwear, 82.0ms\n",
      "Speed: 1.9ms preprocess, 82.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_sudaderas_2705.png\n",
      "Annotations: [(0, 0.49268211610615253, 0.4529244750738144, 0.8877796791493893, 0.8492536842823029)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_358.png: 640x448 1 Topwear, 67.7ms\n",
      "Speed: 1.4ms preprocess, 67.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jerseys_358.png\n",
      "Annotations: [(0, 0.5071043949574232, 0.49631088972091675, 0.9380424059927464, 0.8202699422836304)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_2920.png: 640x512 1 Topwear, 1 Bottomwear, 79.3ms\n",
      "Speed: 1.9ms preprocess, 79.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_2920.png\n",
      "Annotations: [(0, 0.6901770234107971, 0.44598279893398285, 0.4824252128601074, 0.3922155201435089), (1, 0.6609791815280914, 0.7899665832519531, 0.476685106754303, 0.4072779417037964)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_551.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 86.5ms\n",
      "Speed: 1.8ms preprocess, 86.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_551.png\n",
      "Annotations: [(2, 0.4645303934812546, 0.8581464290618896, 0.1312430202960968, 0.1248314380645752), (2, 0.5685189664363861, 0.7586363255977631, 0.11182111501693726, 0.16157037019729614), (1, 0.5019198358058929, 0.4308949839323759, 0.363919198513031, 0.7502684332430363)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_826.png: 640x512 1 Topwear, 2 Footwears, 79.5ms\n",
      "Speed: 1.9ms preprocess, 79.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_826.png\n",
      "Annotations: [(2, 0.5383705198764801, 0.9337803721427917, 0.11598652601242065, 0.07767367362976074), (2, 0.3725663870573044, 0.9009922742843628, 0.12546369433403015, 0.09480249881744385), (1, 0.5084031373262405, 0.5258610397577286, 0.31616780161857605, 0.7794110476970673)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_773.png: 640x512 1 Topwear, 1 Bottomwear, 79.9ms\n",
      "Speed: 1.9ms preprocess, 79.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_773.png\n",
      "Annotations: [(0, 0.48337656259536743, 0.530133381485939, 0.5392857789993286, 0.6633283793926239)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_550.png: 640x512 1 Bottomwear, 2 Footwears, 88.3ms\n",
      "Speed: 1.8ms preprocess, 88.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_550.png\n",
      "Annotations: [(2, 0.5714607238769531, 0.8555275201797485, 0.15321719646453857, 0.1904202699661255), (2, 0.4132128357887268, 0.7034286856651306, 0.14979785680770874, 0.2102043628692627), (1, 0.49055546522140503, 0.2168586179614067, 0.47882699966430664, 0.32226504385471344)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatos_415.png: 640x512 1 Bottomwear, 2 Footwears, 77.6ms\n",
      "Speed: 1.8ms preprocess, 77.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatos_415.png\n",
      "Annotations: [(2, 0.7124360501766205, 0.7122401595115662, 0.26872652769088745, 0.27005863189697266), (2, 0.3380616046488285, 0.6528111696243286, 0.5136130377650261, 0.2535024881362915), (1, 0.6035741716623306, 0.2996439039707184, 0.7275713384151459, 0.5992878079414368)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_2656.png: 640x512 1 Topwear, 1 Bottomwear, 77.6ms\n",
      "Speed: 1.9ms preprocess, 77.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_2656.png\n",
      "Annotations: [(1, 0.577688455581665, 0.9005956649780273, 0.4113060235977173, 0.18376028537750244), (0, 0.5859918743371964, 0.5523557662963867, 0.7219745814800262, 0.6555434465408325)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_2357.png: 640x512 1 Bottomwear, 2 Footwears, 87.7ms\n",
      "Speed: 1.8ms preprocess, 87.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_2357.png\n",
      "Annotations: [(2, 0.20390988886356354, 0.5822205245494843, 0.4078197777271271, 0.2234700322151184), (2, 0.5209113508462906, 0.6817852854728699, 0.6717035472393036, 0.34562230110168457), (1, 0.3839814364910126, 0.26746290922164917, 0.7679628729820251, 0.5101304054260254)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1247.png: 640x640 1 Topwear, 1 Bottomwear, 96.0ms\n",
      "Speed: 2.0ms preprocess, 96.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_sudaderas_1247.png\n",
      "Annotations: [(0, 0.49932438135147095, 0.578156366944313, 0.6245365142822266, 0.8004898726940155)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_866.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 78.6ms\n",
      "Speed: 1.9ms preprocess, 78.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_866.png\n",
      "Annotations: [(2, 0.29007066041231155, 0.8209024369716644, 0.2829449623823166, 0.1573008894920349), (2, 0.6614262759685516, 0.7591042220592499, 0.2707147002220154, 0.16465646028518677), (0, 0.48660050332546234, 0.06525613530538976, 0.4237113296985626, 0.11845093639567494), (1, 0.48138001561164856, 0.18030522391200066, 0.3753747344017029, 0.22956732660531998)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_2972.png: 640x544 1 Bottomwear, 93.0ms\n",
      "Speed: 1.7ms preprocess, 93.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_jeans_2972.png\n",
      "Annotations: [(1, 0.5053250789642334, 0.498486015945673, 0.40213680267333984, 0.7987094447016716)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_4239.png: 640x512 1 Topwear, 1 Bottomwear, 79.6ms\n",
      "Speed: 1.9ms preprocess, 79.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_4239.png\n",
      "Annotations: [(1, 0.3152748942375183, 0.8346952497959137, 0.45576930046081543, 0.31048232316970825), (0, 0.3390510380268097, 0.5546566396951675, 0.6781020760536194, 0.7046954333782196)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_517.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 75.4ms\n",
      "Speed: 1.7ms preprocess, 75.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_517.png\n",
      "Annotations: [(2, 0.42818665504455566, 0.8267488777637482, 0.11765611171722412, 0.13507729768753052), (2, 0.5618106126785278, 0.7619994282722473, 0.11490082740783691, 0.16727328300476074), (1, 0.48451855778694153, 0.4351918250322342, 0.35623008012771606, 0.6833389699459076)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_1040.png: 640x512 2 Topwears, 1 Bottomwear, 90.2ms\n",
      "Speed: 1.9ms preprocess, 90.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_1040.png\n",
      "Annotations: [(0, 0.374136820435524, 0.2427878975868225, 0.15904483199119568, 0.20073235034942627), (1, 0.3061138801276684, 0.6215314567089081, 0.4843335524201393, 0.5458219647407532)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_485.png: 640x512 3 Topwears, 1 Bottomwear, 76.3ms\n",
      "Speed: 1.5ms preprocess, 76.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_485.png\n",
      "Annotations: [(0, 0.36198221147060394, 0.8612862229347229, 0.28543856739997864, 0.24879074096679688), (0, 0.6680411398410797, 0.8638311624526978, 0.30542582273483276, 0.237371563911438), (0, 0.21905067563056946, 0.44103799760341644, 0.4381013512611389, 0.513260155916214)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_230.png: 640x544 1 Topwear, 1 Bottomwear, 80.5ms\n",
      "Speed: 1.8ms preprocess, 80.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_monos_230.png\n",
      "Annotations: [(0, 0.4944143444299698, 0.5, 0.4725603759288788, 1.0)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_4472.png: 640x480 1 Topwear, 86.5ms\n",
      "Speed: 1.8ms preprocess, 86.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas-y-blusas_4472.png\n",
      "Annotations: [(0, 0.4814928472042084, 0.4449763745069504, 0.6140521168708801, 0.6440993845462799)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_661.png: 640x448 1 Bottomwear, 69.2ms\n",
      "Speed: 1.2ms preprocess, 69.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_trajes_661.png\n",
      "Annotations: [(1, 0.49370384216308594, 0.49274586141109467, 0.7274013757705688, 0.9217672646045685)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_4062.png: 640x512 1 Topwear, 1 Bottomwear, 81.2ms\n",
      "Speed: 1.9ms preprocess, 81.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_4062.png\n",
      "Annotations: [(1, 0.5126695483922958, 0.886981189250946, 0.435560017824173, 0.2260376214981079), (0, 0.5319164916872978, 0.5157667770981789, 0.6350015550851822, 0.6880946606397629)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_3720.png: 640x512 2 Topwears, 2 Bottomwears, 4 Footwears, 86.0ms\n",
      "Speed: 1.9ms preprocess, 86.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_3720.png\n",
      "Annotations: [(2, 0.2407289817929268, 0.8735147714614868, 0.11713926494121552, 0.13973629474639893), (2, 0.6976234316825867, 0.8863267600536346, 0.11238813400268555, 0.1543704867362976), (2, 0.8466939628124237, 0.8002302944660187, 0.11090582609176636, 0.1599079966545105), (2, 0.12385403737425804, 0.7545439004898071, 0.11696506291627884, 0.16666781902313232), (0, 0.7624845206737518, 0.12415456026792526, 0.4054529070854187, 0.24549038708209991), (1, 0.7650111019611359, 0.331847608089447, 0.38926631212234497, 0.27699142694473267), (1, 0.22455455735325813, 0.298056922852993, 0.3992576226592064, 0.27555103600025177)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_1303.png: 640x512 1 Bottomwear, 2 Footwears, 80.5ms\n",
      "Speed: 1.9ms preprocess, 80.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_1303.png\n",
      "Annotations: [(2, 0.5725433230400085, 0.776544451713562, 0.12961840629577637, 0.18279457092285156), (2, 0.5210752189159393, 0.9072990417480469, 0.1611972451210022, 0.1798853874206543), (1, 0.5333443582057953, 0.26249057054519653, 0.4645693898200989, 0.3916558623313904)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_1672.png: 640x448 1 Topwear, 1 Bottomwear, 69.9ms\n",
      "Speed: 2.3ms preprocess, 69.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_trajes_1672.png\n",
      "Annotations: [(1, 0.5060167610645294, 0.8188808262348175, 0.4919183850288391, 0.362238347530365), (0, 0.49905822426080704, 0.5479882806539536, 0.7541488856077194, 0.623576432466507)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_131.png: 640x544 1 Topwear, 99.8ms\n",
      "Speed: 1.8ms preprocess, 99.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_jerseys_131.png\n",
      "Annotations: [(0, 0.5, 0.7034230530261993, 1.0, 0.5931538939476013)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_137.png: 640x512 2 Footwears, 76.9ms\n",
      "Speed: 1.9ms preprocess, 76.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_137.png\n",
      "Annotations: [(2, 0.5216108672320843, 0.3704928904771805, 0.7946886792778969, 0.28962406516075134), (2, 0.5807073190808296, 0.6242268830537796, 0.830806240439415, 0.44828900694847107)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4944.png: 640x512 1 Topwear, 1 Bottomwear, 77.0ms\n",
      "Speed: 1.8ms preprocess, 77.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_4944.png\n",
      "Annotations: [(0, 0.3241015379317105, 0.5473991632461548, 0.6285752644762397, 0.7158962488174438)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5635.png: 640x512 2 Topwears, 1 Bottomwear, 2 Footwears, 88.9ms\n",
      "Speed: 1.9ms preprocess, 88.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_5635.png\n",
      "Annotations: [(2, 0.054423220455646515, 0.9850379824638367, 0.10884644091129303, 0.02992403507232666), (0, 0.1836291402578354, 0.4373197704553604, 0.3672582805156708, 0.5191385447978973)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4673.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 76.4ms\n",
      "Speed: 1.9ms preprocess, 76.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_4673.png\n",
      "Annotations: [(2, 0.4787749648094177, 0.8385422229766846, 0.1273096799850464, 0.11596548557281494), (2, 0.1439545415341854, 0.833247721195221, 0.16010356694459915, 0.10151708126068115), (0, 0.20584877766668797, 0.1179007738828659, 0.2898682467639446, 0.2358015477657318), (1, 0.283442972227931, 0.49229641258716583, 0.4606971777975559, 0.6150959432125092)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3073.png: 640x512 1 Topwear, 2 Footwears, 81.3ms\n",
      "Speed: 1.9ms preprocess, 81.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_3073.png\n",
      "Annotations: [(2, 0.4099803566932678, 0.9119981527328491, 0.0841253399848938, 0.1335831880569458), (2, 0.6766015291213989, 0.9142850339412689, 0.09036111831665039, 0.12860065698623657), (0, 0.5075386017560959, 0.5799307152628899, 0.39568641781806946, 0.66490139067173)]\n",
      "Detections: ['original_image', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5010.png: 640x512 1 Topwear, 2 Footwears, 90.3ms\n",
      "Speed: 1.9ms preprocess, 90.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_5010.png\n",
      "Annotations: [(2, 0.3802555203437805, 0.8876676559448242, 0.09518826007843018, 0.1246488094329834), (2, 0.6371998190879822, 0.8788620829582214, 0.0893557071685791, 0.13934791088104248), (0, 0.5562522560358047, 0.43059633672237396, 0.36063477396965027, 0.5311267673969269)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_3544.png: 640x512 1 Bottomwear, 2 Footwears, 74.4ms\n",
      "Speed: 1.8ms preprocess, 74.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_3544.png\n",
      "Annotations: [(2, 0.4397943615913391, 0.6738688945770264, 0.11161679029464722, 0.19643521308898926), (2, 0.554410994052887, 0.8685375154018402, 0.14298641681671143, 0.19049447774887085), (1, 0.5188377648591995, 0.4406447857618332, 0.3939034640789032, 0.7286860048770905)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5374.png: 640x512 1 Topwear, 2 Footwears, 80.7ms\n",
      "Speed: 1.9ms preprocess, 80.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_5374.png\n",
      "Annotations: [(2, 0.7228875756263733, 0.860305666923523, 0.10322356224060059, 0.14109265804290771), (2, 0.5184589326381683, 0.8562633991241455, 0.13644224405288696, 0.1426471471786499), (0, 0.7169584333896637, 0.4821304529905319, 0.3743550181388855, 0.6331442892551422)]\n",
      "Detections: ['original_image', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4439.png: 640x512 1 Topwear, 1 Bottomwear, 89.7ms\n",
      "Speed: 1.9ms preprocess, 89.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4439.png\n",
      "Annotations: [(1, 0.4001925587654114, 0.8748748004436493, 0.3690067529678345, 0.2502503991127014), (0, 0.3884262144565582, 0.4901917278766632, 0.5768846869468689, 0.6311711668968201)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_1754.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 79.5ms\n",
      "Speed: 1.9ms preprocess, 79.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_1754.png\n",
      "Annotations: [(2, 0.34084902703762054, 0.8868299126625061, 0.1068333089351654, 0.11122071743011475), (2, 0.06593058258295059, 0.8727012276649475, 0.13186116516590118, 0.10582196712493896), (1, 0.29789068549871445, 0.4937537759542465, 0.2845185548067093, 0.2284250557422638), (0, 0.2833786942064762, 0.35213348269462585, 0.377817265689373, 0.3314540982246399)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_alpargatas_90.png: 640x512 2 Footwears, 78.5ms\n",
      "Speed: 1.8ms preprocess, 78.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_alpargatas_90.png\n",
      "Annotations: [(2, 0.6255640089511871, 0.6426177620887756, 0.2440357804298401, 0.4196056127548218), (2, 0.3133057504892349, 0.5088893175125122, 0.2537064850330353, 0.5277760028839111)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1981.png: 640x512 1 Bottomwear, 2 Footwears, 89.1ms\n",
      "Speed: 1.9ms preprocess, 89.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_1981.png\n",
      "Annotations: [(2, 0.231031596660614, 0.6319994330406189, 0.462063193321228, 0.2131485939025879), (2, 0.5619916841387749, 0.709138035774231, 0.6762243658304214, 0.33302903175354004), (1, 0.4033528119325638, 0.2912950813770294, 0.6638469398021698, 0.5473738312721252)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_3067.png: 640x512 1 Bottomwear, 79.9ms\n",
      "Speed: 1.8ms preprocess, 79.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_3067.png\n",
      "Annotations: [(1, 0.5010227486491203, 0.4958716630935669, 0.6350287348031998, 0.8764892816543579)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_3636.png: 640x544 1 Topwear, 1 Bottomwear, 2 Footwears, 93.3ms\n",
      "Speed: 2.6ms preprocess, 93.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_jeans_3636.png\n",
      "Annotations: [(2, 0.5714265555143356, 0.9320811927318573, 0.22646990418434143, 0.1221044659614563), (2, 0.37439727783203125, 0.926394522190094, 0.1944483518600464, 0.14619827270507812), (1, 0.5103735476732254, 0.48033955693244934, 0.35872432589530945, 0.822492778301239)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_2554.png: 640x512 1 Topwear, 79.4ms\n",
      "Speed: 1.8ms preprocess, 79.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_2554.png\n",
      "Annotations: [(0, 0.4973793029785156, 0.4469469338655472, 0.6426225900650024, 0.5351704061031342)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_1307.png: 640x448 1 Topwear, 73.0ms\n",
      "Speed: 1.3ms preprocess, 73.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jerseys_1307.png\n",
      "Annotations: [(0, 0.497118903324008, 0.4977017045021057, 0.9103053547441959, 0.7143446207046509)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_5202.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 105.5ms\n",
      "Speed: 2.0ms preprocess, 105.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_5202.png\n",
      "Annotations: [(2, 0.3172401040792465, 0.8664405345916748, 0.08992961049079895, 0.12509608268737793), (2, 0.46532057225704193, 0.927257627248764, 0.09296181797981262, 0.14001458883285522), (1, 0.3349427580833435, 0.6238950788974762, 0.3166857957839966, 0.5068559050559998), (0, 0.3222916014492512, 0.2886945568025112, 0.43054427951574326, 0.41922975331544876)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1329.png: 640x512 1 Bottomwear, 83.8ms\n",
      "Speed: 1.8ms preprocess, 83.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_1329.png\n",
      "Annotations: [(1, 0.5085438638925552, 0.49609728157520294, 0.6190470159053802, 0.841354101896286)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_3675.png: 640x448 1 Topwear, 76.0ms\n",
      "Speed: 1.2ms preprocess, 76.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_3675.png\n",
      "Annotations: [(0, 0.4976853933185339, 0.4922502189874649, 0.871979434043169, 0.8219742476940155)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_1525.png: 640x512 1 Bottomwear, 102.9ms\n",
      "Speed: 1.8ms preprocess, 102.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_1525.png\n",
      "Annotations: [(1, 0.4865168482065201, 0.32154417783021927, 0.4483959376811981, 0.24694369733333588)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_polos_52.png: 640x480 1 Topwear, 79.5ms\n",
      "Speed: 1.9ms preprocess, 79.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_polos_52.png\n",
      "Annotations: [(0, 0.5153115279972553, 0.36798471212387085, 0.7889369949698448, 0.49390995502471924)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_619.png: 640x512 1 Topwear, 105.6ms\n",
      "Speed: 2.0ms preprocess, 105.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_619.png\n",
      "Annotations: [(0, 0.4970887266099453, 0.48282448947429657, 0.8057664707303047, 0.6693123877048492)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1987.png: 640x512 1 Bottomwear, 2 Footwears, 78.7ms\n",
      "Speed: 2.0ms preprocess, 78.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_1987.png\n",
      "Annotations: [(2, 0.7098556160926819, 0.705215573310852, 0.27983641624450684, 0.31691861152648926), (2, 0.37289847433567047, 0.5997013002634048, 0.40824005007743835, 0.3661160171031952), (1, 0.5877827033400536, 0.27177734673023224, 0.7018690854310989, 0.5330973565578461)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_3937.png: 640x544 1 Topwear, 81.5ms\n",
      "Speed: 2.2ms preprocess, 81.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisetas_3937.png\n",
      "Annotations: [(0, 0.49874002765864134, 0.4932813495397568, 0.9468524251133204, 0.8197049200534821)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_3756.png: 640x512 1 Topwear, 91.0ms\n",
      "Speed: 1.8ms preprocess, 91.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_3756.png\n",
      "Annotations: [(0, 0.5096219852566719, 0.4792543202638626, 0.7386319488286972, 0.6219051778316498)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_0.png: 640x512 1 Bottomwear, 82.8ms\n",
      "Speed: 1.8ms preprocess, 82.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_0.png\n",
      "Annotations: [(1, 0.5002856701612473, 0.5077629555016756, 0.6018021404743195, 0.9013101123273373)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1736.png: 640x512 1 Topwear, 79.2ms\n",
      "Speed: 1.9ms preprocess, 79.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_1736.png\n",
      "Annotations: [(0, 0.5020701624453068, 0.4999312609434128, 0.7829250618815422, 0.7915607988834381)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_179.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 92.7ms\n",
      "Speed: 1.9ms preprocess, 92.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_179.png\n",
      "Annotations: [(2, 0.5609178245067596, 0.8798161447048187, 0.16263240575790405, 0.16268855333328247), (2, 0.22645798325538635, 0.8547559678554535, 0.2386322021484375, 0.13178008794784546), (0, 0.40610624849796295, 0.1395682394504547, 0.5974675118923187, 0.2662317752838135), (1, 0.41559868305921555, 0.5209851264953613, 0.45044519007205963, 0.606808066368103)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatos_1253.png: 640x512 2 Footwears, 80.7ms\n",
      "Speed: 1.9ms preprocess, 80.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatos_1253.png\n",
      "Annotations: [(2, 0.6759437024593353, 0.622879147529602, 0.28140193223953247, 0.26221704483032227), (2, 0.366507887840271, 0.6338130533695221, 0.4783332347869873, 0.31340450048446655)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botas_102.png: 640x544 1 Footwear, 83.5ms\n",
      "Speed: 1.8ms preprocess, 83.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_botas_102.png\n",
      "Annotations: [(2, 0.49157366529107094, 0.48176276683807373, 0.9203798100352287, 0.7219741344451904)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5934.png: 640x544 1 Topwear, 96.9ms\n",
      "Speed: 1.8ms preprocess, 96.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_vestidos_5934.png\n",
      "Annotations: [(0, 0.5002958551049232, 0.49519775807857513, 0.6880292147397995, 0.6365397274494171)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4323.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 80.3ms\n",
      "Speed: 1.9ms preprocess, 80.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_4323.png\n",
      "Annotations: [(2, 0.47041749954223633, 0.8667477965354919, 0.16395199298858643, 0.11618494987487793), (2, 0.24187462776899338, 0.8371769189834595, 0.20003141462802887, 0.104714035987854), (0, 0.41302814334630966, 0.2066786214709282, 0.41184504330158234, 0.39596618711948395), (1, 0.3682936578989029, 0.5633429288864136, 0.3977973163127899, 0.538875937461853)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_3884.png: 640x512 1 Topwear, 1 Bottomwear, 96.9ms\n",
      "Speed: 1.9ms preprocess, 96.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_3884.png\n",
      "Annotations: [(1, 0.6276371330022812, 0.9160983860492706, 0.5267665684223175, 0.16780322790145874), (0, 0.5318717285990715, 0.5535506159067154, 0.7257983833551407, 0.7609409987926483)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4364.png: 640x448 1 Topwear, 1 Bottomwear, 70.7ms\n",
      "Speed: 1.6ms preprocess, 70.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisetas_4364.png\n",
      "Annotations: [(1, 0.42893992364406586, 0.9102501273155212, 0.5577533543109894, 0.17777085304260254), (0, 0.4271489940583706, 0.5897557884454727, 0.6997332647442818, 0.6383993327617645)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_1420.png: 640x640 1 Topwear, 109.3ms\n",
      "Speed: 3.2ms preprocess, 109.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_camisetas_1420.png\n",
      "Annotations: [(0, 0.4927845597267151, 0.500480592250824, 0.4639807939529419, 0.9559299945831299)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_203.png: 640x512 1 Topwear, 1 Bottomwear, 79.7ms\n",
      "Speed: 1.9ms preprocess, 79.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_203.png\n",
      "Annotations: [(1, 0.4992554932832718, 0.9088372588157654, 0.3943328559398651, 0.17870962619781494), (0, 0.4844496473670006, 0.5618073865771294, 0.6417574435472488, 0.6797201782464981)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5321.png: 640x512 1 Topwear, 80.4ms\n",
      "Speed: 1.9ms preprocess, 80.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_5321.png\n",
      "Annotations: [(0, 0.7519773840904236, 0.5926814675331116, 0.49604523181915283, 0.7760249376296997)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_256.png: 640x544 1 Footwear, 96.0ms\n",
      "Speed: 1.8ms preprocess, 96.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_zapatillas_256.png\n",
      "Annotations: [(2, 0.4928283095359802, 0.6821905374526978, 0.669007420539856, 0.21938097476959229)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_1368.png: 640x512 1 Topwear, 1 Bottomwear, 79.8ms\n",
      "Speed: 1.9ms preprocess, 79.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_1368.png\n",
      "Annotations: [(1, 0.6200893223285675, 0.8766081035137177, 0.3764602541923523, 0.2467837929725647), (0, 0.612635537981987, 0.5527603626251221, 0.5497166216373444, 0.6456285715103149)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_2550.png: 640x448 1 Topwear, 1 Bottomwear, 84.9ms\n",
      "Speed: 1.7ms preprocess, 84.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_2550.png\n",
      "Annotations: [(1, 0.49921658635139465, 0.8045302629470825, 0.9984331727027893, 0.39044189453125), (0, 0.465983122587204, 0.4943825900554657, 0.931966245174408, 0.47640854120254517)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_517.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 79.6ms\n",
      "Speed: 1.8ms preprocess, 79.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_517.png\n",
      "Annotations: [(2, 0.613370805978775, 0.8598777949810028, 0.13986629247665405, 0.13498836755752563), (2, 0.7488946914672852, 0.9252138733863831, 0.14235615730285645, 0.1495722532272339), (0, 0.6165411174297333, 0.2249189130961895, 0.2027687430381775, 0.23398754745721817), (1, 0.6244504451751709, 0.5058529078960419, 0.2690720558166504, 0.3759458661079407)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_358.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 78.8ms\n",
      "Speed: 1.9ms preprocess, 78.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_358.png\n",
      "Annotations: [(2, 0.4905673861503601, 0.91179358959198, 0.11635994911193848, 0.11209452152252197), (0, 0.533995121717453, 0.2915806509554386, 0.3232031464576721, 0.36689286679029465), (1, 0.5018947273492813, 0.6253274530172348, 0.2383551299571991, 0.5128319561481476)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_3287.png: 640x512 1 Bottomwear, 2 Footwears, 91.4ms\n",
      "Speed: 1.9ms preprocess, 91.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_3287.png\n",
      "Annotations: [(2, 0.34275469183921814, 0.6797726452350616, 0.5241679549217224, 0.2698165774345398), (2, 0.7249975204467773, 0.624626487493515, 0.44569826126098633, 0.3977046608924866), (1, 0.4359889551997185, 0.2641599476337433, 0.6878218799829483, 0.5283198952674866)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_2170.png: 640x448 1 Topwear, 69.1ms\n",
      "Speed: 1.3ms preprocess, 69.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_vestidos_2170.png\n",
      "Annotations: [(0, 0.5239663273096085, 0.5698085576295853, 0.6130981147289276, 0.6471360623836517)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_2446.png: 640x544 1 Topwear, 83.7ms\n",
      "Speed: 1.8ms preprocess, 83.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisas-y-blusas_2446.png\n",
      "Annotations: [(0, 0.502370223402977, 0.5056511089205742, 0.4946940243244171, 0.5433960109949112)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_290.png: 640x640 1 Topwear, 106.1ms\n",
      "Speed: 2.0ms preprocess, 106.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_camisetas_290.png\n",
      "Annotations: [(0, 0.48842965066432953, 0.4946485459804535, 0.6759670078754425, 0.9437928795814514)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4309.png: 640x512 1 Topwear, 1 Bottomwear, 79.9ms\n",
      "Speed: 1.8ms preprocess, 79.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4309.png\n",
      "Annotations: [(1, 0.26827283948659897, 0.8732815384864807, 0.3747248202562332, 0.24927198886871338), (0, 0.2853849020320922, 0.5043453425168991, 0.5668564862571657, 0.6204811632633209)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botas_49.png: 640x480 1 Footwear, 87.6ms\n",
      "Speed: 1.5ms preprocess, 87.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_botas_49.png\n",
      "Annotations: [(2, 0.5042367959395051, 0.4935888648033142, 0.9915264081209898, 0.4862346649169922)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_81.png: 640x512 1 Topwear, 82.4ms\n",
      "Speed: 1.7ms preprocess, 82.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_81.png\n",
      "Annotations: [(0, 0.5036502629518509, 0.39443962275981903, 0.44394180178642273, 0.45620039105415344)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_1794.png: 640x512 1 Bottomwear, 80.7ms\n",
      "Speed: 1.8ms preprocess, 80.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_1794.png\n",
      "Annotations: [(1, 0.5012560337781906, 0.5017671138048172, 0.47535088658332825, 0.7578328549861908)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_3461.png: 640x480 1 Bottomwear, 87.9ms\n",
      "Speed: 1.8ms preprocess, 87.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jeans_3461.png\n",
      "Annotations: [(1, 0.4899607300758362, 0.49900318682193756, 0.5211833715438843, 0.7532088458538055)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5114.png: 640x640 1 Bottomwear, 2 Footwears, 95.8ms\n",
      "Speed: 2.0ms preprocess, 95.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_pantalones_5114.png\n",
      "Annotations: [(2, 0.6100145280361176, 0.8890290856361389, 0.11404472589492798, 0.14067375659942627), (2, 0.3202010616660118, 0.8949150741100311, 0.19512267410755157, 0.1528875231742859), (1, 0.5659453868865967, 0.20776855200529099, 0.34144139289855957, 0.29594410955905914)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_725.png: 640x512 1 Topwear, 78.2ms\n",
      "Speed: 1.8ms preprocess, 78.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_725.png\n",
      "Annotations: [(0, 0.48862524330616, 0.4750792384147644, 0.7088217437267303, 0.6373002529144287)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_402.png: 640x512 1 Topwear, 1 Bottomwear, 96.5ms\n",
      "Speed: 1.7ms preprocess, 96.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_402.png\n",
      "Annotations: [(1, 0.5348413437604904, 0.6460214257240295, 0.22670891880989075, 0.5252982378005981), (0, 0.5354607999324799, 0.32152896374464035, 0.3856329321861267, 0.35361553728580475)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2688.png: 640x512 1 Bottomwear, 83.0ms\n",
      "Speed: 1.8ms preprocess, 83.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_2688.png\n",
      "Annotations: [(1, 0.6682694107294083, 0.5984168350696564, 0.45511433482170105, 0.5723665356636047)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5666.png: 640x480 1 Topwear, 72.6ms\n",
      "Speed: 1.9ms preprocess, 72.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_5666.png\n",
      "Annotations: [(0, 0.4980046860873699, 0.4736569672822952, 0.8479274287819862, 0.879870742559433)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_2775.png: 640x480 1 Topwear, 74.0ms\n",
      "Speed: 1.8ms preprocess, 74.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisetas_2775.png\n",
      "Annotations: [(0, 0.5016101989895105, 0.5273884385824203, 0.8786873035132885, 0.8476088345050812)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_polos_601.png: 640x480 1 Topwear, 88.4ms\n",
      "Speed: 1.8ms preprocess, 88.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_polos_601.png\n",
      "Annotations: [(0, 0.5116840377449989, 0.36672206223011017, 0.680929109454155, 0.5623455941677094)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5201.png: 640x448 1 Topwear, 1 Bottomwear, 67.6ms\n",
      "Speed: 2.1ms preprocess, 67.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_5201.png\n",
      "Annotations: [(1, 0.42415157705545425, 0.8342393636703491, 0.5987495630979538, 0.33152127265930176)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_2489.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 96.6ms\n",
      "Speed: 1.9ms preprocess, 96.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_2489.png\n",
      "Annotations: [(2, 0.6584064960479736, 0.8878803253173828, 0.11569035053253174, 0.1350771188735962), (2, 0.9266193211078644, 0.9167656302452087, 0.10484129190444946, 0.15805459022521973), (0, 0.7398684620857239, 0.1899714544415474, 0.2688877582550049, 0.2550717443227768), (1, 0.7556639313697815, 0.5657356530427933, 0.3879486322402954, 0.5777879655361176)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_3677.png: 640x512 1 Topwear, 77.6ms\n",
      "Speed: 1.8ms preprocess, 77.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_3677.png\n",
      "Annotations: [(0, 0.49610140919685364, 0.49856873974204063, 0.74583500623703, 0.7815335467457771)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_1704.png: 640x480 1 Topwear, 73.8ms\n",
      "Speed: 1.9ms preprocess, 73.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jerseys_1704.png\n",
      "Annotations: [(0, 0.504670113325119, 0.39395152032375336, 0.6205710768699646, 0.5409195721149445)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4818.png: 640x448 1 Topwear, 1 Bottomwear, 71.2ms\n",
      "Speed: 1.9ms preprocess, 71.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisetas_4818.png\n",
      "Annotations: [(1, 0.4561605229973793, 0.8741641640663147, 0.4391060322523117, 0.2516716718673706), (0, 0.42030640691518784, 0.5501431077718735, 0.57115538418293, 0.5916390717029572)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_68.png: 640x480 1 Bottomwear, 75.5ms\n",
      "Speed: 1.8ms preprocess, 75.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_pantalones_68.png\n",
      "Annotations: [(1, 0.5027623325586319, 0.49812276661396027, 0.5121276080608368, 0.9471023976802826)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_4717.png: 640x512 1 Topwear, 81.1ms\n",
      "Speed: 1.7ms preprocess, 81.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_4717.png\n",
      "Annotations: [(0, 0.49894024059176445, 0.48351553082466125, 0.8603187575936317, 0.6756234765052795)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_374.png: 640x640 1 Bottomwear, 112.2ms\n",
      "Speed: 3.5ms preprocess, 112.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_pantalones_374.png\n",
      "Annotations: [(1, 0.5068200826644897, 0.5012233108282089, 0.34142982959747314, 0.9620244801044464)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_690.png: 640x512 1 Bottomwear, 2 Footwears, 81.1ms\n",
      "Speed: 1.8ms preprocess, 81.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_690.png\n",
      "Annotations: [(2, 0.3241829052567482, 0.9058976769447327, 0.1706703156232834, 0.1678708791732788), (1, 0.37855853140354156, 0.4856848567724228, 0.3344763219356537, 0.6628457605838776)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_371.png: 640x512 2 Footwears, 93.2ms\n",
      "Speed: 1.8ms preprocess, 93.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sandalias_371.png\n",
      "Annotations: [(2, 0.3064728006720543, 0.6717730760574341, 0.416039302945137, 0.19305217266082764), (2, 0.6512902081012726, 0.6208974123001099, 0.3960840106010437, 0.37351417541503906)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1928.png: 640x480 1 Topwear, 75.6ms\n",
      "Speed: 1.8ms preprocess, 75.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jeans_1928.png\n",
      "Annotations: [(0, 0.5006749629974365, 0.5215634852647781, 0.8629124164581299, 0.84853395819664)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4137.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 89.1ms\n",
      "Speed: 1.8ms preprocess, 89.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4137.png\n",
      "Annotations: [(2, 0.6907411515712738, 0.7400909662246704, 0.15909987688064575, 0.23133528232574463), (2, 0.3723781704902649, 0.8281733393669128, 0.25397372245788574, 0.17980968952178955), (0, 0.4933634102344513, 0.08903299272060394, 0.5968765616416931, 0.17806598544120789), (1, 0.5042033046483994, 0.41383299231529236, 0.4843045771121979, 0.72488933801651)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_159.png: 640x512 1 Topwear, 82.2ms\n",
      "Speed: 1.8ms preprocess, 82.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_159.png\n",
      "Annotations: [(0, 0.4960981756448746, 0.48528558015823364, 0.4259805381298065, 0.903957724571228)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_4457.png: 640x480 1 Topwear, 85.4ms\n",
      "Speed: 2.3ms preprocess, 85.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas-y-blusas_4457.png\n",
      "Annotations: [(0, 0.49940062314271927, 0.32341866195201874, 0.5037126392126083, 0.4076215326786041)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_1262.png: 640x448 1 Topwear, 1 Bottomwear, 66.7ms\n",
      "Speed: 2.0ms preprocess, 66.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_1262.png\n",
      "Annotations: [(1, 0.4811672419309616, 0.8961505889892578, 0.46704164147377014, 0.20170223712921143), (0, 0.4829079210758209, 0.5848268270492554, 0.6384677290916443, 0.5343742370605469)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_807.png: 640x480 1 Bottomwear, 88.9ms\n",
      "Speed: 2.0ms preprocess, 88.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_trajes_807.png\n",
      "Annotations: [(1, 0.5068432539701462, 0.4750782698392868, 0.39108696579933167, 0.881248265504837)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_3075.png: 640x512 1 Bottomwear, 84.8ms\n",
      "Speed: 1.8ms preprocess, 84.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_3075.png\n",
      "Annotations: [(1, 0.7336690872907639, 0.5162233635783195, 0.4983716309070587, 0.5546947866678238)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_3442.png: 640x448 1 Topwear, 1 Bottomwear, 2 Footwears, 68.7ms\n",
      "Speed: 1.6ms preprocess, 68.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jeans_3442.png\n",
      "Annotations: [(2, 0.6398619711399078, 0.9446790218353271, 0.12043923139572144, 0.09934163093566895), (2, 0.28116007149219513, 0.9336070120334625, 0.23674258589744568, 0.08589595556259155), (0, 0.5200710892677307, 0.28747381269931793, 0.46469712257385254, 0.28935107588768005), (1, 0.48174823820590973, 0.6465597599744797, 0.4387306869029999, 0.5406152307987213)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_2616.png: 640x448 1 Bottomwear, 87.7ms\n",
      "Speed: 1.6ms preprocess, 87.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jeans_2616.png\n",
      "Annotations: [(1, 0.5077039003372192, 0.4944662619382143, 0.5515655279159546, 0.8963739536702633)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5431.png: 640x512 1 Topwear, 1 Bottomwear, 81.2ms\n",
      "Speed: 2.0ms preprocess, 81.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_5431.png\n",
      "Annotations: [(1, 0.2959794639609754, 0.7846556305885315, 0.5715032340958714, 0.2751840353012085), (0, 0.3273593485355377, 0.5092793256044388, 0.6547186970710754, 0.5652128159999847)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_164.png: 640x512 1 Topwear, 97.1ms\n",
      "Speed: 1.8ms preprocess, 97.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_164.png\n",
      "Annotations: [(0, 0.5064305812120438, 0.4793517515063286, 0.5242501199245453, 0.5102102905511856)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_3595.png: 640x512 1 Bottomwear, 78.8ms\n",
      "Speed: 1.9ms preprocess, 78.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_3595.png\n",
      "Annotations: [(1, 0.5048928707838058, 0.5038990378379822, 0.48894432187080383, 0.731651782989502)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1625.png: 640x640 1 Footwear, 111.3ms\n",
      "Speed: 2.1ms preprocess, 111.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_1625.png\n",
      "Annotations: [(2, 0.5002022832632065, 0.5598986148834229, 0.8073747456073761, 0.429607629776001)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_973.png: 640x512 1 Topwear, 1 Bottomwear, 81.9ms\n",
      "Speed: 1.9ms preprocess, 81.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_973.png\n",
      "Annotations: [(1, 0.32918529585003853, 0.9064384698867798, 0.5459896549582481, 0.18712306022644043), (0, 0.35486340522766113, 0.5038395822048187, 0.7097268104553223, 0.7453189492225647)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_1032.png: 640x512 1 Topwear, 1 Bottomwear, 95.6ms\n",
      "Speed: 1.9ms preprocess, 95.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_1032.png\n",
      "Annotations: [(0, 0.5103740692138672, 0.5895249843597412, 0.7325903177261353, 0.7446306943893433)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5648.png: 640x512 1 Topwear, 1 Bottomwear, 80.8ms\n",
      "Speed: 1.8ms preprocess, 80.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_5648.png\n",
      "Annotations: [(1, 0.42216329276561737, 0.6253553479909897, 0.38959112763404846, 0.27857664227485657), (0, 0.3852464556694031, 0.36982400715351105, 0.45991265773773193, 0.28272804617881775)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camiseta-interior_1.png: 640x448 1 Topwear, 68.4ms\n",
      "Speed: 1.9ms preprocess, 68.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camiseta-interior_1.png\n",
      "Annotations: [(0, 0.35727837309241295, 0.5643389970064163, 0.5669749453663826, 0.5350687205791473)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_549.png: 640x512 1 Bottomwear, 90.3ms\n",
      "Speed: 1.7ms preprocess, 90.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_549.png\n",
      "Annotations: [(1, 0.4778100475668907, 0.5722073465585709, 0.5634810477495193, 0.781185120344162)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4825.png: 640x512 1 Topwear, 1 Bottomwear, 80.5ms\n",
      "Speed: 1.9ms preprocess, 80.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4825.png\n",
      "Annotations: [(1, 0.3401762954890728, 0.9385753273963928, 0.4588509574532509, 0.12284934520721436), (0, 0.3751343344338238, 0.483352392911911, 0.7191491415724158, 0.9134052395820618)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_2794.png: 640x544 1 Topwear, 1 Bottomwear, 1 Footwear, 100.6ms\n",
      "Speed: 1.8ms preprocess, 100.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_faldas_2794.png\n",
      "Annotations: [(2, 0.43858133256435394, 0.9042931199073792, 0.12352576851844788, 0.15417790412902832), (1, 0.4830157607793808, 0.3152569383382797, 0.3083867132663727, 0.5665779411792755)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_5345.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 81.2ms\n",
      "Speed: 1.9ms preprocess, 81.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_5345.png\n",
      "Annotations: [(2, 0.14521663263440132, 0.8808438777923584, 0.08790471404790878, 0.12165379524230957), (2, 0.3633968234062195, 0.8557277619838715, 0.09953290224075317, 0.12612777948379517), (0, 0.3269718326628208, 0.1326369121670723, 0.44181322306394577, 0.2650033086538315), (1, 0.29092609882354736, 0.509828194975853, 0.37620991468429565, 0.6271462738513947)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5634.png: 640x512 1 Topwear, 101.5ms\n",
      "Speed: 1.8ms preprocess, 101.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_5634.png\n",
      "Annotations: [(0, 0.4907483868300915, 0.48538850247859955, 0.8065954819321632, 0.7048126757144928)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_714.png: 640x512 1 Topwear, 1 Bottomwear, 81.8ms\n",
      "Speed: 1.9ms preprocess, 81.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_714.png\n",
      "Annotations: [(0, 0.6156034916639328, 0.5143755823373795, 0.5254140198230743, 0.71060511469841)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4917.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 97.6ms\n",
      "Speed: 1.5ms preprocess, 97.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_4917.png\n",
      "Annotations: [(2, 0.7018471956253052, 0.9093137681484222, 0.1319636106491089, 0.10354036092758179), (2, 0.5366204231977463, 0.9114490151405334, 0.1605842411518097, 0.10851311683654785), (0, 0.6757973581552505, 0.22019484639167786, 0.3612607419490814, 0.4403896927833557), (1, 0.6047222018241882, 0.6339050233364105, 0.368452787399292, 0.542366087436676)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_503.png: 640x512 1 Topwear, 1 Footwear, 78.7ms\n",
      "Speed: 1.9ms preprocess, 78.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_503.png\n",
      "Annotations: [(0, 0.5324152112007141, 0.47816477715969086, 0.5633831024169922, 0.6168942749500275)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_3248.png: 640x448 1 Bottomwear, 2 Footwears, 69.8ms\n",
      "Speed: 2.2ms preprocess, 69.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_pantalones_3248.png\n",
      "Annotations: [(2, 0.6940831243991852, 0.89786696434021, 0.19277209043502808, 0.15623760223388672), (2, 0.372772715985775, 0.9131092429161072, 0.24998803436756134, 0.13495886325836182), (1, 0.48289623856544495, 0.4524762034416199, 0.5807361006736755, 0.8393152952194214)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_1251.png: 640x448 1 Bottomwear, 83.8ms\n",
      "Speed: 1.4ms preprocess, 83.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_pantalones_1251.png\n",
      "Annotations: [(1, 0.49567170441150665, 0.4973316341638565, 0.597059816122055, 0.9411050975322723)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5820.png: 640x512 1 Bottomwear, 82.3ms\n",
      "Speed: 1.7ms preprocess, 82.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_5820.png\n",
      "Annotations: [(1, 0.4975990578532219, 0.500877870246768, 0.5598853975534439, 0.8928906656801701)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5476.png: 640x480 1 Topwear, 75.5ms\n",
      "Speed: 1.9ms preprocess, 75.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_sudaderas_5476.png\n",
      "Annotations: [(0, 0.500269740819931, 0.39661920070648193, 0.6216078400611877, 0.5408744812011719)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_3650.png: 640x512 1 Topwear, 97.2ms\n",
      "Speed: 1.8ms preprocess, 97.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_3650.png\n",
      "Annotations: [(1, 0.2924973666667938, 0.7414599061012268, 0.39784765243530273, 0.27202045917510986), (0, 0.3056766986846924, 0.521664023399353, 0.6113533973693848, 0.6346427202224731)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_2773.png: 640x640 1 Footwear, 99.9ms\n",
      "Speed: 2.1ms preprocess, 99.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_2773.png\n",
      "Annotations: [(2, 0.4974505342543125, 0.5806566625833511, 0.8237132951617241, 0.3907005488872528)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_2928.png: 640x544 1 Topwear, 1 Bottomwear, 2 Footwears, 78.4ms\n",
      "Speed: 2.4ms preprocess, 78.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_jeans_2928.png\n",
      "Annotations: [(2, 0.4089854061603546, 0.8992529511451721, 0.22486501932144165, 0.18767476081848145), (2, 0.7754091024398804, 0.8075102865695953, 0.2209312915802002, 0.2182430624961853), (0, 0.16220307350158691, 0.07857967168092728, 0.32440614700317383, 0.15715934336185455), (1, 0.3822906883433461, 0.43788187205791473, 0.7093824800103903, 0.7417387068271637)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_1309.png: 640x512 1 Topwear, 1 Bottomwear, 102.2ms\n",
      "Speed: 1.8ms preprocess, 102.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_1309.png\n",
      "Annotations: [(1, 0.27886566519737244, 0.8081051111221313, 0.5577313303947449, 0.3231924772262573), (0, 0.3687276169657707, 0.44866494834423065, 0.5574377924203873, 0.45903006196022034)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_1863.png: 640x512 2 Topwears, 2 Bottomwears, 81.3ms\n",
      "Speed: 1.9ms preprocess, 81.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_1863.png\n",
      "Annotations: [(1, 0.24137240089476109, 0.9005640745162964, 0.39758695289492607, 0.17794561386108398), (0, 0.2417975114658475, 0.554588183760643, 0.42316668294370174, 0.684721976518631), (0, 0.7078110575675964, 0.5584663897752762, 0.508226752281189, 0.6525159776210785)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botas_733.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 100.2ms\n",
      "Speed: 1.9ms preprocess, 100.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_botas_733.png\n",
      "Annotations: [(2, 0.5866503268480301, 0.5039990395307541, 0.205282062292099, 0.59197798371315), (2, 0.4274769127368927, 0.5169326215982437, 0.22858017683029175, 0.6719608008861542), (0, 0.5000841468572617, 0.12381529808044434, 0.7298263609409332, 0.2331443428993225)]\n",
      "Detections: ['original_image', 'topwear', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_2199.png: 640x640 1 Topwear, 99.9ms\n",
      "Speed: 2.6ms preprocess, 99.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_abrigos_2199.png\n",
      "Annotations: [(0, 0.48327070474624634, 0.5022031962871552, 0.7146527767181396, 0.9404873251914978)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_tacones_721.png: 640x512 2 Footwears, 94.0ms\n",
      "Speed: 1.9ms preprocess, 94.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_tacones_721.png\n",
      "Annotations: [(2, 0.2762383595108986, 0.6381978243589401, 0.47844521701335907, 0.3078092634677887), (2, 0.7026191800832748, 0.605357825756073, 0.4751019775867462, 0.402126669883728)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4311.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 79.1ms\n",
      "Speed: 1.9ms preprocess, 79.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4311.png\n",
      "Annotations: [(2, 0.27962011843919754, 0.9032135307788849, 0.26987461745738983, 0.1412755846977234), (2, 0.7110953032970428, 0.8791815042495728, 0.2475622296333313, 0.16903555393218994), (0, 0.4636644721031189, 0.12253502383828163, 0.6385807991027832, 0.24093543738126755), (1, 0.4962115064263344, 0.5143062397837639, 0.5634730309247971, 0.6532527357339859), (1, 0.4954570233821869, 0.42272451519966125, 0.6478973031044006, 0.8454490303993225)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_planos_15.png: 640x544 1 Footwear, 94.7ms\n",
      "Speed: 1.9ms preprocess, 94.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_planos_15.png\n",
      "Annotations: [(2, 0.4945511072874069, 0.7104123830795288, 0.7117041647434235, 0.1802767515182495)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5814.png: 640x544 1 Topwear, 84.4ms\n",
      "Speed: 1.8ms preprocess, 84.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_abrigos_5814.png\n",
      "Annotations: [(0, 0.5040040798485279, 0.4792129099369049, 0.7765177115797997, 0.6300515532493591)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1367.png: 640x512 1 Bottomwear, 81.6ms\n",
      "Speed: 1.8ms preprocess, 81.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_1367.png\n",
      "Annotations: [(1, 0.5010808855295181, 0.48816533386707306, 0.5013451278209686, 0.7775667607784271)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_2588.png: 416x640 1 Topwear, 71.4ms\n",
      "Speed: 2.2ms preprocess, 71.4ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Processing dataset_camisetas_2588.png\n",
      "Annotations: [(0, 0.4957153648138046, 0.5432584322988987, 0.34027376770973206, 0.8758925125002861)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_3369.png: 640x640 1 Footwear, 98.7ms\n",
      "Speed: 1.8ms preprocess, 98.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_3369.png\n",
      "Annotations: [(2, 0.495555579662323, 0.48311641812324524, 0.3256288766860962, 0.1556437611579895)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5771.png: 640x512 1 Topwear, 99.0ms\n",
      "Speed: 1.7ms preprocess, 99.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_5771.png\n",
      "Annotations: [(0, 0.4800466522574425, 0.4487290531396866, 0.49403615295886993, 0.5724427402019501)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_2156.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 79.4ms\n",
      "Speed: 1.8ms preprocess, 79.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_2156.png\n",
      "Annotations: [(2, 0.24883408844470978, 0.9132782220840454, 0.1395491659641266, 0.0906219482421875), (2, 0.5881588459014893, 0.9136165976524353, 0.17277312278747559, 0.0866851806640625), (0, 0.5785420536994934, 0.21306537836790085, 0.4396524429321289, 0.3336765915155411), (1, 0.4632519334554672, 0.6222655922174454, 0.4423195421695709, 0.605873316526413)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_3152.png: 640x480 1 Topwear, 72.3ms\n",
      "Speed: 2.3ms preprocess, 72.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_3152.png\n",
      "Annotations: [(0, 0.49681066535413265, 0.5253109335899353, 0.913055557757616, 0.8626590967178345)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_2809.png: 640x480 1 Topwear, 88.0ms\n",
      "Speed: 1.9ms preprocess, 88.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_2809.png\n",
      "Annotations: [(0, 0.5019218474626541, 0.5043355375528336, 0.7785318791866302, 0.9375238120555878)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_3851.png: 640x512 1 Topwear, 1 Bottomwear, 79.1ms\n",
      "Speed: 1.5ms preprocess, 79.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_3851.png\n",
      "Annotations: [(1, 0.32539860904216766, 0.9038498103618622, 0.46704497933387756, 0.19230037927627563), (0, 0.42692798003554344, 0.5872645974159241, 0.6466722562909126, 0.6877570152282715)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_1727.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 95.3ms\n",
      "Speed: 2.0ms preprocess, 95.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_1727.png\n",
      "Annotations: [(2, 0.26793040335178375, 0.8924687802791595, 0.11618039011955261, 0.1303287148475647), (2, 0.12705012038350105, 0.8823881149291992, 0.16279234737157822, 0.11869823932647705), (0, 0.23059533163905144, 0.24864168465137482, 0.2840724363923073, 0.2085447609424591), (1, 0.16983860172331333, 0.46618980169296265, 0.26844603940844536, 0.29543161392211914)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_4987.png: 640x512 1 Topwear, 1 Bottomwear, 81.0ms\n",
      "Speed: 1.9ms preprocess, 81.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_4987.png\n",
      "Annotations: [(1, 0.6068958789110184, 0.7430439591407776, 0.4917334020137787, 0.2698861360549927), (0, 0.7018886804580688, 0.4951243996620178, 0.5962226390838623, 0.5754276514053345)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5722.png: 640x512 1 Topwear, 1 Bottomwear, 87.9ms\n",
      "Speed: 1.9ms preprocess, 87.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_5722.png\n",
      "Annotations: [(1, 0.6367185711860657, 0.8833096027374268, 0.36903464794158936, 0.22399449348449707), (0, 0.679685115814209, 0.573443815112114, 0.640629768371582, 0.6887966692447662)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_2740.png: 640x544 1 Bottomwear, 93.4ms\n",
      "Speed: 1.9ms preprocess, 93.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_pantalones_2740.png\n",
      "Annotations: [(1, 0.5021244138479233, 0.5074778348207474, 0.5541098415851593, 0.6932307183742523)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_466.png: 640x512 2 Footwears, 81.0ms\n",
      "Speed: 1.9ms preprocess, 81.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sandalias_466.png\n",
      "Annotations: [(2, 0.7343409061431885, 0.47880053520202637, 0.26168155670166016, 0.4538614749908447), (2, 0.406706091016531, 0.6684294939041138, 0.579739935696125, 0.2623004913330078)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_tacones_14.png: 640x544 1 Footwear, 100.7ms\n",
      "Speed: 2.2ms preprocess, 100.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_tacones_14.png\n",
      "Annotations: [(2, 0.47577396780252457, 0.5927266925573349, 0.845353290438652, 0.6281237900257111)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_2903.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 83.9ms\n",
      "Speed: 1.8ms preprocess, 83.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_2903.png\n",
      "Annotations: [(2, 0.6048185527324677, 0.9089721441268921, 0.13275426626205444, 0.1469968557357788), (2, 0.900658905506134, 0.9035650193691254, 0.19868218898773193, 0.154765784740448), (0, 0.665611207485199, 0.19515058398246765, 0.6088922023773193, 0.3903011679649353), (1, 0.6969745308160782, 0.5249670743942261, 0.5267994105815887, 0.7061522006988525)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_158.png: 640x544 1 Topwear, 1 Bottomwear, 98.4ms\n",
      "Speed: 1.7ms preprocess, 98.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_pantalones_158.png\n",
      "Annotations: [(1, 0.5268881916999817, 0.4506758600473404, 0.6024185419082642, 0.6668455302715302)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_998.png: 640x512 1 Topwear, 1 Bottomwear, 81.3ms\n",
      "Speed: 1.9ms preprocess, 81.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_998.png\n",
      "Annotations: [(1, 0.6599579304456711, 0.9352936744689941, 0.527286559343338, 0.12941265106201172), (0, 0.6535164713859558, 0.5783803462982178, 0.6929670572280884, 0.654715895652771)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_489.png: 640x512 2 Topwears, 1 Bottomwear, 2 Footwears, 80.2ms\n",
      "Speed: 1.9ms preprocess, 80.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_489.png\n",
      "Annotations: [(2, 0.5917945802211761, 0.8989450931549072, 0.11005264520645142, 0.11359381675720215), (2, 0.4359394907951355, 0.9185859858989716, 0.15020203590393066, 0.12474042177200317), (1, 0.568287268280983, 0.49384067952632904, 0.2585556209087372, 0.22863546013832092), (0, 0.6012523174285889, 0.2853430286049843, 0.26407694816589355, 0.23741810023784637)]\n",
      "Detections: ['original_image', 'footwear', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_245.png: 640x640 1 Topwear, 113.9ms\n",
      "Speed: 2.0ms preprocess, 113.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_sudaderas_245.png\n",
      "Annotations: [(0, 0.5032989978790283, 0.492631733417511, 0.6636584997177124, 0.9285657405853271)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5860.png: 640x544 1 Bottomwear, 84.2ms\n",
      "Speed: 1.9ms preprocess, 84.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_pantalones_5860.png\n",
      "Annotations: [(1, 0.5084061324596405, 0.5004361420869827, 0.40559810400009155, 0.8110109269618988)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_2827.png: 640x512 1 Topwear, 1 Bottomwear, 96.1ms\n",
      "Speed: 2.1ms preprocess, 96.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_2827.png\n",
      "Annotations: [(1, 0.3853224143385887, 0.8873633146286011, 0.5014267712831497, 0.22527337074279785), (0, 0.4859577789902687, 0.5537081807851791, 0.66749207675457, 0.6877134144306183)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_1520.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 84.2ms\n",
      "Speed: 1.8ms preprocess, 84.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_1520.png\n",
      "Annotations: [(2, 0.6349865049123764, 0.8189345896244049, 0.33100441098213196, 0.13698655366897583), (2, 0.3393198773264885, 0.8949048817157745, 0.33856119215488434, 0.14742451906204224), (0, 0.5199300795793533, 0.11781273409724236, 0.4897134006023407, 0.22311536222696304), (1, 0.527125895023346, 0.5040462613105774, 0.4002103805541992, 0.6338188648223877)]\n",
      "Detections: ['original_image', 'footwear', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1729.png: 640x640 1 Topwear, 1 Bottomwear, 111.9ms\n",
      "Speed: 2.2ms preprocess, 111.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_sudaderas_1729.png\n",
      "Annotations: [(1, 0.448782742023468, 0.8899356126785278, 0.3522456884384155, 0.22012877464294434), (0, 0.5178622752428055, 0.48331159353256226, 0.5847695767879486, 0.7569574117660522)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_454.png: 640x544 1 Topwear, 85.8ms\n",
      "Speed: 1.8ms preprocess, 85.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_vestidos_454.png\n",
      "Annotations: [(0, 0.5072709172964096, 0.5120678544044495, 0.5008619129657745, 0.882562518119812)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3451.png: 640x512 1 Topwear, 93.9ms\n",
      "Speed: 2.0ms preprocess, 93.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_3451.png\n",
      "Annotations: [(0, 0.4731808304786682, 0.5534761399030685, 0.33487236499786377, 0.8805834352970123)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_2585.png: 640x512 1 Topwear, 2 Footwears, 82.1ms\n",
      "Speed: 1.8ms preprocess, 82.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_2585.png\n",
      "Annotations: [(2, 0.5248351842164993, 0.8548679947853088, 0.10670050978660583, 0.1547931432723999), (2, 0.6341790556907654, 0.8956121206283569, 0.1213998794555664, 0.1514747142791748), (0, 0.5788307040929794, 0.41012686118483543, 0.3623570501804352, 0.5914309099316597)]\n",
      "Detections: ['original_image', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_2274.png: 640x544 1 Topwear, 1 Bottomwear, 101.6ms\n",
      "Speed: 2.4ms preprocess, 101.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisas-y-blusas_2274.png\n",
      "Annotations: [(1, 0.3797957971692085, 0.8221633732318878, 0.48436687886714935, 0.3173295855522156), (0, 0.33037734776735306, 0.5574125051498413, 0.39183150231838226, 0.5592082738876343)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botas_550.png: 640x416 1 Footwear, 67.0ms\n",
      "Speed: 1.6ms preprocess, 67.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 416)\n",
      "Processing dataset_botas_550.png\n",
      "Annotations: [(2, 0.48753297282382846, 0.491953581571579, 0.9439328918233514, 0.4188210368156433)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4557.png: 640x512 1 Topwear, 1 Bottomwear, 95.2ms\n",
      "Speed: 1.9ms preprocess, 95.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4557.png\n",
      "Annotations: [(0, 0.3658263776451349, 0.5857372283935547, 0.6408711485564709, 0.760826587677002)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_226.png: 640x512 1 Topwear, 1 Bottomwear, 1 Footwear, 83.0ms\n",
      "Speed: 1.9ms preprocess, 83.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_226.png\n",
      "Annotations: [(2, 0.18731789290905, 0.6245171427726746, 0.1092301607131958, 0.10051584243774414), (2, 0.24888572841882706, 0.8531466424465179, 0.1388075202703476, 0.13026553392410278), (1, 0.21508479490876198, 0.5982028990983963, 0.3185001537203789, 0.4385918080806732), (0, 0.24117344617843628, 0.2863503471016884, 0.48234689235687256, 0.3456637114286423)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_4458.png: 640x480 1 Topwear, 76.8ms\n",
      "Speed: 1.7ms preprocess, 76.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_4458.png\n",
      "Annotations: [(0, 0.4874921217560768, 0.4031863175332546, 0.7666281908750534, 0.5865801647305489)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_95.png: 640x512 1 Topwear, 1 Bottomwear, 90.9ms\n",
      "Speed: 1.9ms preprocess, 90.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_95.png\n",
      "Annotations: [(1, 0.7601492702960968, 0.867951899766922, 0.4017053246498108, 0.264096200466156), (0, 0.7567105293273926, 0.4958275556564331, 0.48657894134521484, 0.6024333238601685)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_391.png: 640x448 1 Topwear, 1 Bottomwear, 2 Footwears, 71.1ms\n",
      "Speed: 1.6ms preprocess, 71.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_pantalones_391.png\n",
      "Annotations: [(2, 0.6502746641635895, 0.8971239924430847, 0.1785241961479187, 0.17643940448760986), (2, 0.3018065094947815, 0.837900698184967, 0.33831268548965454, 0.12752759456634521), (1, 0.4966156482696533, 0.44415690191090107, 0.5265618562698364, 0.7816432379186153)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_3028.png: 640x544 1 Topwear, 1 Bottomwear, 2 Footwears, 99.2ms\n",
      "Speed: 2.3ms preprocess, 99.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_jeans_3028.png\n",
      "Annotations: [(2, 0.40515565872192383, 0.9109092354774475, 0.09603780508041382, 0.14540064334869385), (2, 0.6604886949062347, 0.9170268177986145, 0.11617809534072876, 0.14450907707214355), (0, 0.5872880071401596, 0.06731472909450531, 0.43722835183143616, 0.13337314128875732), (1, 0.5704637914896011, 0.4521336518228054, 0.41334959864616394, 0.7059096172451973)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4774.png: 640x448 1 Topwear, 1 Bottomwear, 69.7ms\n",
      "Speed: 2.0ms preprocess, 69.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisetas_4774.png\n",
      "Annotations: [(1, 0.5413447767496109, 0.8792717158794403, 0.5514844357967377, 0.24145656824111938), (0, 0.4915868230164051, 0.525668278336525, 0.7421973571181297, 0.605362743139267)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2304.png: 640x512 1 Topwear, 1 Bottomwear, 98.6ms\n",
      "Speed: 2.0ms preprocess, 98.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_2304.png\n",
      "Annotations: [(1, 0.4616718739271164, 0.7749456167221069, 0.500208169221878, 0.45010876655578613), (0, 0.4358760789036751, 0.5004152208566666, 0.49509237706661224, 0.5698065459728241)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1373.png: 640x640 1 Footwear, 96.0ms\n",
      "Speed: 2.1ms preprocess, 96.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_1373.png\n",
      "Annotations: [(2, 0.49433891475200653, 0.6210196614265442, 0.8161987364292145, 0.3165334463119507)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4840.png: 640x512 1 Topwear, 1 Bottomwear, 95.7ms\n",
      "Speed: 1.9ms preprocess, 95.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4840.png\n",
      "Annotations: [(0, 0.6638152897357941, 0.5579641610383987, 0.6625083088874817, 0.6705122888088226)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_2636.png: 640x544 1 Topwear, 85.4ms\n",
      "Speed: 1.8ms preprocess, 85.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_vestidos_2636.png\n",
      "Annotations: [(0, 0.4986383616924286, 0.49970288574695587, 0.6626297831535339, 0.7693328559398651)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_1603.png: 640x512 1 Bottomwear, 2 Footwears, 94.4ms\n",
      "Speed: 1.9ms preprocess, 94.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_1603.png\n",
      "Annotations: [(2, 0.38535459339618683, 0.8920790255069733, 0.15642955899238586, 0.182298481464386), (2, 0.6023358106613159, 0.827118992805481, 0.16473150253295898, 0.18501043319702148), (1, 0.510826826095581, 0.4295370429754257, 0.45337843894958496, 0.6246576607227325)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4809.png: 640x512 1 Topwear, 79.0ms\n",
      "Speed: 1.9ms preprocess, 79.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4809.png\n",
      "Annotations: [(0, 0.525184690952301, 0.4294600635766983, 0.430999755859375, 0.5240447223186493), (0, 0.536915197968483, 0.5478897541761398, 0.49949154257774353, 0.7167152464389801)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_2444.png: 640x512 1 Topwear, 1 Bottomwear, 78.7ms\n",
      "Speed: 1.7ms preprocess, 78.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_2444.png\n",
      "Annotations: [(1, 0.43118762969970703, 0.9110024869441986, 0.5080251693725586, 0.17799502611160278), (0, 0.4812668412923813, 0.5662270784378052, 0.7305102646350861, 0.6548483371734619)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_2203.png: 640x512 1 Bottomwear, 1 Footwear, 88.8ms\n",
      "Speed: 1.6ms preprocess, 88.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_2203.png\n",
      "Annotations: [(2, 0.5552007853984833, 0.8944515883922577, 0.17407077550888062, 0.20456808805465698), (1, 0.5386434644460678, 0.47793880105018616, 0.44403567910194397, 0.8106998801231384)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_818.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 78.4ms\n",
      "Speed: 1.9ms preprocess, 78.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_818.png\n",
      "Annotations: [(2, 0.7006252110004425, 0.8753942549228668, 0.08162134885787964, 0.17562836408615112), (2, 0.8510955274105072, 0.8848232328891754, 0.101901113986969, 0.1629151701927185), (1, 0.7233279049396515, 0.5015433430671692, 0.2217063307762146, 0.22508978843688965), (0, 0.7039187550544739, 0.29880470037460327, 0.2506587505340576, 0.22522836923599243)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_4752.png: 640x544 1 Topwear, 82.1ms\n",
      "Speed: 1.8ms preprocess, 82.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_abrigos_4752.png\n",
      "Annotations: [(0, 0.49440643936395645, 0.4754510521888733, 0.6598182171583176, 0.6139436960220337)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4251.png: 640x544 1 Topwear, 96.8ms\n",
      "Speed: 1.9ms preprocess, 96.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisetas_4251.png\n",
      "Annotations: [(0, 0.4920887053012848, 0.5452505201101303, 0.6282497048377991, 0.6743426620960236)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_polos_445.png: 640x640 1 Topwear, 100.9ms\n",
      "Speed: 2.5ms preprocess, 100.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_polos_445.png\n",
      "Annotations: [(0, 0.49142153561115265, 0.501026526093483, 0.709406703710556, 0.9359779059886932)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_667.png: 640x512 1 Topwear, 96.2ms\n",
      "Speed: 1.8ms preprocess, 96.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_667.png\n",
      "Annotations: [(0, 0.5252922773361206, 0.5857017785310745, 0.521504282951355, 0.6202575862407684)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5483.png: 640x512 1 Topwear, 1 Bottomwear, 92.1ms\n",
      "Speed: 1.9ms preprocess, 92.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_5483.png\n",
      "Annotations: [(1, 0.2894931100308895, 0.8346037566661835, 0.3868420198559761, 0.23649615049362183), (0, 0.3344879634678364, 0.5243896543979645, 0.5374809727072716, 0.495216429233551), (0, 0.32934465259313583, 0.6337433159351349, 0.5229877978563309, 0.651939332485199)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_2445.png: 640x480 1 Topwear, 76.3ms\n",
      "Speed: 1.8ms preprocess, 76.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas_2445.png\n",
      "Annotations: [(0, 0.50224251113832, 0.5257072895765305, 0.899480689316988, 0.8636099398136139)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4309.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 100.1ms\n",
      "Speed: 1.8ms preprocess, 100.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_4309.png\n",
      "Annotations: [(2, 0.21863991767168045, 0.8844837546348572, 0.10382197797298431, 0.14584124088287354), (2, 0.5750880986452103, 0.884357362985611, 0.18357297778129578, 0.17479366064071655), (0, 0.2662958651781082, 0.1817496381700039, 0.42034807801246643, 0.24894732981920242), (1, 0.31920606456696987, 0.548521876335144, 0.5186828263103962, 0.5138251781463623)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2298.png: 640x512 1 Topwear, 2 Bottomwears, 2 Footwears, 77.9ms\n",
      "Speed: 3.1ms preprocess, 77.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_2298.png\n",
      "Annotations: [(2, 0.27172132581472397, 0.8902333974838257, 0.09387464821338654, 0.14403605461120605), (2, 0.5611405074596405, 0.8979879319667816, 0.12682849168777466, 0.12804609537124634), (1, 0.39221320301294327, 0.43169036507606506, 0.30539970099925995, 0.20869320631027222), (0, 0.3965458869934082, 0.257374070584774, 0.35492491722106934, 0.2430254966020584)]\n",
      "Detections: ['original_image', 'topwear', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_2127.png: 640x512 1 Topwear, 98.8ms\n",
      "Speed: 1.9ms preprocess, 98.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_2127.png\n",
      "Annotations: [(0, 0.4118883088231087, 0.5501014739274979, 0.4561564773321152, 0.7357302606105804)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5769.png: 640x512 1 Topwear, 79.6ms\n",
      "Speed: 1.9ms preprocess, 79.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_5769.png\n",
      "Annotations: [(0, 0.7305582016706467, 0.5132262110710144, 0.49846747517585754, 0.7358924150466919)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_51.png: 640x544 1 Topwear, 94.5ms\n",
      "Speed: 1.7ms preprocess, 94.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_vestidos_51.png\n",
      "Annotations: [(0, 0.5051101595163345, 0.4942910224199295, 0.5757348239421844, 0.9639090001583099)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_1996.png: 640x544 1 Topwear, 86.1ms\n",
      "Speed: 1.9ms preprocess, 86.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_abrigos_1996.png\n",
      "Annotations: [(0, 0.4959031566977501, 0.4963558614253998, 0.8242628127336502, 0.8205816149711609)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_cardigans_33.png: 640x448 1 Topwear, 1 Bottomwear, 80.3ms\n",
      "Speed: 2.5ms preprocess, 80.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_cardigans_33.png\n",
      "Annotations: [(1, 0.5425226092338562, 0.8601399660110474, 0.6545780897140503, 0.25737297534942627), (0, 0.5747480243444443, 0.5165270119905472, 0.6869002878665924, 0.6035290658473969)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_2436.png: 640x512 1 Topwear, 1 Bottomwear, 83.1ms\n",
      "Speed: 2.0ms preprocess, 83.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_2436.png\n",
      "Annotations: [(1, 0.4562968462705612, 0.8687743544578552, 0.40237143635749817, 0.25721585750579834), (0, 0.4607578292489052, 0.5114770978689194, 0.5526634901762009, 0.577905684709549)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5396.png: 640x512 1 Topwear, 98.9ms\n",
      "Speed: 1.9ms preprocess, 98.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_5396.png\n",
      "Annotations: [(0, 0.258276104927063, 0.5983268618583679, 0.516552209854126, 0.7269861698150635)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3689.png: 640x512 2 Topwears, 1 Bottomwear, 81.5ms\n",
      "Speed: 2.6ms preprocess, 81.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_3689.png\n",
      "Annotations: [(0, 0.3136110305786133, 0.5716394633054733, 0.6272220611572266, 0.6727466881275177)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_2730.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 96.1ms\n",
      "Speed: 1.8ms preprocess, 96.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_2730.png\n",
      "Annotations: [(2, 0.2959619611501694, 0.8829454779624939, 0.08911225199699402, 0.16540610790252686), (2, 0.611688882112503, 0.8797515630722046, 0.10809260606765747, 0.16051089763641357), (0, 0.3747147396206856, 0.17977605760097504, 0.4939997047185898, 0.3414953649044037), (1, 0.39080293476581573, 0.5013641119003296, 0.4777863919734955, 0.6407686471939087)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_112.png: 640x512 1 Topwear, 1 Bottomwear, 81.7ms\n",
      "Speed: 1.9ms preprocess, 81.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_112.png\n",
      "Annotations: [(1, 0.3764016404747963, 0.892579048871994, 0.4145191162824631, 0.21484190225601196), (0, 0.34532419592142105, 0.5141129940748215, 0.529991552233696, 0.6298195421695709)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_756.png: 640x512 2 Topwears, 1 Bottomwear, 2 Footwears, 98.4ms\n",
      "Speed: 2.0ms preprocess, 98.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_756.png\n",
      "Annotations: [(2, 0.26654863357543945, 0.967964380979538, 0.11266416311264038, 0.06407123804092407), (2, 0.20077426731586456, 0.9406681060791016, 0.11987301707267761, 0.11034369468688965), (1, 0.24372392892837524, 0.580214112997055, 0.3407592177391052, 0.374939501285553), (0, 0.23312921077013016, 0.4784900099039078, 0.37365327775478363, 0.5721563994884491)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_177.png: 640x544 1 Topwear, 85.5ms\n",
      "Speed: 3.1ms preprocess, 85.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_monos_177.png\n",
      "Annotations: [(1, 0.5740078240633011, 0.558580294251442, 0.4736141860485077, 0.6655676066875458)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_2722.png: 640x512 1 Topwear, 101.2ms\n",
      "Speed: 1.8ms preprocess, 101.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_2722.png\n",
      "Annotations: [(0, 0.5091504473239183, 0.49088694155216217, 0.9816991053521633, 0.6872083842754364)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_107.png: 640x512 2 Bottomwears, 83.6ms\n",
      "Speed: 1.5ms preprocess, 83.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_107.png\n",
      "Annotations: [(1, 0.38453493267297745, 0.7489781975746155, 0.49870912730693817, 0.3147376775741577), (0, 0.3335537686944008, 0.4892495572566986, 0.6095847338438034, 0.3595772385597229), (1, 0.333457943983376, 0.592632994055748, 0.6134702023118734, 0.5735266506671906)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_505.png: 640x512 1 Bottomwear, 97.1ms\n",
      "Speed: 1.8ms preprocess, 97.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_505.png\n",
      "Annotations: [(1, 0.732191726565361, 0.5798243209719658, 0.5005857050418854, 0.7393059879541397)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_3883.png: 640x640 1 Footwear, 114.6ms\n",
      "Speed: 2.0ms preprocess, 114.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_3883.png\n",
      "Annotations: [(2, 0.5015927702188492, 0.5254499912261963, 0.8265685737133026, 0.48875391483306885)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3939.png: 640x448 1 Topwear, 71.8ms\n",
      "Speed: 1.2ms preprocess, 71.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_vestidos_3939.png\n",
      "Annotations: [(0, 0.510955922305584, 0.5021103620529175, 0.8277517706155777, 0.9518017768859863)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_490.png: 640x512 1 Topwear, 1 Bottomwear, 1 Footwear, 84.5ms\n",
      "Speed: 2.0ms preprocess, 84.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_490.png\n",
      "Annotations: [(2, 0.6116377413272858, 0.9297823309898376, 0.09201139211654663, 0.09083282947540283), (1, 0.6100747734308243, 0.6497353613376617, 0.22237929701805115, 0.5097433924674988), (0, 0.6059939414262772, 0.3162929192185402, 0.395006388425827, 0.38343076407909393)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_1109.png: 640x480 1 Topwear, 87.9ms\n",
      "Speed: 2.2ms preprocess, 87.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jerseys_1109.png\n",
      "Annotations: [(0, 0.5051720142364502, 0.4047541916370392, 0.6006932258605957, 0.5528762936592102)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4265.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 84.4ms\n",
      "Speed: 2.0ms preprocess, 84.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4265.png\n",
      "Annotations: [(2, 0.241361353546381, 0.8639656901359558, 0.3279991075396538, 0.1382007598876953), (2, 0.7638693153858185, 0.8283905386924744, 0.2826346755027771, 0.16949331760406494), (0, 0.5107348263263702, 0.12213003635406494, 0.4340059161186218, 0.24426007270812988), (1, 0.5297911763191223, 0.42690351605415344, 0.571345329284668, 0.6393614411354065)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5357.png: 640x512 1 Topwear, 1 Bottomwear, 110.2ms\n",
      "Speed: 1.9ms preprocess, 110.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_5357.png\n",
      "Annotations: [(1, 0.5608240216970444, 0.9056820869445801, 0.6024980843067169, 0.18863582611083984), (0, 0.6765619814395905, 0.5216944813728333, 0.5748617053031921, 0.7338352203369141)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_360.png: 640x512 1 Topwear, 1 Bottomwear, 86.5ms\n",
      "Speed: 2.0ms preprocess, 86.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_360.png\n",
      "Annotations: [(1, 0.39381515979766846, 0.8989925384521484, 0.497800350189209, 0.20201492309570312), (0, 0.4391913525760174, 0.49052272737026215, 0.7064045444130898, 0.6495342552661896)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_253.png: 640x512 1 Topwear, 111.6ms\n",
      "Speed: 2.1ms preprocess, 111.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_253.png\n",
      "Annotations: [(0, 0.4906220808625221, 0.47488290071487427, 0.5109322518110275, 0.6639094352722168)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_339.png: 640x512 2 Footwears, 78.8ms\n",
      "Speed: 1.8ms preprocess, 78.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sandalias_339.png\n",
      "Annotations: [(2, 0.3295050673186779, 0.6333646774291992, 0.43602661043405533, 0.3806285858154297), (2, 0.7533686459064484, 0.5427833795547485, 0.4176899790763855, 0.4688570499420166)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_4098.png: 640x512 1 Topwear, 1 Bottomwear, 79.0ms\n",
      "Speed: 1.9ms preprocess, 79.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_4098.png\n",
      "Annotations: [(1, 0.4731130376458168, 0.8279484510421753, 0.4653093069791794, 0.3138011693954468), (0, 0.48266929388046265, 0.44090868532657623, 0.6620930433273315, 0.5040342509746552)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_2996.png: 640x448 1 Topwear, 74.2ms\n",
      "Speed: 1.5ms preprocess, 74.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_vestidos_2996.png\n",
      "Annotations: [(1, 0.5048551112413406, 0.8352570235729218, 0.578675240278244, 0.3294859528541565), (0, 0.49944768100976944, 0.5959920287132263, 0.7310256212949753, 0.6051515340805054)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_249.png: 640x512 1 Bottomwear, 80.5ms\n",
      "Speed: 2.0ms preprocess, 80.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_249.png\n",
      "Annotations: [(1, 0.4930301159620285, 0.4954288862645626, 0.47471311688423157, 0.7616882994771004)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1008.png: 640x512 1 Topwear, 2 Footwears, 78.0ms\n",
      "Speed: 1.9ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_1008.png\n",
      "Annotations: [(2, 0.7849630415439606, 0.9164095818996429, 0.1025739312171936, 0.1383938193321228), (2, 0.5163472294807434, 0.9030839204788208, 0.10173618793487549, 0.14487159252166748), (0, 0.6178338080644608, 0.5307495594024658, 0.5095666348934174, 0.7863936424255371)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_3051.png: 640x480 1 Topwear, 81.5ms\n",
      "Speed: 1.8ms preprocess, 81.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_3051.png\n",
      "Annotations: [(0, 0.49397921934723854, 0.4828779399394989, 0.8255211040377617, 0.8294230103492737)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_759.png: 640x480 1 Bottomwear, 76.2ms\n",
      "Speed: 1.8ms preprocess, 76.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_trajes_759.png\n",
      "Annotations: [(1, 0.5305418372154236, 0.47649236023426056, 0.4059816598892212, 0.9031783044338226)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_77.png: 640x544 1 Topwear, 99.3ms\n",
      "Speed: 1.8ms preprocess, 99.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_vestidos_77.png\n",
      "Annotations: [(0, 0.5032152384519577, 0.5012605488300323, 0.3258451521396637, 0.850184977054596)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_2717.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 79.3ms\n",
      "Speed: 1.8ms preprocess, 79.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_2717.png\n",
      "Annotations: [(2, 0.6717891097068787, 0.8145696818828583, 0.15693628787994385, 0.18955403566360474), (2, 0.3416847810149193, 0.8626164197921753, 0.29421038925647736, 0.1434406042098999), (0, 0.4730577766895294, 0.10623909533023834, 0.5007598996162415, 0.21247819066047668), (1, 0.4833787903189659, 0.4776590168476105, 0.4936782866716385, 0.7048763632774353)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_951.png: 640x480 1 Topwear, 72.0ms\n",
      "Speed: 1.7ms preprocess, 72.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_951.png\n",
      "Annotations: [(0, 0.4965884159319103, 0.498338520526886, 0.975545153953135, 0.8817447423934937)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2122.png: 640x448 2 Topwears, 82.5ms\n",
      "Speed: 1.3ms preprocess, 82.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jerseys_2122.png\n",
      "Annotations: [(0, 0.4919674447737634, 0.49245685338974, 0.9540591137483716, 0.9408179521560669)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_2044.png: 640x448 1 Topwear, 68.7ms\n",
      "Speed: 1.3ms preprocess, 68.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas_2044.png\n",
      "Annotations: [(0, 0.5024943314492702, 0.49654345214366913, 0.8759288862347603, 0.6281937658786774)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_1479.png: 640x480 1 Bottomwear, 83.0ms\n",
      "Speed: 2.0ms preprocess, 83.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas_1479.png\n",
      "Annotations: [(1, 0.49384883791208267, 0.5, 0.5534893721342087, 1.0)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_3991.png: 640x640 1 Footwear, 101.3ms\n",
      "Speed: 2.1ms preprocess, 101.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_3991.png\n",
      "Annotations: [(2, 0.49933746829628944, 0.5987412333488464, 0.7962261959910393, 0.35794365406036377)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1201.png: 640x448 1 Topwear, 81.1ms\n",
      "Speed: 1.3ms preprocess, 81.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_sudaderas_1201.png\n",
      "Annotations: [(0, 0.49686367996037006, 0.5118974894285202, 0.9400865696370602, 0.7977679073810577)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_2903.png: 640x512 1 Footwear, 77.9ms\n",
      "Speed: 1.8ms preprocess, 77.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_2903.png\n",
      "Annotations: [(2, 0.5128789506852627, 0.5894021391868591, 0.8582986667752266, 0.283363938331604)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_3902.png: 640x512 1 Topwear, 1 Bottomwear, 76.8ms\n",
      "Speed: 1.9ms preprocess, 76.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_3902.png\n",
      "Annotations: [(1, 0.6709927320480347, 0.8917277455329895, 0.4703943729400635, 0.216544508934021), (0, 0.6588228791952133, 0.5225908905267715, 0.6263709366321564, 0.6308717429637909)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1672.png: 640x512 1 Bottomwear, 83.5ms\n",
      "Speed: 1.8ms preprocess, 83.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_1672.png\n",
      "Annotations: [(1, 0.5089489221572876, 0.4965921640396118, 0.6862462759017944, 0.8909823894500732)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_1722.png: 640x512 1 Topwear, 1 Bottomwear, 77.1ms\n",
      "Speed: 1.7ms preprocess, 77.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_1722.png\n",
      "Annotations: [(1, 0.6304207444190979, 0.8902073502540588, 0.36192214488983154, 0.2175811529159546), (0, 0.6130506694316864, 0.5212169140577316, 0.5469462275505066, 0.6549631655216217)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_3725.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 82.4ms\n",
      "Speed: 2.7ms preprocess, 82.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_3725.png\n",
      "Annotations: [(2, 0.5729288458824158, 0.8668060898780823, 0.12586259841918945, 0.15288007259368896), (2, 0.3577256500720978, 0.8600581884384155, 0.12693476676940918, 0.15577197074890137), (1, 0.5100780725479126, 0.48386070132255554, 0.4420720338821411, 0.6770951151847839)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_4393.png: 640x512 1 Topwear, 1 Bottomwear, 75.7ms\n",
      "Speed: 1.9ms preprocess, 75.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_4393.png\n",
      "Annotations: [(1, 0.43423227965831757, 0.9236288666725159, 0.4848305284976959, 0.15274226665496826), (0, 0.5621262341737747, 0.5582512766122818, 0.6930190026760101, 0.7790908515453339)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5693.png: 640x480 1 Topwear, 81.5ms\n",
      "Speed: 2.5ms preprocess, 81.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_5693.png\n",
      "Annotations: [(0, 0.5002749897539616, 0.47819261252880096, 0.853716067969799, 0.891951709985733)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2036.png: 640x448 1 Topwear, 70.1ms\n",
      "Speed: 1.1ms preprocess, 70.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jerseys_2036.png\n",
      "Annotations: [(0, 0.5005497150123119, 0.5042077302932739, 0.9511218443512917, 0.7408286333084106)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4995.png: 640x544 1 Topwear, 98.8ms\n",
      "Speed: 1.8ms preprocess, 98.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sudaderas_4995.png\n",
      "Annotations: [(0, 0.48621679097414017, 0.4851399213075638, 0.6905068010091782, 0.6240321099758148)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5854.png: 640x544 1 Topwear, 1 Bottomwear, 83.2ms\n",
      "Speed: 2.7ms preprocess, 83.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sudaderas_5854.png\n",
      "Annotations: [(1, 0.5349296033382416, 0.8806743025779724, 0.4669165015220642, 0.23651373386383057), (0, 0.5759036615490913, 0.5172852724790573, 0.7236870378255844, 0.7121190130710602)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3338.png: 640x512 1 Topwear, 87.7ms\n",
      "Speed: 1.6ms preprocess, 87.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_3338.png\n",
      "Annotations: [(0, 0.5073049962520599, 0.4893199950456619, 0.7331423163414001, 0.7711341083049774)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1538.png: 640x640 1 Footwear, 113.2ms\n",
      "Speed: 2.1ms preprocess, 113.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_1538.png\n",
      "Annotations: [(2, 0.49917253851890564, 0.58090640604496, 0.8496337532997131, 0.4090974032878876)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_bodies_284.png: 640x512 1 Bottomwear, 79.5ms\n",
      "Speed: 2.0ms preprocess, 79.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_bodies_284.png\n",
      "Annotations: [(0, 0.47849470376968384, 0.5625890493392944, 0.380534291267395, 0.5858362913131714)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_3044.png: 640x640 1 Topwear, 1 Bottomwear, 114.8ms\n",
      "Speed: 2.1ms preprocess, 114.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_sudaderas_3044.png\n",
      "Annotations: [(1, 0.5166603326797485, 0.8919461071491241, 0.3892625570297241, 0.2161077857017517), (0, 0.5002066493034363, 0.47910255193710327, 0.5913596153259277, 0.7487589120864868)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_1210.png: 640x640 1 Topwear, 1 Bottomwear, 2 Footwears, 101.6ms\n",
      "Speed: 2.1ms preprocess, 101.6ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_shorts_1210.png\n",
      "Annotations: [(2, 0.32719558477401733, 0.8970849514007568, 0.10644125938415527, 0.13727402687072754), (2, 0.5471733808517456, 0.8837323486804962, 0.12298190593719482, 0.15376681089401245), (1, 0.527135968208313, 0.35813090950250626, 0.37205970287323, 0.3160988539457321)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_1243.png: 640x480 1 Topwear, 1 Bottomwear, 77.3ms\n",
      "Speed: 1.8ms preprocess, 77.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_1243.png\n",
      "Annotations: [(0, 0.4653518795967102, 0.49588252417743206, 0.9307037591934204, 0.9057385660707951)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_350.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 87.9ms\n",
      "Speed: 1.9ms preprocess, 87.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_350.png\n",
      "Annotations: [(2, 0.6434095203876495, 0.8377527594566345, 0.08538752794265747, 0.1566535234451294), (2, 0.44372420012950897, 0.9149659276008606, 0.15075162053108215, 0.11993277072906494), (0, 0.49175798892974854, 0.2816315144300461, 0.35313522815704346, 0.350218802690506), (1, 0.5121721476316452, 0.6237424612045288, 0.33177652955055237, 0.5047869682312012)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_1819.png: 640x512 1 Topwear, 1 Bottomwear, 80.2ms\n",
      "Speed: 1.9ms preprocess, 80.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_1819.png\n",
      "Annotations: [(1, 0.5997706055641174, 0.9390258491039276, 0.5220386981964111, 0.12194830179214478), (0, 0.5672205239534378, 0.5704871416091919, 0.5579732358455658, 0.7270557880401611)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5960.png: 640x448 1 Topwear, 77.5ms\n",
      "Speed: 1.7ms preprocess, 77.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_5960.png\n",
      "Annotations: [(0, 0.5049449950456619, 0.4962923526763916, 0.8757126033306122, 0.763465166091919)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_201.png: 640x544 1 Topwear, 2 Footwears, 85.3ms\n",
      "Speed: 1.9ms preprocess, 85.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_vestidos_201.png\n",
      "Annotations: [(2, 0.4846114367246628, 0.9442585706710815, 0.09116247296333313, 0.09790396690368652), (2, 0.5604418218135834, 0.9379701018333435, 0.09682375192642212, 0.10678744316101074), (0, 0.5109433531761169, 0.4950571358203888, 0.27467918395996094, 0.7041047215461731)]\n",
      "Detections: ['original_image', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_1336.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 93.2ms\n",
      "Speed: 2.0ms preprocess, 93.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_1336.png\n",
      "Annotations: [(2, 0.6853622198104858, 0.9292221665382385, 0.09768819808959961, 0.14155566692352295), (2, 0.7680801749229431, 0.9340182244777679, 0.10875225067138672, 0.13160580396652222), (0, 0.7681283056735992, 0.21402785927057266, 0.38255685567855835, 0.18684761226177216), (1, 0.7296734750270844, 0.5153617262840271, 0.2833639979362488, 0.4735229015350342)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_2286.png: 640x512 1 Topwear, 1 Bottomwear, 83.3ms\n",
      "Speed: 2.1ms preprocess, 83.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_2286.png\n",
      "Annotations: [(0, 0.4041881989687681, 0.5745779722929001, 0.738212738186121, 0.7386676371097565)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_554.png: 640x512 2 Footwears, 90.8ms\n",
      "Speed: 2.0ms preprocess, 90.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sandalias_554.png\n",
      "Annotations: [(2, 0.3874462693929672, 0.698850691318512, 0.40859225392341614, 0.27499353885650635), (2, 0.7249899506568909, 0.6024499386548996, 0.32153987884521484, 0.44597378373146057)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_290.png: 640x512 1 Bottomwear, 2 Footwears, 79.6ms\n",
      "Speed: 2.3ms preprocess, 79.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_290.png\n",
      "Annotations: [(2, 0.5420935899019241, 0.8738467395305634, 0.14538046717643738, 0.198200523853302), (2, 0.4217517077922821, 0.7358080446720123, 0.13998055458068848, 0.21573811769485474), (1, 0.5004065334796906, 0.26766612380743027, 0.4484483599662781, 0.36439771950244904)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_4326.png: 640x512 1 Topwear, 1 Bottomwear, 82.4ms\n",
      "Speed: 1.9ms preprocess, 82.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_4326.png\n",
      "Annotations: [(1, 0.37961071729660034, 0.9337378740310669, 0.5442466735839844, 0.12388718128204346), (0, 0.34089604765176773, 0.59560227394104, 0.6349721401929855, 0.6902563571929932)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_1103.png: 640x480 1 Topwear, 75.6ms\n",
      "Speed: 2.3ms preprocess, 75.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas_1103.png\n",
      "Annotations: [(0, 0.501629339531064, 0.508939728140831, 0.8990460895001888, 0.9414887726306915)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_231.png: 640x448 1 Bottomwear, 67.7ms\n",
      "Speed: 1.3ms preprocess, 67.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jeans_231.png\n",
      "Annotations: [(1, 0.5028569400310516, 0.5026977211236954, 0.7049484848976135, 0.9459602534770966)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1132.png: 640x512 1 Bottomwear, 81.5ms\n",
      "Speed: 1.8ms preprocess, 81.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_1132.png\n",
      "Annotations: [(1, 0.5184398368000984, 0.506232500076294, 0.5961891263723373, 0.9030711650848389)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4288.png: 640x512 1 Topwear, 79.7ms\n",
      "Speed: 2.3ms preprocess, 79.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4288.png\n",
      "Annotations: [(0, 0.49356962367892265, 0.47841282188892365, 0.7471400275826454, 0.6594229638576508)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_1885.png: 640x480 1 Topwear, 91.2ms\n",
      "Speed: 2.0ms preprocess, 91.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jerseys_1885.png\n",
      "Annotations: [(0, 0.4978448301553726, 0.4097321182489395, 0.6298289000988007, 0.5826612412929535)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_275.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 121.9ms\n",
      "Speed: 1.8ms preprocess, 121.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_275.png\n",
      "Annotations: [(2, 0.44434989988803864, 0.8281830549240112, 0.1259762942790985, 0.1605987548828125), (2, 0.5656653940677643, 0.889387845993042, 0.14831656217575073, 0.18838465213775635), (1, 0.5065701454877853, 0.44362926483154297, 0.3494105637073517, 0.74365234375)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_2444.png: 640x512 1 Bottomwear, 79.3ms\n",
      "Speed: 1.9ms preprocess, 79.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_2444.png\n",
      "Annotations: [(1, 0.49683384597301483, 0.505212128162384, 0.4988233149051666, 0.7941111326217651)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2009.png: 640x512 1 Bottomwear, 77.5ms\n",
      "Speed: 1.7ms preprocess, 77.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_2009.png\n",
      "Annotations: [(1, 0.49908848479390144, 0.5122913867235184, 0.796531043946743, 0.5680006444454193)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_3689.png: 640x448 1 Topwear, 74.8ms\n",
      "Speed: 1.4ms preprocess, 74.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisetas_3689.png\n",
      "Annotations: [(0, 0.4979623481631279, 0.5057634860277176, 0.8920369297266006, 0.6469925343990326)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_2517.png: 640x640 1 Footwear, 98.0ms\n",
      "Speed: 1.9ms preprocess, 98.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_2517.png\n",
      "Annotations: [(2, 0.495555579662323, 0.48311641812324524, 0.3256288766860962, 0.1556437611579895)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_3513.png: 640x448 1 Topwear, 1 Bottomwear, 74.6ms\n",
      "Speed: 4.3ms preprocess, 74.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_3513.png\n",
      "Annotations: [(1, 0.5231944099068642, 0.8877399563789368, 0.5877056568861008, 0.22452008724212646), (0, 0.6324040591716766, 0.5113314241170883, 0.7351918816566467, 0.633609801530838)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botas_570.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 82.2ms\n",
      "Speed: 1.9ms preprocess, 82.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_botas_570.png\n",
      "Annotations: [(2, 0.4725794643163681, 0.8567350208759308, 0.15365663170814514, 0.2134128212928772), (1, 0.4742504432797432, 0.12513521313667297, 0.4919372648000717, 0.2256036400794983), (2, 0.5689556002616882, 0.5648043304681778, 0.19741666316986084, 0.6086523234844208), (2, 0.41668760776519775, 0.5693213865160942, 0.2143545150756836, 0.6908610016107559)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_2022.png: 640x544 1 Topwear, 96.2ms\n",
      "Speed: 5.3ms preprocess, 96.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_vestidos_2022.png\n",
      "Annotations: [(0, 0.48187610507011414, 0.5725255683064461, 0.7212463021278381, 0.7438224405050278)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_1009.png: 640x640 1 Topwear, 115.7ms\n",
      "Speed: 2.7ms preprocess, 115.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_abrigos_1009.png\n",
      "Annotations: [(0, 0.49803008139133453, 0.48734255135059357, 0.6749789416790009, 0.9147845208644867)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_cardigans_137.png: 640x480 1 Topwear, 77.3ms\n",
      "Speed: 1.7ms preprocess, 77.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_cardigans_137.png\n",
      "Annotations: [(0, 0.5294512137770653, 0.6271234005689621, 0.7923100739717484, 0.6936337053775787)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5193.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 91.0ms\n",
      "Speed: 1.8ms preprocess, 91.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_5193.png\n",
      "Annotations: [(2, 0.04445250378921628, 0.8643175363540649, 0.0772780915722251, 0.11935412883758545), (2, 0.262752890586853, 0.8548415303230286, 0.08078527450561523, 0.11850273609161377), (0, 0.14571228623390198, 0.26531320810317993, 0.29142457246780396, 0.2065417766571045), (1, 0.18625744618475437, 0.5493574440479279, 0.3181281201541424, 0.44133347272872925)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_2196.png: 640x512 2 Topwears, 1 Bottomwear, 2 Footwears, 77.8ms\n",
      "Speed: 1.9ms preprocess, 77.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_2196.png\n",
      "Annotations: [(2, 0.4941646605730057, 0.9069671034812927, 0.0856451690196991, 0.12141168117523193), (2, 0.2377450093626976, 0.9098848104476929, 0.12610222399234772, 0.1101304292678833), (0, 0.4107721745967865, 0.39931057393550873, 0.31655246019363403, 0.3131040632724762), (1, 0.38703154027462006, 0.6700260639190674, 0.3648245632648468, 0.43063604831695557)]\n",
      "Detections: ['original_image', 'footwear', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_4280.png: 640x512 1 Topwear, 1 Bottomwear, 92.1ms\n",
      "Speed: 1.9ms preprocess, 92.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_4280.png\n",
      "Annotations: [(1, 0.5034489631652832, 0.9025616347789764, 0.47158944606781006, 0.19487673044204712), (0, 0.58769091963768, 0.5730177164077759, 0.5462409853935242, 0.7147880792617798)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_750.png: 640x512 1 Topwear, 81.4ms\n",
      "Speed: 2.2ms preprocess, 81.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_750.png\n",
      "Annotations: [(0, 0.8574592769145966, 0.2116941660642624, 0.21881037950515747, 0.20710709691047668), (0, 0.7885275483131409, 0.5015091150999069, 0.42294490337371826, 0.8039099276065826)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5185.png: 640x480 1 Topwear, 89.1ms\n",
      "Speed: 1.9ms preprocess, 89.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas-y-blusas_5185.png\n",
      "Annotations: [(0, 0.4892357066273689, 0.372833251953125, 0.7493724673986435, 0.511979341506958)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_503.png: 640x480 1 Topwear, 1 Bottomwear, 73.0ms\n",
      "Speed: 2.6ms preprocess, 73.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas_503.png\n",
      "Annotations: [(0, 0.5694312453269958, 0.3729586750268936, 0.8574732542037964, 0.6978243291378021)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5853.png: 640x512 1 Topwear, 1 Bottomwear, 75.4ms\n",
      "Speed: 1.9ms preprocess, 75.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_5853.png\n",
      "Annotations: [(1, 0.4708010405302048, 0.792955756187439, 0.4287382662296295, 0.40181469917297363), (0, 0.47952238470315933, 0.4829205796122551, 0.4740547388792038, 0.6218496710062027)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4598.png: 640x544 1 Topwear, 100.6ms\n",
      "Speed: 1.9ms preprocess, 100.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_vestidos_4598.png\n",
      "Annotations: [(0, 0.501902237534523, 0.5062337964773178, 0.5286945998668671, 0.7199364006519318)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4910.png: 640x512 1 Topwear, 1 Bottomwear, 1 Footwear, 80.6ms\n",
      "Speed: 1.9ms preprocess, 80.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4910.png\n",
      "Annotations: [(2, 0.3076908588409424, 0.9072785079479218, 0.10644388198852539, 0.13473206758499146), (0, 0.24619977176189423, 0.29852401465177536, 0.29023846983909607, 0.2795523554086685), (1, 0.2620515376329422, 0.6247628331184387, 0.284528523683548, 0.49106931686401367)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_554.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 97.6ms\n",
      "Speed: 2.0ms preprocess, 97.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_554.png\n",
      "Annotations: [(2, 0.6060711741447449, 0.8179972469806671, 0.12590551376342773, 0.15777939558029175), (2, 0.3879854828119278, 0.858811616897583, 0.13138356804847717, 0.15359783172607422), (0, 0.49616739153862, 0.09293323755264282, 0.4326559901237488, 0.1356995701789856), (1, 0.5024548023939133, 0.4235859662294388, 0.3783150017261505, 0.720725029706955)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5099.png: 640x640 1 Bottomwear, 111.5ms\n",
      "Speed: 3.0ms preprocess, 111.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_pantalones_5099.png\n",
      "Annotations: [(1, 0.5051477402448654, 0.4947654455900192, 0.33136263489723206, 0.9807094633579254)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_328.png: 640x544 1 Footwear, 86.5ms\n",
      "Speed: 3.0ms preprocess, 86.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sandalias_328.png\n",
      "Annotations: [(2, 0.502001129090786, 0.6356611251831055, 0.5258553773164749, 0.2962169647216797)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_3167.png: 640x512 1 Topwear, 1 Bottomwear, 80.3ms\n",
      "Speed: 1.9ms preprocess, 80.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_3167.png\n",
      "Annotations: [(1, 0.49526630342006683, 0.8976047933101654, 0.4807824194431305, 0.2047904133796692), (0, 0.47975829243659973, 0.5333988964557648, 0.5842590928077698, 0.675728976726532)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_bodies_34.png: 640x544 1 Topwear, 1 Bottomwear, 95.6ms\n",
      "Speed: 1.7ms preprocess, 95.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_bodies_34.png\n",
      "Annotations: [(1, 0.5287731066346169, 0.857864499092102, 0.570626899600029, 0.2802734375), (0, 0.5648428648710251, 0.5549832731485367, 0.46423009037971497, 0.5585984885692596)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_2632.png: 640x544 1 Topwear, 1 Bottomwear, 79.8ms\n",
      "Speed: 2.3ms preprocess, 79.8ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisas-y-blusas_2632.png\n",
      "Annotations: [(0, 0.32023632526397705, 0.43500468134880066, 0.31254488229751587, 0.47349244356155396), (1, 0.30916186049580574, 0.7545305788516998, 0.4071129187941551, 0.49093884229660034)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5538.png: 640x448 1 Topwear, 78.3ms\n",
      "Speed: 1.3ms preprocess, 78.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_abrigos_5538.png\n",
      "Annotations: [(0, 0.5025330372154713, 0.5107046961784363, 0.9182291850447655, 0.7482800483703613)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_1101.png: 640x512 1 Topwear, 1 Bottomwear, 79.7ms\n",
      "Speed: 1.9ms preprocess, 79.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_1101.png\n",
      "Annotations: [(1, 0.5753819793462753, 0.9082586467266083, 0.4157121479511261, 0.18348270654678345), (0, 0.5192265808582306, 0.5646836161613464, 0.7670090794563293, 0.7261776924133301)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5768.png: 640x512 1 Topwear, 1 Bottomwear, 99.1ms\n",
      "Speed: 2.0ms preprocess, 99.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_5768.png\n",
      "Annotations: [(1, 0.4309369698166847, 0.9128071665763855, 0.42358772456645966, 0.16226470470428467), (0, 0.4645335339009762, 0.557270273566246, 0.7419702485203743, 0.7726953327655792)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_407.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 81.6ms\n",
      "Speed: 2.0ms preprocess, 81.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sandalias_407.png\n",
      "Annotations: [(2, 0.3929256722331047, 0.7040976583957672, 0.35862602293491364, 0.1428038477897644), (2, 0.6613223254680634, 0.7007359266281128, 0.28295737504959106, 0.24050569534301758), (1, 0.4211243838071823, 0.30215196311473846, 0.5455775558948517, 0.5896765291690826)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_1895.png: 640x480 1 Topwear, 91.3ms\n",
      "Speed: 1.8ms preprocess, 91.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_1895.png\n",
      "Annotations: [(0, 0.5058336481451988, 0.48477649688720703, 0.8431398421525955, 0.8339934349060059)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5771.png: 640x512 1 Topwear, 80.2ms\n",
      "Speed: 1.8ms preprocess, 80.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_5771.png\n",
      "Annotations: [(0, 0.4963906444609165, 0.4846615195274353, 0.9088964387774467, 0.9106453657150269)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2174.png: 640x448 1 Topwear, 82.3ms\n",
      "Speed: 1.3ms preprocess, 82.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jerseys_2174.png\n",
      "Annotations: [(0, 0.48520076368004084, 0.48371367156505585, 0.9132816772907972, 0.8112706243991852)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2493.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 78.3ms\n",
      "Speed: 2.4ms preprocess, 78.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_2493.png\n",
      "Annotations: [(2, 0.2887527644634247, 0.8959243297576904, 0.09234791994094849, 0.10208725929260254), (2, 0.43793945014476776, 0.9200021326541901, 0.13284841179847717, 0.10586494207382202), (1, 0.32492849975824356, 0.4497392624616623, 0.24209915101528168, 0.14386561512947083), (0, 0.35846904665231705, 0.27364739775657654, 0.30014507472515106, 0.25224024057388306)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5402.png: 640x448 1 Topwear, 67.6ms\n",
      "Speed: 1.3ms preprocess, 67.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_vestidos_5402.png\n",
      "Annotations: [(0, 0.4992484115064144, 0.4968868624418974, 0.8369289115071297, 0.9130351282656193)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_3316.png: 640x512 1 Topwear, 1 Bottomwear, 89.0ms\n",
      "Speed: 1.9ms preprocess, 89.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_3316.png\n",
      "Annotations: [(1, 0.4275882765650749, 0.9133711457252502, 0.4293415695428848, 0.1732577085494995), (0, 0.44273098558187485, 0.5499671846628189, 0.6212496310472488, 0.7118725478649139)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_1508.png: 640x512 1 Topwear, 1 Bottomwear, 79.4ms\n",
      "Speed: 1.9ms preprocess, 79.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_1508.png\n",
      "Annotations: [(1, 0.7762342393398285, 0.8164598047733307, 0.447531521320343, 0.3670803904533386), (0, 0.7122824043035507, 0.49686671048402786, 0.5754351913928986, 0.5465271323919296)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4565.png: 640x512 1 Topwear, 1 Bottomwear, 1 Footwear, 104.2ms\n",
      "Speed: 1.9ms preprocess, 104.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4565.png\n",
      "Annotations: [(2, 0.6196123957633972, 0.9457651376724243, 0.11988306045532227, 0.08820819854736328), (0, 0.6225868165493011, 0.2579568326473236, 0.19460171461105347, 0.18506431579589844), (1, 0.623459056019783, 0.6430093050003052, 0.24774369597434998, 0.617798924446106)]\n",
      "Detections: ['original_image', 'topwear', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2100.png: 640x512 1 Bottomwear, 79.5ms\n",
      "Speed: 1.7ms preprocess, 79.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_2100.png\n",
      "Annotations: [(1, 0.4941563233733177, 0.4745195657014847, 0.7018227130174637, 0.4451194703578949)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_265.png: 640x544 1 Topwear, 98.9ms\n",
      "Speed: 1.8ms preprocess, 98.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_monos_265.png\n",
      "Annotations: [(0, 0.4989040121436119, 0.5123946741223335, 0.5357057601213455, 0.647207960486412)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1491.png: 640x480 1 Topwear, 73.3ms\n",
      "Speed: 1.7ms preprocess, 73.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jeans_1491.png\n",
      "Annotations: [(0, 0.498499371111393, 0.5258067846298218, 0.9129856079816818, 0.8647036552429199)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5643.png: 640x480 1 Topwear, 82.5ms\n",
      "Speed: 1.9ms preprocess, 82.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas-y-blusas_5643.png\n",
      "Annotations: [(0, 0.48808978497982025, 0.5162787437438965, 0.7134737074375153, 0.7982728481292725)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_1965.png: 640x640 1 Topwear, 92.0ms\n",
      "Speed: 2.7ms preprocess, 92.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_abrigos_1965.png\n",
      "Annotations: [(0, 0.5055617094039917, 0.4795888513326645, 0.6354595422744751, 0.8324814140796661)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_1985.png: 640x512 1 Topwear, 1 Bottomwear, 97.2ms\n",
      "Speed: 1.8ms preprocess, 97.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_1985.png\n",
      "Annotations: [(0, 0.4999142438173294, 0.591354489326477, 0.46646174788475037, 0.7072130441665649)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_3710.png: 640x512 1 Bottomwear, 2 Footwears, 79.9ms\n",
      "Speed: 2.3ms preprocess, 79.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_3710.png\n",
      "Annotations: [(2, 0.4109097123146057, 0.8671835660934448, 0.15531253814697266, 0.20509374141693115), (2, 0.6024318635463715, 0.7204069495201111, 0.14315801858901978, 0.2469162940979004), (1, 0.5048380941152573, 0.21328307688236237, 0.4866946041584015, 0.35496601462364197)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_polos_401.png: 640x544 1 Topwear, 1 Bottomwear, 96.0ms\n",
      "Speed: 1.7ms preprocess, 96.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_polos_401.png\n",
      "Annotations: [(0, 0.4996912032365799, 0.5899133235216141, 0.6854322850704193, 0.6716288030147552)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_139.png: 640x512 1 Bottomwear, 85.4ms\n",
      "Speed: 2.3ms preprocess, 85.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_139.png\n",
      "Annotations: [(1, 0.508111946284771, 0.5065370928496122, 0.5795443207025528, 0.9173366762697697)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4429.png: 640x544 1 Bottomwear, 92.2ms\n",
      "Speed: 1.6ms preprocess, 92.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_jeans_4429.png\n",
      "Annotations: [(1, 0.4862663000822067, 0.5227230489253998, 0.505421906709671, 0.7698339819908142)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_3041.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 88.5ms\n",
      "Speed: 1.9ms preprocess, 88.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_3041.png\n",
      "Annotations: [(2, 0.6625247597694397, 0.8191259205341339, 0.2622523307800293, 0.1326717734336853), (2, 0.36743589490652084, 0.8664732575416565, 0.24269463121891022, 0.15707659721374512), (0, 0.5602125376462936, 0.12285778671503067, 0.607997328042984, 0.24116431176662445), (1, 0.5649739801883698, 0.4824841767549515, 0.3679824471473694, 0.628244012594223)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5438.png: 640x512 1 Topwear, 1 Bottomwear, 78.8ms\n",
      "Speed: 1.8ms preprocess, 78.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_5438.png\n",
      "Annotations: [(1, 0.6255123317241669, 0.8917016983032227, 0.45313721895217896, 0.207794189453125), (0, 0.6081588417291641, 0.5518268793821335, 0.5926778018474579, 0.6013781130313873)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botines_287.png: 640x448 1 Footwear, 85.3ms\n",
      "Speed: 1.5ms preprocess, 85.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_botines_287.png\n",
      "Annotations: [(2, 0.4899011552333832, 0.49566249549388885, 0.9340335726737976, 0.5464383661746979)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4575.png: 640x512 1 Topwear, 1 Bottomwear, 83.5ms\n",
      "Speed: 1.8ms preprocess, 83.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4575.png\n",
      "Annotations: [(1, 0.41742462664842606, 0.9112389981746674, 0.521545872092247, 0.17752200365066528), (0, 0.4694943353533745, 0.5649967342615128, 0.6037666946649551, 0.6920208632946014)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1792.png: 640x512 1 Bottomwear, 2 Footwears, 99.1ms\n",
      "Speed: 1.9ms preprocess, 99.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_1792.png\n",
      "Annotations: [(2, 0.7290347516536713, 0.6786004602909088, 0.31251245737075806, 0.30146294832229614), (2, 0.31521087884902954, 0.6590607762336731, 0.5086021423339844, 0.28026115894317627), (1, 0.5841600522398949, 0.2524045705795288, 0.7803234606981277, 0.501237154006958)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1763.png: 640x512 1 Bottomwear, 2 Footwears, 83.1ms\n",
      "Speed: 2.3ms preprocess, 83.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_1763.png\n",
      "Annotations: [(2, 0.32142060436308384, 0.5981687903404236, 0.5560872666537762, 0.24421393871307373), (2, 0.6574938595294952, 0.6687231659889221, 0.6160388588905334, 0.363979697227478), (1, 0.5242777913808823, 0.26341497898101807, 0.6453448832035065, 0.5146827697753906)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1546.png: 640x512 1 Bottomwear, 97.2ms\n",
      "Speed: 1.7ms preprocess, 97.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_1546.png\n",
      "Annotations: [(1, 0.5156756043434143, 0.5068666338920593, 0.6610604524612427, 0.8928678035736084)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_349.png: 640x512 1 Bottomwear, 81.4ms\n",
      "Speed: 1.8ms preprocess, 81.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_349.png\n",
      "Annotations: [(1, 0.49647989869117737, 0.5179551094770432, 0.4740191102027893, 0.7357570230960846)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1580.png: 640x544 1 Topwear, 99.3ms\n",
      "Speed: 1.6ms preprocess, 99.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_vestidos_1580.png\n",
      "Annotations: [(0, 0.42666859179735184, 0.5572016388177872, 0.6019039005041122, 0.7329261004924774)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_711.png: 640x512 1 Bottomwear, 2 Footwears, 81.1ms\n",
      "Speed: 1.9ms preprocess, 81.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_711.png\n",
      "Annotations: [(2, 0.47731323540210724, 0.9105975329875946, 0.14601334929466248, 0.1788049340248108), (2, 0.5639276057481766, 0.7511807084083557, 0.13567015528678894, 0.2047109603881836), (1, 0.5007040947675705, 0.2930849492549896, 0.4381559193134308, 0.33368170261383057)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_4548.png: 640x512 1 Topwear, 1 Bottomwear, 87.9ms\n",
      "Speed: 1.8ms preprocess, 87.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_4548.png\n",
      "Annotations: [(1, 0.23370474390685558, 0.879837304353714, 0.3931177891790867, 0.24032539129257202), (0, 0.3054359080269933, 0.5163659304380417, 0.589030122384429, 0.6638435423374176)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_3645.png: 640x640 1 Topwear, 1 Bottomwear, 102.6ms\n",
      "Speed: 2.0ms preprocess, 102.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_camisetas_3645.png\n",
      "Annotations: [(1, 0.522976353764534, 0.8190770745277405, 0.337503045797348, 0.3578137159347534), (0, 0.49629485607147217, 0.45082223415374756, 0.42673373222351074, 0.47914373874664307)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_2053.png: 640x512 1 Topwear, 1 Bottomwear, 94.3ms\n",
      "Speed: 1.9ms preprocess, 94.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_2053.png\n",
      "Annotations: [(1, 0.2756456099450588, 0.8258554637432098, 0.3818799927830696, 0.2443181872367859), (0, 0.333497978746891, 0.4513004720211029, 0.5032513588666916, 0.650111973285675)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_540.png: 640x544 1 Topwear, 92.6ms\n",
      "Speed: 2.2ms preprocess, 92.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sudaderas_540.png\n",
      "Annotations: [(0, 0.5144691616296768, 0.5023920238018036, 0.7413729131221771, 0.6499703526496887)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_2192.png: 640x512 1 Bottomwear, 83.9ms\n",
      "Speed: 1.9ms preprocess, 83.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_2192.png\n",
      "Annotations: [(1, 0.49004335701465607, 0.4816649407148361, 0.3479336202144623, 0.6424302160739899)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5640.png: 640x448 1 Topwear, 83.5ms\n",
      "Speed: 1.9ms preprocess, 83.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_abrigos_5640.png\n",
      "Annotations: [(0, 0.5038428567349911, 0.4946755915880203, 0.8172448351979256, 0.67426797747612)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_3133.png: 640x448 1 Topwear, 1 Bottomwear, 2 Footwears, 66.4ms\n",
      "Speed: 2.1ms preprocess, 66.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jeans_3133.png\n",
      "Annotations: [(2, 0.5770068913698196, 0.9154954254627228, 0.16398271918296814, 0.1454656720161438), (2, 0.12628869200125337, 0.9007698893547058, 0.23230827879160643, 0.14756286144256592), (0, 0.5136441886425018, 0.07185299322009087, 0.5950763821601868, 0.14184973388910294), (1, 0.41664229333400726, 0.47557365894317627, 0.667276531457901, 0.8194128274917603)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_288.png: 640x512 2 Footwears, 101.9ms\n",
      "Speed: 2.3ms preprocess, 101.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sandalias_288.png\n",
      "Annotations: [(2, 0.6080762594938278, 0.6515129804611206, 0.2941342890262604, 0.369900107383728), (2, 0.29709499329328537, 0.5445785969495773, 0.3455705791711807, 0.39619365334510803)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_937.png: 640x640 1 Bottomwear, 100.1ms\n",
      "Speed: 2.0ms preprocess, 100.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_shorts_937.png\n",
      "Annotations: [(1, 0.4434162527322769, 0.4686238169670105, 0.5506241023540497, 0.6133517026901245)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_897.png: 640x480 1 Bottomwear, 90.3ms\n",
      "Speed: 2.1ms preprocess, 90.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_faldas_897.png\n",
      "Annotations: [(1, 0.4852560982108116, 0.5011326111853123, 0.6321032792329788, 0.7664197608828545)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_3987.png: 640x480 1 Topwear, 73.1ms\n",
      "Speed: 1.8ms preprocess, 73.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_3987.png\n",
      "Annotations: [(0, 0.4984054509550333, 0.5302611142396927, 0.9198160283267498, 0.8765996396541595)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_1094.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 86.3ms\n",
      "Speed: 2.5ms preprocess, 86.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_1094.png\n",
      "Annotations: [(2, 0.6107776165008545, 0.747262567281723, 0.1369084119796753, 0.23049980401992798), (2, 0.42192424833774567, 0.8897110819816589, 0.20635482668876648, 0.15375781059265137), (1, 0.46288522332906723, 0.2416001409292221, 0.43908388912677765, 0.35426703095436096)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatos_1038.png: 640x512 2 Footwears, 88.0ms\n",
      "Speed: 1.8ms preprocess, 88.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatos_1038.png\n",
      "Annotations: [(2, 0.587885856628418, 0.5900248289108276, 0.21097028255462646, 0.42331135272979736), (2, 0.3588629961013794, 0.5899676233530045, 0.35029852390289307, 0.4432623088359833)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_3664.png: 640x480 1 Topwear, 1 Bottomwear, 74.9ms\n",
      "Speed: 1.5ms preprocess, 74.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas-y-blusas_3664.png\n",
      "Annotations: [(0, 0.5, 0.4218886196613312, 1.0, 0.8437772393226624)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_2917.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 95.3ms\n",
      "Speed: 1.9ms preprocess, 95.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_2917.png\n",
      "Annotations: [(2, 0.3705641031265259, 0.836881697177887, 0.11547702550888062, 0.12564599514007568), (2, 0.5903552770614624, 0.8751609325408936, 0.1502135992050171, 0.1153256893157959), (1, 0.47364671528339386, 0.45216695964336395, 0.35690054297447205, 0.738434225320816)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_2008.png: 640x480 1 Topwear, 71.2ms\n",
      "Speed: 1.7ms preprocess, 71.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_pantalones_2008.png\n",
      "Annotations: [(0, 0.505258796736598, 0.5038827806711197, 0.9748742617666721, 0.8253006637096405)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5936.png: 640x544 1 Topwear, 103.3ms\n",
      "Speed: 1.8ms preprocess, 103.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisas-y-blusas_5936.png\n",
      "Annotations: [(0, 0.5005499348044395, 0.5051261186599731, 0.6071975976228714, 0.655016303062439)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_tacones_918.png: 640x512 2 Footwears, 78.6ms\n",
      "Speed: 1.9ms preprocess, 78.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_tacones_918.png\n",
      "Annotations: [(2, 0.5745106339454651, 0.609740823507309, 0.6194398403167725, 0.5525534749031067)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_888.png: 640x512 2 Footwears, 87.5ms\n",
      "Speed: 2.0ms preprocess, 87.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sandalias_888.png\n",
      "Annotations: [(2, 0.7062823325395584, 0.6607301384210587, 0.5568192899227142, 0.3351249396800995)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_1033.png: 640x512 1 Topwear, 1 Bottomwear, 84.1ms\n",
      "Speed: 1.9ms preprocess, 84.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_1033.png\n",
      "Annotations: [(0, 0.6625682413578033, 0.5958482772111893, 0.5784013867378235, 0.7888031899929047)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_494.png: 640x512 1 Topwear, 1 Bottomwear, 77.8ms\n",
      "Speed: 2.1ms preprocess, 77.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_494.png\n",
      "Annotations: [(1, 0.26646172627806664, 0.9013850092887878, 0.34089983254671097, 0.19722998142242432), (0, 0.28654884174466133, 0.5764483660459518, 0.4961005672812462, 0.6454668343067169)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5497.png: 640x512 1 Topwear, 92.5ms\n",
      "Speed: 1.8ms preprocess, 92.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_5497.png\n",
      "Annotations: [(0, 0.5031364858150482, 0.4560092091560364, 0.614777147769928, 0.675500750541687)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1206.png: 640x512 1 Topwear, 77.1ms\n",
      "Speed: 1.9ms preprocess, 77.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_1206.png\n",
      "Annotations: [(0, 0.22171099949628115, 0.5639060884714127, 0.40852673910558224, 0.8207983672618866)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1650.png: 640x640 1 Topwear, 113.5ms\n",
      "Speed: 1.9ms preprocess, 113.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_sudaderas_1650.png\n",
      "Annotations: [(0, 0.5037720203399658, 0.49988049268722534, 0.6044116020202637, 0.9210549592971802)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_polos_421.png: 640x448 1 Topwear, 1 Bottomwear, 70.1ms\n",
      "Speed: 2.1ms preprocess, 70.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_polos_421.png\n",
      "Annotations: [(1, 0.4838712215423584, 0.8768401741981506, 0.4988757371902466, 0.24631965160369873), (0, 0.5204180628061295, 0.5159114003181458, 0.6420221030712128, 0.5918796062469482)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_2073.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 93.4ms\n",
      "Speed: 1.9ms preprocess, 93.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_2073.png\n",
      "Annotations: [(2, 0.5619618147611618, 0.8686428964138031, 0.12889423966407776, 0.11966174840927124), (2, 0.29616105556488037, 0.8679598867893219, 0.17577332258224487, 0.11655610799789429), (1, 0.4247029274702072, 0.4401588439941406, 0.393476277589798, 0.7652689218521118)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_1161.png: 640x448 1 Topwear, 74.8ms\n",
      "Speed: 1.4ms preprocess, 74.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_1161.png\n",
      "Annotations: [(0, 0.4985053092241287, 0.4989132881164551, 0.9226073920726776, 0.7949721813201904)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_cardigans_309.png: 640x512 1 Topwear, 1 Bottomwear, 79.8ms\n",
      "Speed: 1.9ms preprocess, 79.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_cardigans_309.png\n",
      "Annotations: [(1, 0.2733144983649254, 0.8007790744304657, 0.364409938454628, 0.38677865266799927), (0, 0.2725513302721083, 0.5609282851219177, 0.5140820099040866, 0.6016325950622559)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_bodies_314.png: 640x512 1 Topwear, 1 Bottomwear, 97.1ms\n",
      "Speed: 1.8ms preprocess, 97.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_bodies_314.png\n",
      "Annotations: [(1, 0.623777911067009, 0.7513962388038635, 0.59654501080513, 0.4398765563964844), (0, 0.60470861941576, 0.4193051904439926, 0.7905827611684799, 0.5421083271503448)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_4167.png: 640x512 1 Topwear, 1 Bottomwear, 78.7ms\n",
      "Speed: 2.0ms preprocess, 78.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_4167.png\n",
      "Annotations: [(1, 0.5154004096984863, 0.9346973598003387, 0.4122753143310547, 0.1306052803993225), (0, 0.5119112879037857, 0.6202471256256104, 0.7147296369075775, 0.7595057487487793)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_3032.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 77.5ms\n",
      "Speed: 1.8ms preprocess, 77.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_3032.png\n",
      "Annotations: [(2, 0.6116130650043488, 0.8633899688720703, 0.13359957933425903, 0.11052405834197998), (2, 0.41559647023677826, 0.8721212446689606, 0.14462372660636902, 0.11769455671310425), (1, 0.6006752401590347, 0.4737109839916229, 0.2574402987957001, 0.1329147219657898), (0, 0.6095782220363617, 0.34177467226982117, 0.3706069588661194, 0.4009625315666199)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_1614.png: 640x448 1 Topwear, 71.1ms\n",
      "Speed: 5.3ms preprocess, 71.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_trajes_1614.png\n",
      "Annotations: [(0, 0.49063316732645035, 0.49971315264701843, 0.8950399607419968, 0.7051820158958435)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_778.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 80.8ms\n",
      "Speed: 2.0ms preprocess, 80.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_778.png\n",
      "Annotations: [(2, 0.6142465174198151, 0.9284616112709045, 0.10582774877548218, 0.10356748104095459), (2, 0.8225647509098053, 0.8864063024520874, 0.13019591569900513, 0.10550975799560547), (0, 0.7840033173561096, 0.2543255016207695, 0.2404388189315796, 0.21941722929477692), (1, 0.8076484501361847, 0.4425627738237381, 0.27952510118484497, 0.2305874526500702), (0, 0.7914785444736481, 0.3490306884050369, 0.341392457485199, 0.37611159682273865)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_2679.png: 640x480 1 Topwear, 87.5ms\n",
      "Speed: 1.7ms preprocess, 87.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_sudaderas_2679.png\n",
      "Annotations: [(0, 0.4982055500149727, 0.4516884684562683, 0.8778883069753647, 0.8606623411178589)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_polos_77.png: 640x544 1 Topwear, 1 Bottomwear, 81.2ms\n",
      "Speed: 1.8ms preprocess, 81.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_polos_77.png\n",
      "Annotations: [(0, 0.5021283179521561, 0.5973331928253174, 0.7157276570796967, 0.7557591199874878)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_tacones_33.png: 640x512 1 Bottomwear, 2 Footwears, 91.9ms\n",
      "Speed: 2.0ms preprocess, 91.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_tacones_33.png\n",
      "Annotations: [(2, 0.34412831813097, 0.5551559925079346, 0.47970329225063324, 0.45847392082214355), (2, 0.7002307027578354, 0.5579609274864197, 0.46547678112983704, 0.4871894121170044), (1, 0.5038826242089272, 0.19114574790000916, 0.8522811383008957, 0.35891711711883545)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_990.png: 640x448 1 Topwear, 71.9ms\n",
      "Speed: 1.8ms preprocess, 71.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_abrigos_990.png\n",
      "Annotations: [(0, 0.4886211073026061, 0.5040444731712341, 0.9336918760091066, 0.7257846593856812)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4513.png: 640x512 1 Topwear, 77.4ms\n",
      "Speed: 1.7ms preprocess, 77.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_4513.png\n",
      "Annotations: [(0, 0.4991631358861923, 0.4773130267858505, 0.7309097349643707, 0.6127209961414337)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_2084.png: 640x512 1 Bottomwear, 2 Footwears, 95.6ms\n",
      "Speed: 1.9ms preprocess, 95.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_2084.png\n",
      "Annotations: [(2, 0.7133868634700775, 0.7033888697624207, 0.2583853602409363, 0.29877424240112305), (2, 0.30642789229750633, 0.6208954453468323, 0.49943888932466507, 0.2280799150466919), (1, 0.6122518628835678, 0.29274556040763855, 0.7017989456653595, 0.5854911208152771)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_968.png: 640x512 1 Bottomwear, 2 Footwears, 76.5ms\n",
      "Speed: 1.9ms preprocess, 76.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sandalias_968.png\n",
      "Annotations: [(2, 0.3295716680586338, 0.7229203581809998, 0.4763779565691948, 0.40149807929992676), (1, 0.42393400706350803, 0.2563468664884567, 0.7766096107661724, 0.5100721418857574)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_1225.png: 640x512 1 Topwear, 1 Bottomwear, 88.3ms\n",
      "Speed: 1.9ms preprocess, 88.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_1225.png\n",
      "Annotations: [(0, 0.5865863114595413, 0.5936759859323502, 0.49964019656181335, 0.6872133910655975)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_466.png: 640x512 1 Topwear, 1 Bottomwear, 81.6ms\n",
      "Speed: 2.5ms preprocess, 81.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_466.png\n",
      "Annotations: [(0, 0.4919889271259308, 0.5671758353710175, 0.7427145838737488, 0.729640781879425)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5203.png: 640x512 1 Topwear, 1 Bottomwear, 80.7ms\n",
      "Speed: 1.7ms preprocess, 80.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_5203.png\n",
      "Annotations: [(1, 0.6148389726877213, 0.9363959431648254, 0.5306760966777802, 0.12720811367034912), (0, 0.6617275476455688, 0.587274506688118, 0.6679396629333496, 0.7812759578227997)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_788.png: 640x448 1 Topwear, 86.4ms\n",
      "Speed: 1.3ms preprocess, 86.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas_788.png\n",
      "Annotations: [(0, 0.5078608430922031, 0.5087934881448746, 0.9138195440173149, 0.7625486552715302)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_4334.png: 640x512 1 Topwear, 80.7ms\n",
      "Speed: 2.0ms preprocess, 80.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_4334.png\n",
      "Annotations: [(1, 0.6639640480279922, 0.8919251561164856, 0.4028874337673187, 0.17333078384399414), (0, 0.6567389369010925, 0.520256444811821, 0.5486843585968018, 0.5939742624759674)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_3496.png: 640x512 1 Topwear, 1 Bottomwear, 92.8ms\n",
      "Speed: 2.0ms preprocess, 92.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_3496.png\n",
      "Annotations: [(1, 0.6156055480241776, 0.9300342798233032, 0.4508751332759857, 0.13993144035339355), (0, 0.5978293865919113, 0.5662165880203247, 0.7064018547534943, 0.6837632656097412)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_1326.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 82.8ms\n",
      "Speed: 3.2ms preprocess, 82.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_1326.png\n",
      "Annotations: [(2, 0.31654903292655945, 0.8606033325195312, 0.11681216955184937, 0.12439203262329102), (2, 0.4833875298500061, 0.8880684077739716, 0.11321663856506348, 0.13031238317489624), (0, 0.46495574712753296, 0.13561343029141426, 0.5184577703475952, 0.23672129958868027), (1, 0.43072105944156647, 0.5131022781133652, 0.36867961287498474, 0.6492200195789337)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_2075.png: 640x512 1 Topwear, 82.8ms\n",
      "Speed: 2.0ms preprocess, 82.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_2075.png\n",
      "Annotations: [(0, 0.47428272664546967, 0.6257890462875366, 0.5195426046848297, 0.6329349279403687)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_tacones_0.png: 640x512 1 Bottomwear, 2 Footwears, 98.1ms\n",
      "Speed: 1.9ms preprocess, 98.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_tacones_0.png\n",
      "Annotations: [(2, 0.277667548507452, 0.5507457256317139, 0.34033001214265823, 0.3799881935119629), (2, 0.6255016177892685, 0.5327763259410858, 0.5038200914859772, 0.4123547673225403), (1, 0.47789342887699604, 0.19567281007766724, 0.8968585394322872, 0.37899625301361084)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_3545.png: 640x512 1 Topwear, 1 Bottomwear, 78.7ms\n",
      "Speed: 1.9ms preprocess, 78.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_3545.png\n",
      "Annotations: [(1, 0.5363675057888031, 0.8585131764411926, 0.49028271436691284, 0.2695680856704712), (0, 0.6120259910821915, 0.5601090490818024, 0.6627858579158783, 0.6682838797569275)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5379.png: 640x512 1 Bottomwear, 91.8ms\n",
      "Speed: 1.8ms preprocess, 91.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_5379.png\n",
      "Annotations: [(1, 0.5011952891945839, 0.5016352534294128, 0.519106313586235, 0.8303138017654419)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4572.png: 640x512 1 Topwear, 82.7ms\n",
      "Speed: 1.9ms preprocess, 82.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_4572.png\n",
      "Annotations: [(0, 0.5115621723234653, 0.49681997299194336, 0.84698735922575, 0.681442379951477)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botas_307.png: 640x512 1 Bottomwear, 2 Footwears, 80.4ms\n",
      "Speed: 1.9ms preprocess, 80.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_botas_307.png\n",
      "Annotations: [(2, 0.18600976467132568, 0.6084547340869904, 0.37201952934265137, 0.20981866121292114), (2, 0.5043050721287727, 0.6841849088668823, 0.6307381242513657, 0.3147789239883423), (1, 0.3773452341556549, 0.3043513596057892, 0.7546904683113098, 0.6087027192115784)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_2790.png: 640x544 1 Bottomwear, 99.1ms\n",
      "Speed: 1.8ms preprocess, 99.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_pantalones_2790.png\n",
      "Annotations: [(1, 0.505951315164566, 0.5001111179590225, 0.4945363402366638, 0.697818249464035)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5717.png: 640x448 1 Bottomwear, 68.5ms\n",
      "Speed: 1.7ms preprocess, 68.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_pantalones_5717.png\n",
      "Annotations: [(1, 0.4908255711197853, 0.5143452286720276, 0.7655328959226608, 0.7242673635482788)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_1697.png: 640x544 1 Topwear, 1 Bottomwear, 110.3ms\n",
      "Speed: 3.1ms preprocess, 110.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_shorts_1697.png\n",
      "Annotations: [(0, 0.4992339611053467, 0.28191596269607544, 0.28350770473480225, 0.25246262550354004), (1, 0.5293854027986526, 0.6792424768209457, 0.34321388602256775, 0.5406637489795685)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3450.png: 640x512 1 Topwear, 87.0ms\n",
      "Speed: 1.9ms preprocess, 87.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_3450.png\n",
      "Annotations: [(0, 0.49884530901908875, 0.5, 0.43193918466567993, 1.0)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_4094.png: 640x512 1 Topwear, 1 Bottomwear, 97.7ms\n",
      "Speed: 1.8ms preprocess, 97.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_4094.png\n",
      "Annotations: [(1, 0.4733791798353195, 0.8659306764602661, 0.3694867193698883, 0.2681386470794678), (0, 0.4621637091040611, 0.5011561065912247, 0.4782424718141556, 0.6607412993907928)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_389.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 95.5ms\n",
      "Speed: 3.6ms preprocess, 95.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_389.png\n",
      "Annotations: [(2, 0.3155721500515938, 0.919109046459198, 0.2956818789243698, 0.1241309642791748), (2, 0.7305189073085785, 0.8691371083259583, 0.19914299249649048, 0.22454392910003662), (0, 0.5045081973075867, 0.11412481218576431, 0.6803675889968872, 0.22824962437152863), (1, 0.5232455134391785, 0.4522281289100647, 0.5210050344467163, 0.7951823472976685)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4733.png: 640x640 1 Bottomwear, 121.1ms\n",
      "Speed: 2.7ms preprocess, 121.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_pantalones_4733.png\n",
      "Annotations: [(1, 0.5043400824069977, 0.5037199109792709, 0.33210664987564087, 0.9307446777820587)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_1123.png: 640x512 1 Topwear, 94.9ms\n",
      "Speed: 3.5ms preprocess, 94.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_1123.png\n",
      "Annotations: [(0, 0.5052137412130833, 0.47753602266311646, 0.802916519343853, 0.6629542112350464)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_2110.png: 640x640 1 Topwear, 1 Bottomwear, 96.8ms\n",
      "Speed: 1.8ms preprocess, 96.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_abrigos_2110.png\n",
      "Annotations: [(1, 0.49005448818206787, 0.8379802703857422, 0.28939664363861084, 0.3212764263153076), (0, 0.4945238456130028, 0.4794710725545883, 0.49655289947986603, 0.5037217438220978)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_1255.png: 640x512 1 Topwear, 88.2ms\n",
      "Speed: 1.8ms preprocess, 88.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_1255.png\n",
      "Annotations: [(0, 0.49566318094730377, 0.5039209127426147, 0.8614738881587982, 0.7395685911178589)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2577.png: 640x512 1 Topwear, 1 Bottomwear, 77.2ms\n",
      "Speed: 1.9ms preprocess, 77.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_2577.png\n",
      "Annotations: [(1, 0.5280454754829407, 0.7125098407268524, 0.40619516372680664, 0.26416558027267456), (0, 0.42706863582134247, 0.41293827444314957, 0.7019096910953522, 0.5106740444898605)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_3972.png: 640x640 1 Bottomwear, 116.9ms\n",
      "Speed: 2.6ms preprocess, 116.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_pantalones_3972.png\n",
      "Annotations: [(1, 0.5024334788322449, 0.4980514496564865, 0.3089810609817505, 0.9524182379245758)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4600.png: 640x512 1 Topwear, 81.9ms\n",
      "Speed: 1.8ms preprocess, 81.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4600.png\n",
      "Annotations: [(0, 0.5778288096189499, 0.5015131533145905, 0.5706000626087189, 0.7225702404975891)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_493.png: 640x512 1 Bottomwear, 95.6ms\n",
      "Speed: 1.8ms preprocess, 95.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_493.png\n",
      "Annotations: [(1, 0.49671613425016403, 0.4977888911962509, 0.5011716037988663, 0.7591994106769562)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_3584.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 81.0ms\n",
      "Speed: 1.8ms preprocess, 81.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_3584.png\n",
      "Annotations: [(2, 0.1806042529642582, 0.8025109171867371, 0.24038945883512497, 0.11924755573272705), (2, 0.41445934772491455, 0.8787327110767365, 0.2104661464691162, 0.14778119325637817), (0, 0.30972747318446636, 0.16333910822868347, 0.5006872750818729, 0.32667821645736694), (1, 0.33576899766921997, 0.48433463275432587, 0.3779364824295044, 0.7032450735569)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_3547.png: 640x448 1 Topwear, 69.6ms\n",
      "Speed: 1.3ms preprocess, 69.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisetas_3547.png\n",
      "Annotations: [(0, 0.4931363742798567, 0.5040608495473862, 0.8812207616865635, 0.6430661976337433)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4482.png: 640x544 1 Topwear, 1 Bottomwear, 2 Footwears, 100.5ms\n",
      "Speed: 1.7ms preprocess, 100.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_pantalones_4482.png\n",
      "Annotations: [(2, 0.5049089938402176, 0.9351720809936523, 0.09605059027671814, 0.11080622673034668), (2, 0.5336199253797531, 0.8347565829753876, 0.08857718110084534, 0.12348908185958862), (0, 0.5010414719581604, 0.2447507455945015, 0.20231902599334717, 0.1887413114309311), (1, 0.5068860501050949, 0.5744024515151978, 0.2718086540699005, 0.3938479423522949)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_1505.png: 640x512 2 Topwears, 1 Bottomwear, 78.8ms\n",
      "Speed: 2.3ms preprocess, 78.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_1505.png\n",
      "Annotations: [(1, 0.5118738561868668, 0.6782370209693909, 0.4425123631954193, 0.39274001121520996), (0, 0.4298272132873535, 0.3579653203487396, 0.859654426574707, 0.4184834361076355)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5568.png: 640x544 1 Topwear, 1 Bottomwear, 93.6ms\n",
      "Speed: 2.4ms preprocess, 93.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sudaderas_5568.png\n",
      "Annotations: [(1, 0.44692956656217575, 0.8063626885414124, 0.42366601526737213, 0.37553107738494873), (0, 0.48002708703279495, 0.551284670829773, 0.6483627408742905, 0.5867414474487305)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4721.png: 640x512 1 Topwear, 80.4ms\n",
      "Speed: 1.8ms preprocess, 80.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4721.png\n",
      "Annotations: [(0, 0.717681348323822, 0.5493480712175369, 0.4124298095703125, 0.7415741384029388)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_2319.png: 640x512 1 Bottomwear, 1 Footwear, 79.0ms\n",
      "Speed: 1.9ms preprocess, 79.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_2319.png\n",
      "Annotations: [(1, 0.507302537560463, 0.21140368282794952, 0.9439320266246796, 0.4135545790195465), (2, 0.49677244888152927, 0.655361533164978, 0.987189331324771, 0.4471491575241089)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4529.png: 640x512 1 Topwear, 93.1ms\n",
      "Speed: 10.6ms preprocess, 93.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4529.png\n",
      "Annotations: [(0, 0.7078698873519897, 0.5634015947580338, 0.5838558673858643, 0.6875004470348358)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_1928.png: 640x512 1 Topwear, 1 Bottomwear, 80.2ms\n",
      "Speed: 1.9ms preprocess, 80.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_1928.png\n",
      "Annotations: [(1, 0.3270850256085396, 0.9058966338634491, 0.5072851032018661, 0.1882067322731018), (0, 0.3389376811683178, 0.527648575603962, 0.5024923458695412, 0.6692366451025009)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_1909.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 90.5ms\n",
      "Speed: 1.9ms preprocess, 90.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_1909.png\n",
      "Annotations: [(2, 0.3462507352232933, 0.9120174646377563, 0.21809346973896027, 0.12381792068481445), (2, 0.7331348657608032, 0.7626600861549377, 0.1697465181350708, 0.21232211589813232), (1, 0.5138413906097412, 0.44046083092689514, 0.4738178253173828, 0.6734712719917297)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1007.png: 640x512 1 Topwear, 1 Bottomwear, 81.6ms\n",
      "Speed: 1.9ms preprocess, 81.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_1007.png\n",
      "Annotations: [(1, 0.40639927983283997, 0.8767886757850647, 0.4154542088508606, 0.24450147151947021), (0, 0.3829997591674328, 0.5008094534277916, 0.6610546484589577, 0.6264184266328812)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_4974.png: 640x512 1 Topwear, 1 Bottomwear, 80.8ms\n",
      "Speed: 1.8ms preprocess, 80.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_4974.png\n",
      "Annotations: [(1, 0.8172505795955658, 0.8244912624359131, 0.3654988408088684, 0.33597397804260254), (0, 0.7927033305168152, 0.4473419189453125, 0.41459333896636963, 0.5758863687515259)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4094.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 89.3ms\n",
      "Speed: 11.2ms preprocess, 89.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4094.png\n",
      "Annotations: [(2, 0.5263360440731049, 0.7938123941421509, 0.2309165596961975, 0.19073617458343506), (1, 0.46992027759552, 0.3648897260427475, 0.4306199550628662, 0.5645122826099396)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_1960.png: 640x448 1 Topwear, 1 Bottomwear, 69.6ms\n",
      "Speed: 1.5ms preprocess, 69.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas_1960.png\n",
      "Annotations: [(0, 0.5081743057817221, 0.5469381213188171, 0.9836513884365559, 0.9061237573623657)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4624.png: 640x512 1 Topwear, 1 Bottomwear, 91.1ms\n",
      "Speed: 1.9ms preprocess, 91.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4624.png\n",
      "Annotations: [(1, 0.4614289700984955, 0.825827419757843, 0.3814007639884949, 0.34834516048431396), (0, 0.47200751304626465, 0.4994817078113556, 0.6369376182556152, 0.5700560212135315)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1522.png: 640x544 1 Topwear, 1 Bottomwear, 84.4ms\n",
      "Speed: 2.2ms preprocess, 84.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sudaderas_1522.png\n",
      "Annotations: [(1, 0.4840584546327591, 0.8930187821388245, 0.44880005717277527, 0.21396243572235107), (0, 0.48039568215608597, 0.5074765086174011, 0.6069835275411606, 0.6607062816619873)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1985.png: 640x448 2 Bottomwears, 67.8ms\n",
      "Speed: 1.5ms preprocess, 67.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jeans_1985.png\n",
      "Annotations: [(1, 0.6304020434617996, 0.5158050060272217, 0.7377723157405853, 0.8998968601226807)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5875.png: 640x480 1 Topwear, 94.6ms\n",
      "Speed: 2.2ms preprocess, 94.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisetas_5875.png\n",
      "Annotations: [(0, 0.5069405660033226, 0.40180130302906036, 0.5930085927248001, 0.5679160058498383)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_1518.png: 640x480 1 Topwear, 70.7ms\n",
      "Speed: 1.8ms preprocess, 70.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jerseys_1518.png\n",
      "Annotations: [(1, 0.31338304094970226, 0.8172597289085388, 0.5953522957861423, 0.36548054218292236), (0, 0.5098768956959248, 0.5893576145172119, 0.9588167890906334, 0.5170105695724487)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_331.png: 640x480 1 Topwear, 72.2ms\n",
      "Speed: 1.9ms preprocess, 72.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_vestidos_331.png\n",
      "Annotations: [(0, 0.49843212217092514, 0.522675409913063, 0.5162121802568436, 0.8288304507732391)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1961.png: 640x448 1 Topwear, 1 Bottomwear, 2 Footwears, 78.9ms\n",
      "Speed: 2.0ms preprocess, 78.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_vestidos_1961.png\n",
      "Annotations: [(2, 0.4321727007627487, 0.9407445192337036, 0.1374892294406891, 0.10292387008666992), (2, 0.5167405307292938, 0.9000651836395264, 0.1245846152305603, 0.16919076442718506), (0, 0.49038174748420715, 0.26454871892929077, 0.3364705443382263, 0.22714591026306152), (1, 0.4667445719242096, 0.5137751400470734, 0.36889761686325073, 0.3067261576652527), (0, 0.46858543157577515, 0.41599512100219727, 0.42797374725341797, 0.5342803001403809)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_1304.png: 640x512 1 Topwear, 1 Bottomwear, 78.1ms\n",
      "Speed: 1.9ms preprocess, 78.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_1304.png\n",
      "Annotations: [(1, 0.757568359375, 0.883677065372467, 0.48249733448028564, 0.23264586925506592), (0, 0.6962187439203262, 0.5046878457069397, 0.4972638785839081, 0.6057702302932739)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_1334.png: 640x512 2 Bottomwears, 3 Footwears, 95.2ms\n",
      "Speed: 1.8ms preprocess, 95.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_1334.png\n",
      "Annotations: [(2, 0.7074938714504242, 0.9014911353588104, 0.17399173974990845, 0.15407735109329224), (2, 0.420731782913208, 0.8546925187110901, 0.2185152769088745, 0.15811359882354736), (1, 0.5980895012617111, 0.2547646164894104, 0.4053228199481964, 0.42137646675109863)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1735.png: 640x544 1 Topwear, 2 Footwears, 83.6ms\n",
      "Speed: 1.9ms preprocess, 83.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_vestidos_1735.png\n",
      "Annotations: [(2, 0.5991811156272888, 0.914251983165741, 0.08479940891265869, 0.14194297790527344), (2, 0.30738090723752975, 0.9170524179935455, 0.13739342987537384, 0.12986809015274048), (0, 0.5040332973003387, 0.2551729679107666, 0.21979469060897827, 0.21436536312103271), (0, 0.5582501143217087, 0.4175315946340561, 0.41715243458747864, 0.5203597843647003)]\n",
      "Detections: ['original_image', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5216.png: 640x512 1 Topwear, 80.8ms\n",
      "Speed: 1.9ms preprocess, 80.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_5216.png\n",
      "Annotations: [(0, 0.49869799986481667, 0.5184778273105621, 0.9512697383761406, 0.5775269865989685)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5578.png: 640x448 1 Topwear, 83.4ms\n",
      "Speed: 1.4ms preprocess, 83.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisetas_5578.png\n",
      "Annotations: [(0, 0.4803918683901429, 0.49786122143268585, 0.9320885967463255, 0.7120705544948578)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatos_105.png: 640x544 1 Footwear, 77.8ms\n",
      "Speed: 1.8ms preprocess, 77.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_zapatos_105.png\n",
      "Annotations: [(2, 0.4951654374599457, 0.7049190104007721, 0.7076261639595032, 0.18704360723495483)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_937.png: 640x448 1 Bottomwear, 66.3ms\n",
      "Speed: 1.3ms preprocess, 66.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_pantalones_937.png\n",
      "Annotations: [(1, 0.4928371533751488, 0.5029975920915604, 0.7414466887712479, 0.9299674928188324)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_3508.png: 640x512 1 Bottomwear, 96.5ms\n",
      "Speed: 1.7ms preprocess, 96.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_3508.png\n",
      "Annotations: [(1, 0.493643581867218, 0.48595570027828217, 0.3514232635498047, 0.6498583853244781)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4214.png: 640x512 1 Topwear, 76.8ms\n",
      "Speed: 2.0ms preprocess, 76.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4214.png\n",
      "Annotations: [(0, 0.8217530250549316, 0.4838950037956238, 0.3564939498901367, 0.5637449026107788)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2158.png: 640x512 1 Topwear, 93.0ms\n",
      "Speed: 1.8ms preprocess, 93.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_2158.png\n",
      "Annotations: [(0, 0.5081464760005474, 0.5001993626356125, 0.9043016210198402, 0.854398638010025)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_3047.png: 640x512 1 Footwear, 87.7ms\n",
      "Speed: 1.7ms preprocess, 87.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_3047.png\n",
      "Annotations: [(2, 0.48904936760663986, 0.5101943463087082, 0.820252314209938, 0.2670709192752838)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_437.png: 640x448 1 Topwear, 67.9ms\n",
      "Speed: 1.3ms preprocess, 67.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_vestidos_437.png\n",
      "Annotations: [(0, 0.5015048012137413, 0.5148218870162964, 0.7872104197740555, 0.9061039686203003)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5592.png: 640x544 1 Topwear, 1 Bottomwear, 2 Footwears, 82.7ms\n",
      "Speed: 1.8ms preprocess, 82.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_pantalones_5592.png\n",
      "Annotations: [(2, 0.5549878776073456, 0.9463735222816467, 0.13164430856704712, 0.09159815311431885), (2, 0.48242637515068054, 0.9137686789035797, 0.1469539999961853, 0.11386257410049438), (0, 0.5144919753074646, 0.2500813603401184, 0.20116639137268066, 0.19130390882492065), (1, 0.4810047447681427, 0.6337988525629044, 0.3037649989128113, 0.48517510294914246)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_3557.png: 640x544 1 Topwear, 1 Bottomwear, 82.3ms\n",
      "Speed: 4.7ms preprocess, 82.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sudaderas_3557.png\n",
      "Annotations: [(1, 0.5140034407377243, 0.897766649723053, 0.4623009264469147, 0.20446670055389404), (0, 0.5980683267116547, 0.5060408264398575, 0.6269206404685974, 0.6577586829662323)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_4285.png: 640x448 1 Topwear, 1 Bottomwear, 66.1ms\n",
      "Speed: 1.6ms preprocess, 66.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_4285.png\n",
      "Annotations: [(1, 0.5304429233074188, 0.8717870116233826, 0.6924833655357361, 0.25129568576812744), (0, 0.40774358343333006, 0.5800363570451736, 0.7724939379841089, 0.7071536481380463)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_2330.png: 640x512 1 Topwear, 1 Bottomwear, 90.9ms\n",
      "Speed: 1.8ms preprocess, 90.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_2330.png\n",
      "Annotations: [(0, 0.29831220116466284, 0.5865134000778198, 0.5641020257025957, 0.8269731998443604)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_4993.png: 640x448 1 Topwear, 79.5ms\n",
      "Speed: 1.2ms preprocess, 79.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_4993.png\n",
      "Annotations: [(0, 0.49968489073216915, 0.49448665976524353, 0.8973879404366016, 0.692945659160614)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5178.png: 640x512 1 Topwear, 84.5ms\n",
      "Speed: 1.8ms preprocess, 84.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_5178.png\n",
      "Annotations: [(0, 0.4886215999722481, 0.4562566876411438, 0.7313939183950424, 0.706816554069519)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4361.png: 640x512 1 Topwear, 2 Footwears, 80.2ms\n",
      "Speed: 2.2ms preprocess, 80.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4361.png\n",
      "Annotations: [(0, 0.7933289110660553, 0.3549561947584152, 0.4133421778678894, 0.38577988743782043), (1, 0.7643660604953766, 0.6416702419519424, 0.4712678790092468, 0.34808704257011414)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4719.png: 640x448 1 Topwear, 1 Bottomwear, 80.0ms\n",
      "Speed: 2.7ms preprocess, 80.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisetas_4719.png\n",
      "Annotations: [(1, 0.4816994220018387, 0.8817571103572845, 0.5019141137599945, 0.22906261682510376), (0, 0.4899238720536232, 0.5494281351566315, 0.6988428086042404, 0.569468080997467)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2328.png: 640x512 1 Topwear, 1 Bottomwear, 81.8ms\n",
      "Speed: 2.3ms preprocess, 81.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_2328.png\n",
      "Annotations: [(1, 0.323134683072567, 0.9304889142513275, 0.5355691462755203, 0.13902217149734497), (0, 0.36068370938301086, 0.6362159252166748, 0.7213674187660217, 0.7034170627593994)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5866.png: 640x480 1 Topwear, 1 Bottomwear, 72.1ms\n",
      "Speed: 2.4ms preprocess, 72.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas-y-blusas_5866.png\n",
      "Annotations: [(1, 0.4723278060555458, 0.8765052556991577, 0.515138790011406, 0.23344671726226807), (0, 0.5071767717599869, 0.5457795113325119, 0.6412567794322968, 0.676316648721695)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_2802.png: 640x512 1 Topwear, 1 Bottomwear, 96.6ms\n",
      "Speed: 2.0ms preprocess, 96.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_2802.png\n",
      "Annotations: [(1, 0.3299698382616043, 0.8355861306190491, 0.5607530772686005, 0.32882773876190186), (0, 0.40450848545879126, 0.420427531003952, 0.7743481118232012, 0.7845783829689026)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5951.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 75.2ms\n",
      "Speed: 1.8ms preprocess, 75.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_5951.png\n",
      "Annotations: [(2, 0.040897663682699203, 0.893375813961029, 0.08179532736539841, 0.07509422302246094), (2, 0.24892251938581467, 0.9057804644107819, 0.08970893919467926, 0.09277957677841187), (0, 0.24979408085346222, 0.2973955273628235, 0.3565346300601959, 0.2330349087715149), (1, 0.2162494957447052, 0.6355616897344589, 0.39415115118026733, 0.499515563249588)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botas_763.png: 640x512 1 Bottomwear, 2 Footwears, 81.4ms\n",
      "Speed: 1.8ms preprocess, 81.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_botas_763.png\n",
      "Annotations: [(2, 0.6057966947555542, 0.637037605047226, 0.3944978713989258, 0.36581188440322876), (2, 0.32090918347239494, 0.5658949613571167, 0.42728976160287857, 0.4511159658432007), (1, 0.47034307941794395, 0.21817390620708466, 0.8663356974720955, 0.41128942370414734)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_bodies_329.png: 640x512 1 Topwear, 1 Bottomwear, 101.9ms\n",
      "Speed: 1.9ms preprocess, 101.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_bodies_329.png\n",
      "Annotations: [(1, 0.535590797662735, 0.7815628051757812, 0.4284328818321228, 0.4228261709213257), (0, 0.5057930499315262, 0.498184397816658, 0.5340671241283417, 0.5351036489009857)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1390.png: 640x512 1 Topwear, 2 Footwears, 77.1ms\n",
      "Speed: 2.0ms preprocess, 77.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_1390.png\n",
      "Annotations: [(2, 0.42933548986911774, 0.8257192969322205, 0.09758451581001282, 0.12915444374084473), (2, 0.12722953595221043, 0.8254982233047485, 0.14506525918841362, 0.1327667236328125), (0, 0.33329811692237854, 0.37805305421352386, 0.4300915598869324, 0.5200101435184479)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatos_220.png: 640x544 1 Footwear, 82.9ms\n",
      "Speed: 1.8ms preprocess, 82.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_zapatos_220.png\n",
      "Annotations: [(2, 0.4872574210166931, 0.7002524137496948, 0.7065201997756958, 0.2047046422958374)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4023.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 105.5ms\n",
      "Speed: 1.8ms preprocess, 105.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_4023.png\n",
      "Annotations: [(2, 0.9337601065635681, 0.9002457857131958, 0.12578392028808594, 0.11603498458862305), (2, 0.5661639124155045, 0.9151334762573242, 0.1584767997264862, 0.12901437282562256), (0, 0.7588528096675873, 0.20136085152626038, 0.3718112111091614, 0.36000633239746094), (1, 0.7745694518089294, 0.5834870785474777, 0.40534961223602295, 0.5276223719120026)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_2860.png: 640x544 1 Topwear, 81.4ms\n",
      "Speed: 1.8ms preprocess, 81.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_abrigos_2860.png\n",
      "Annotations: [(0, 0.48577093333005905, 0.5026342868804932, 0.7442662864923477, 0.8109006881713867)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_114.png: 640x448 1 Footwear, 66.3ms\n",
      "Speed: 1.9ms preprocess, 66.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_zapatillas_114.png\n",
      "Annotations: [(2, 0.47741958871483803, 0.501803457736969, 0.8244447037577629, 0.25297069549560547)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4548.png: 640x512 1 Topwear, 1 Bottomwear, 98.3ms\n",
      "Speed: 1.7ms preprocess, 98.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4548.png\n",
      "Annotations: [(1, 0.46135345846414566, 0.8639574944972992, 0.44659678637981415, 0.26800280809402466), (0, 0.5061225220561028, 0.5104267597198486, 0.7404775768518448, 0.6246600151062012)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatos_1153.png: 640x512 2 Footwears, 79.7ms\n",
      "Speed: 1.7ms preprocess, 79.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatos_1153.png\n",
      "Annotations: [(2, 0.7144058644771576, 0.6215568035840988, 0.42580682039260864, 0.2614823877811432), (2, 0.2661287598311901, 0.5458483099937439, 0.3351636305451393, 0.36223793029785156)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_4476.png: 640x544 1 Topwear, 83.8ms\n",
      "Speed: 2.1ms preprocess, 83.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisas-y-blusas_4476.png\n",
      "Annotations: [(0, 0.5017394050955772, 0.5034053027629852, 0.5848456174135208, 0.5839241147041321)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_570.png: 640x512 1 Bottomwear, 2 Footwears, 88.6ms\n",
      "Speed: 1.7ms preprocess, 88.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_570.png\n",
      "Annotations: [(2, 0.04780086129903793, 0.8825523853302002, 0.09560172259807587, 0.12428164482116699), (2, 0.34648609161376953, 0.8963380455970764, 0.121989905834198, 0.12480413913726807), (1, 0.19492656644433737, 0.511770486831665, 0.36753921397030354, 0.6763385534286499)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_1397.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 82.7ms\n",
      "Speed: 1.9ms preprocess, 82.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_1397.png\n",
      "Annotations: [(2, 0.664684534072876, 0.8791226148605347, 0.11234927177429199, 0.12427520751953125), (2, 0.4428979307413101, 0.8796074390411377, 0.1158728301525116, 0.128975510597229), (0, 0.6330086588859558, 0.29848435521125793, 0.2626776695251465, 0.2453879714012146), (1, 0.6587015241384506, 0.48346681892871857, 0.3287258446216583, 0.24769219756126404)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5443.png: 640x640 1 Topwear, 1 Bottomwear, 99.4ms\n",
      "Speed: 2.1ms preprocess, 99.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_sudaderas_5443.png\n",
      "Annotations: [(1, 0.4833306670188904, 0.9396892189979553, 0.3207571506500244, 0.12062156200408936), (0, 0.4323733448982239, 0.49617910385131836, 0.6272631883621216, 0.9129527807235718)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_1719.png: 640x448 1 Topwear, 78.3ms\n",
      "Speed: 1.3ms preprocess, 78.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jerseys_1719.png\n",
      "Annotations: [(0, 0.49399190582334995, 0.5029168874025345, 0.9183348529040813, 0.8017743527889252)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_1437.png: 640x640 1 Topwear, 100.0ms\n",
      "Speed: 4.8ms preprocess, 100.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_camisetas_1437.png\n",
      "Annotations: [(0, 0.507541298866272, 0.5059678703546524, 0.4382755756378174, 0.9534003436565399)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1712.png: 640x448 1 Topwear, 67.3ms\n",
      "Speed: 1.9ms preprocess, 67.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_vestidos_1712.png\n",
      "Annotations: [(0, 0.5263946354389191, 0.5600293427705765, 0.6274949908256531, 0.7247144877910614)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_3276.png: 640x512 1 Bottomwear, 91.0ms\n",
      "Speed: 1.8ms preprocess, 91.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_3276.png\n",
      "Annotations: [(1, 0.4801575466990471, 0.45631810277700424, 0.7127664238214493, 0.4547109156847)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4435.png: 640x448 1 Bottomwear, 77.5ms\n",
      "Speed: 2.2ms preprocess, 77.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_pantalones_4435.png\n",
      "Annotations: [(1, 0.49852245301008224, 0.5103611350059509, 0.6141418367624283, 0.8228832483291626)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_2255.png: 640x448 1 Topwear, 1 Bottomwear, 2 Footwears, 69.5ms\n",
      "Speed: 2.1ms preprocess, 69.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jeans_2255.png\n",
      "Annotations: [(2, 0.5901292562484741, 0.9396169185638428, 0.14599931240081787, 0.10001373291015625), (2, 0.3728954493999481, 0.9350520074367523, 0.19306254386901855, 0.10562092065811157), (1, 0.45139791816473007, 0.48725488781929016, 0.5912692099809647, 0.8623740077018738)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_1761.png: 640x512 1 Topwear, 1 Bottomwear, 95.2ms\n",
      "Speed: 2.3ms preprocess, 95.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_1761.png\n",
      "Annotations: [(1, 0.5005325227975845, 0.90589839220047, 0.41643473505973816, 0.18164312839508057), (0, 0.5378339439630508, 0.5783376097679138, 0.531428188085556, 0.6276991367340088)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_747.png: 640x448 1 Topwear, 1 Bottomwear, 74.0ms\n",
      "Speed: 1.7ms preprocess, 74.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_abrigos_747.png\n",
      "Annotations: [(1, 0.5832650810480118, 0.8666816353797913, 0.5300773084163666, 0.24792516231536865), (0, 0.5004746690392494, 0.5482367128133774, 0.7200556248426437, 0.6127753555774689)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3861.png: 640x512 1 Topwear, 78.4ms\n",
      "Speed: 1.8ms preprocess, 78.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_3861.png\n",
      "Annotations: [(0, 0.5014892220497131, 0.49454212188720703, 0.5014358758926392, 0.8620736598968506)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_38.png: 640x448 1 Topwear, 66.5ms\n",
      "Speed: 1.3ms preprocess, 66.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_38.png\n",
      "Annotations: [(0, 0.49543192610144615, 0.4971136301755905, 0.9002125933766365, 0.7853145897388458)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4698.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 97.2ms\n",
      "Speed: 1.9ms preprocess, 97.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_4698.png\n",
      "Annotations: [(2, 0.5628025680780411, 0.8279853165149689, 0.21956142783164978, 0.09569817781448364), (2, 0.75590980052948, 0.8963338136672974, 0.1862502098083496, 0.11737799644470215), (0, 0.8008918166160583, 0.11241589486598969, 0.3579977750778198, 0.22483178973197937), (1, 0.7244863212108612, 0.5052407383918762, 0.3751752972602844, 0.5950976610183716)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_1442.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 76.2ms\n",
      "Speed: 1.9ms preprocess, 76.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_1442.png\n",
      "Annotations: [(2, 0.4121994376182556, 0.8372531235218048, 0.07995456457138062, 0.1282833218574524), (2, 0.1702943965792656, 0.8319664001464844, 0.10219113528728485, 0.13117194175720215), (0, 0.33589332550764084, 0.24667996913194656, 0.2377581149339676, 0.18070046603679657), (1, 0.33108000084757805, 0.4829082489013672, 0.5217215195298195, 0.3603936433792114)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_2951.png: 640x512 1 Topwear, 1 Bottomwear, 95.5ms\n",
      "Speed: 1.7ms preprocess, 95.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_2951.png\n",
      "Annotations: [(1, 0.7882049679756165, 0.9314697980880737, 0.402951717376709, 0.13628995418548584), (0, 0.7346402108669281, 0.6246398091316223, 0.5141212344169617, 0.614044189453125)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_682.png: 640x448 1 Bottomwear, 82.0ms\n",
      "Speed: 1.3ms preprocess, 82.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_pantalones_682.png\n",
      "Annotations: [(1, 0.4900207370519638, 0.49999988079071045, 0.7068363726139069, 0.9342947006225586)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_668.png: 640x512 1 Topwear, 2 Footwears, 86.8ms\n",
      "Speed: 2.0ms preprocess, 86.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_668.png\n",
      "Annotations: [(2, 0.259361632168293, 0.8953332304954529, 0.09142981469631195, 0.1379082202911377), (2, 0.47719891369342804, 0.9312408864498138, 0.12131962180137634, 0.12750953435897827), (0, 0.2643210180103779, 0.4475419968366623, 0.2965617999434471, 0.4677990972995758)]\n",
      "Detections: ['original_image', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_2935.png: 640x480 1 Topwear, 74.7ms\n",
      "Speed: 2.3ms preprocess, 74.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas_2935.png\n",
      "Annotations: [(0, 0.49308757670223713, 0.45185551047325134, 0.8889472745358944, 0.8359876275062561)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_3170.png: 640x512 1 Topwear, 96.9ms\n",
      "Speed: 1.9ms preprocess, 96.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_3170.png\n",
      "Annotations: [(0, 0.4940459616482258, 0.4779321551322937, 0.8510722145438194, 0.6554150581359863)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4588.png: 640x512 1 Topwear, 78.3ms\n",
      "Speed: 1.9ms preprocess, 78.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4588.png\n",
      "Annotations: [(0, 0.25504472851753235, 0.5568524673581123, 0.5100894570350647, 0.7268109172582626)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1280.png: 640x512 1 Topwear, 78.3ms\n",
      "Speed: 1.5ms preprocess, 78.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_1280.png\n",
      "Annotations: [(0, 0.49753180146217346, 0.6209213882684708, 0.9950636029243469, 0.6753399074077606), (0, 0.49395287595689297, 0.4848155975341797, 0.9072561152279377, 0.8634247779846191)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2062.png: 640x448 1 Topwear, 77.9ms\n",
      "Speed: 1.3ms preprocess, 77.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jerseys_2062.png\n",
      "Annotations: [(0, 0.49001408088952303, 0.49259597063064575, 0.9262030031532049, 0.8859933614730835)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_3732.png: 640x512 1 Topwear, 86.1ms\n",
      "Speed: 1.9ms preprocess, 86.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_3732.png\n",
      "Annotations: [(0, 0.49142712727189064, 0.5635816007852554, 0.8216328546404839, 0.7465939223766327)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_3081.png: 640x512 1 Topwear, 78.6ms\n",
      "Speed: 1.7ms preprocess, 78.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_3081.png\n",
      "Annotations: [(0, 0.5165022760629654, 0.5110214948654175, 0.6970041692256927, 0.5888329744338989)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_708.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 76.0ms\n",
      "Speed: 2.1ms preprocess, 76.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_708.png\n",
      "Annotations: [(2, 0.5421465039253235, 0.7058480381965637, 0.1319892406463623, 0.19208776950836182), (2, 0.4205527603626251, 0.8331891000270844, 0.18031877279281616, 0.1916598677635193), (1, 0.49387073516845703, 0.24071581661701202, 0.46622753143310547, 0.30743607878685)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_alpargatas_43.png: 640x512 1 Bottomwear, 2 Footwears, 98.4ms\n",
      "Speed: 1.8ms preprocess, 98.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_alpargatas_43.png\n",
      "Annotations: [(2, 0.5137006808072329, 0.707592248916626, 0.9311078451573849, 0.29990100860595703), (1, 0.5488538332283497, 0.2581433951854706, 0.9022923335433006, 0.5162867903709412)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_2528.png: 640x512 1 Topwear, 1 Bottomwear, 80.5ms\n",
      "Speed: 1.8ms preprocess, 80.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_2528.png\n",
      "Annotations: [(1, 0.5225717127323151, 0.8663432598114014, 0.4232705235481262, 0.2638857364654541), (0, 0.5006290376186371, 0.5084491968154907, 0.6475980877876282, 0.6587094068527222)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4945.png: 640x512 1 Topwear, 80.8ms\n",
      "Speed: 1.7ms preprocess, 80.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4945.png\n",
      "Annotations: [(0, 0.4872991740703583, 0.5056408494710922, 0.582381546497345, 0.5826278030872345)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_795.png: 640x512 1 Topwear, 2 Footwears, 97.9ms\n",
      "Speed: 1.8ms preprocess, 97.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_795.png\n",
      "Annotations: [(2, 0.8039666414260864, 0.9646674692630768, 0.12296664714813232, 0.07066506147384644), (2, 0.46810492873191833, 0.9498477578163147, 0.1474197506904602, 0.09927999973297119), (0, 0.6562119275331497, 0.5594898909330368, 0.4654439389705658, 0.7663330137729645)]\n",
      "Detections: ['original_image', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1717.png: 640x640 1 Topwear, 1 Bottomwear, 98.0ms\n",
      "Speed: 1.9ms preprocess, 98.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_sudaderas_1717.png\n",
      "Annotations: [(1, 0.5185160040855408, 0.9125775396823883, 0.43788206577301025, 0.17200511693954468), (0, 0.5014849305152893, 0.5520150661468506, 0.6458269357681274, 0.8174974918365479)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_791.png: 640x512 1 Topwear, 1 Bottomwear, 80.9ms\n",
      "Speed: 1.8ms preprocess, 80.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_791.png\n",
      "Annotations: [(1, 0.2958622854202986, 0.8114181160926819, 0.50212437286973, 0.31814277172088623), (0, 0.32533321529626846, 0.5004300326108932, 0.61933533847332, 0.6645263731479645)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_2822.png: 640x544 1 Bottomwear, 101.6ms\n",
      "Speed: 1.8ms preprocess, 101.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_pantalones_2822.png\n",
      "Annotations: [(1, 0.5119529664516449, 0.517246663570404, 0.506594717502594, 0.7219173908233643)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_2508.png: 640x480 1 Topwear, 74.2ms\n",
      "Speed: 1.8ms preprocess, 74.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_sudaderas_2508.png\n",
      "Annotations: [(0, 0.5003903210163116, 0.4094468355178833, 0.6937817931175232, 0.5975246429443359)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_3295.png: 640x544 1 Topwear, 80.2ms\n",
      "Speed: 1.8ms preprocess, 80.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sudaderas_3295.png\n",
      "Annotations: [(0, 0.5074126124382019, 0.513129711151123, 0.6776710748672485, 0.6963887214660645)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4168.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 94.4ms\n",
      "Speed: 1.8ms preprocess, 94.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4168.png\n",
      "Annotations: [(2, 0.43948139250278473, 0.9057234823703766, 0.28467580676078796, 0.12166279554367065), (2, 0.6765543520450592, 0.7398232519626617, 0.14081209897994995, 0.27994149923324585), (1, 0.48383088409900665, 0.47917987406253815, 0.376463383436203, 0.8274368941783905)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatos_1110.png: 640x512 1 Bottomwear, 2 Footwears, 75.4ms\n",
      "Speed: 1.8ms preprocess, 75.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatos_1110.png\n",
      "Annotations: [(2, 0.563498392701149, 0.7277240753173828, 0.4375879466533661, 0.2327040433883667), (2, 0.3104950711131096, 0.658428430557251, 0.4449136406183243, 0.3119475841522217), (1, 0.43756083538755774, 0.27612578868865967, 0.8497685613110662, 0.5522515773773193)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2562.png: 640x512 1 Topwear, 1 Bottomwear, 77.5ms\n",
      "Speed: 1.7ms preprocess, 77.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_2562.png\n",
      "Annotations: [(1, 0.48721565306186676, 0.7974568009376526, 0.5195377767086029, 0.36306440830230713), (0, 0.42319492250680923, 0.4802258834242821, 0.537798210978508, 0.5822701007127762)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1537.png: 640x512 1 Topwear, 100.5ms\n",
      "Speed: 1.8ms preprocess, 100.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_1537.png\n",
      "Annotations: [(0, 0.48668381571769714, 0.49011847376823425, 0.7918223738670349, 0.8513172268867493)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_4988.png: 640x512 1 Topwear, 77.3ms\n",
      "Speed: 1.7ms preprocess, 77.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_4988.png\n",
      "Annotations: [(0, 0.5090801008045673, 0.5487689226865768, 0.8011517748236656, 0.8031186163425446)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3543.png: 640x480 1 Topwear, 70.7ms\n",
      "Speed: 1.9ms preprocess, 70.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_vestidos_3543.png\n",
      "Annotations: [(0, 0.4942818135023117, 0.5252141989767551, 0.4299558699131012, 0.8224736377596855)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4100.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 90.7ms\n",
      "Speed: 1.8ms preprocess, 90.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4100.png\n",
      "Annotations: [(2, 0.3375762477517128, 0.8415495753288269, 0.1796872466802597, 0.1655735969543457), (2, 0.14845485612750053, 0.7482592463493347, 0.16616753488779068, 0.18997085094451904), (1, 0.2959582768380642, 0.4475347399711609, 0.46366704255342484, 0.6204503774642944)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1513.png: 640x512 1 Topwear, 2 Footwears, 88.3ms\n",
      "Speed: 2.4ms preprocess, 88.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_1513.png\n",
      "Annotations: [(2, 0.3118918538093567, 0.8622979521751404, 0.10580360889434814, 0.13217008113861084), (2, 0.5312457084655762, 0.8689215779304504, 0.09873104095458984, 0.14182841777801514), (0, 0.408191479742527, 0.4314224421977997, 0.4463866204023361, 0.5786617398262024)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_2571.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 76.6ms\n",
      "Speed: 1.9ms preprocess, 76.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_2571.png\n",
      "Annotations: [(2, 0.8798951208591461, 0.900959700345993, 0.07182687520980835, 0.14009255170822144), (2, 0.6777757704257965, 0.8371810913085938, 0.07475346326828003, 0.14127647876739502), (0, 0.7384859621524811, 0.19500571489334106, 0.2163061499595642, 0.1797856092453003), (1, 0.7305475771427155, 0.5036474019289017, 0.29910486936569214, 0.5808795392513275)]\n",
      "Detections: ['original_image', 'topwear', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_62.png: 640x448 1 Bottomwear, 70.1ms\n",
      "Speed: 1.3ms preprocess, 70.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_trajes_62.png\n",
      "Annotations: [(1, 0.4937608018517494, 0.4971572309732437, 0.6878905743360519, 0.9246844947338104)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_2505.png: 640x512 1 Topwear, 2 Footwears, 103.4ms\n",
      "Speed: 1.8ms preprocess, 103.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_2505.png\n",
      "Annotations: [(2, 0.1770230270922184, 0.9854725301265717, 0.15541111677885056, 0.02905493974685669), (2, 0.4038752466440201, 0.9669756889343262, 0.15935364365577698, 0.06604862213134766), (0, 0.2721969000995159, 0.4541769325733185, 0.41558489948511124, 0.5231627821922302)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3072.png: 640x512 1 Topwear, 75.2ms\n",
      "Speed: 1.9ms preprocess, 75.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_3072.png\n",
      "Annotations: [(0, 0.6615992337465286, 0.5846193879842758, 0.6675737798213959, 0.8015382587909698)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_328.png: 640x480 1 Footwear, 70.5ms\n",
      "Speed: 1.8ms preprocess, 70.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_zapatillas_328.png\n",
      "Annotations: [(2, 0.4943195269443095, 0.5047133713960648, 0.9717869190499187, 0.2915221154689789)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5752.png: 640x512 1 Topwear, 97.3ms\n",
      "Speed: 1.7ms preprocess, 97.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_5752.png\n",
      "Annotations: [(0, 0.5114928632974625, 0.4362010806798935, 0.5081379115581512, 0.46804574131965637)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3739.png: 640x512 1 Topwear, 1 Bottomwear, 75.4ms\n",
      "Speed: 1.9ms preprocess, 75.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_3739.png\n",
      "Annotations: [(0, 0.6051292419433594, 0.6068318784236908, 0.6330534219741821, 0.7097935080528259)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_401.png: 640x448 1 Topwear, 68.8ms\n",
      "Speed: 1.3ms preprocess, 68.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas_401.png\n",
      "Annotations: [(0, 0.4997416101396084, 0.4976963698863983, 0.8699026182293892, 0.6211265921592712)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_1075.png: 640x448 1 Bottomwear, 66.5ms\n",
      "Speed: 1.3ms preprocess, 66.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_pantalones_1075.png\n",
      "Annotations: [(1, 0.5014648213982582, 0.49274055659770966, 0.6912866085767746, 0.9366998970508575)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_444.png: 640x512 1 Topwear, 83.3ms\n",
      "Speed: 2.1ms preprocess, 83.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_444.png\n",
      "Annotations: [(0, 0.5771869197487831, 0.5097499489784241, 0.8153264969587326, 0.6916242837905884)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4629.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 76.4ms\n",
      "Speed: 2.0ms preprocess, 76.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4629.png\n",
      "Annotations: [(2, 0.28832970559597015, 0.9597259163856506, 0.18041595816612244, 0.08054816722869873), (2, 0.16451524198055267, 0.9163166284561157, 0.13414013385772705, 0.144708514213562), (0, 0.2730390131473541, 0.29827600717544556, 0.18826264142990112, 0.1593354344367981), (1, 0.23445376753807068, 0.6724981069564819, 0.34254884719848633, 0.5165029764175415)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_polos_388.png: 640x544 1 Topwear, 79.4ms\n",
      "Speed: 1.8ms preprocess, 79.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_polos_388.png\n",
      "Annotations: [(0, 0.5253569111227989, 0.6546355783939362, 0.9221210032701492, 0.6907288432121277)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_760.png: 640x480 1 Topwear, 75.4ms\n",
      "Speed: 1.8ms preprocess, 75.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas_760.png\n",
      "Annotations: [(0, 0.5030368231236935, 0.5037313401699066, 0.8839427903294563, 0.9052472710609436)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4107.png: 640x448 1 Topwear, 67.1ms\n",
      "Speed: 1.4ms preprocess, 67.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisetas_4107.png\n",
      "Annotations: [(0, 0.500360619276762, 0.500589594244957, 0.9518513455986977, 0.6807797253131866)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_1191.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 80.8ms\n",
      "Speed: 2.0ms preprocess, 80.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_1191.png\n",
      "Annotations: [(2, 0.8889212012290955, 0.8294995427131653, 0.13498473167419434, 0.20814907550811768), (2, 0.6155063211917877, 0.9080142378807068, 0.19786638021469116, 0.1477106809616089), (1, 0.7222399115562439, 0.2924690321087837, 0.4086357355117798, 0.2884241193532944), (0, 0.6895259916782379, 0.10677158832550049, 0.611521303653717, 0.21354317665100098)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_1676.png: 640x480 1 Topwear, 90.1ms\n",
      "Speed: 1.8ms preprocess, 90.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_trajes_1676.png\n",
      "Annotations: [(0, 0.5068715279921889, 0.5981622338294983, 0.9713692534714937, 0.7461490631103516)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_301.png: 640x448 1 Bottomwear, 67.1ms\n",
      "Speed: 2.0ms preprocess, 67.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jeans_301.png\n",
      "Annotations: [(1, 0.49794336408376694, 0.4892827272415161, 0.5566426068544388, 0.8931493759155273)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_407.png: 640x512 1 Bottomwear, 2 Footwears, 77.6ms\n",
      "Speed: 2.0ms preprocess, 77.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_407.png\n",
      "Annotations: [(2, 0.2693098932504654, 0.8750879764556885, 0.08230629563331604, 0.13114416599273682), (2, 0.050898533314466476, 0.8678963780403137, 0.10179706662893295, 0.11945140361785889), (1, 0.20833122450858355, 0.45266199111938477, 0.35538006387650967, 0.6507271528244019)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_2472.png: 640x448 1 Topwear, 83.2ms\n",
      "Speed: 1.3ms preprocess, 83.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisetas_2472.png\n",
      "Annotations: [(0, 0.4971986263990402, 0.4967225641012192, 0.9120254814624786, 0.6675486862659454)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_2649.png: 640x512 1 Topwear, 1 Bottomwear, 80.4ms\n",
      "Speed: 1.9ms preprocess, 80.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_2649.png\n",
      "Annotations: [(0, 0.36809252202510834, 0.5458694100379944, 0.6327832043170929, 0.6873966455459595)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_tacones_782.png: 640x512 2 Footwears, 75.2ms\n",
      "Speed: 1.9ms preprocess, 75.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_tacones_782.png\n",
      "Annotations: [(2, 0.36529015749692917, 0.6306296288967133, 0.5468397289514542, 0.5610945820808411)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5419.png: 640x512 1 Topwear, 101.8ms\n",
      "Speed: 1.9ms preprocess, 101.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_5419.png\n",
      "Annotations: [(0, 0.3370618186891079, 0.5777174234390259, 0.5143202617764473, 0.7775250673294067)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_polos_786.png: 640x640 1 Topwear, 97.9ms\n",
      "Speed: 2.2ms preprocess, 97.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_polos_786.png\n",
      "Annotations: [(0, 0.5069141834974289, 0.55293408036232, 0.6474006474018097, 0.848321259021759)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4096.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 80.3ms\n",
      "Speed: 1.8ms preprocess, 80.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4096.png\n",
      "Annotations: [(2, 0.6803617775440216, 0.7457824945449829, 0.21155589818954468, 0.18863201141357422), (2, 0.46886204183101654, 0.8560536801815033, 0.2566404640674591, 0.15578800439834595), (1, 0.5666025429964066, 0.4427773356437683, 0.3882860839366913, 0.675589919090271)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_4319.png: 640x512 1 Topwear, 1 Bottomwear, 96.4ms\n",
      "Speed: 1.9ms preprocess, 96.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_4319.png\n",
      "Annotations: [(1, 0.4290938675403595, 0.8805334568023682, 0.4287424683570862, 0.21852517127990723), (0, 0.4731248803436756, 0.5080997198820114, 0.7378315553069115, 0.7199477255344391)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_3530.png: 640x512 1 Bottomwear, 82.3ms\n",
      "Speed: 1.7ms preprocess, 82.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_3530.png\n",
      "Annotations: [(1, 0.49189992249011993, 0.49776123464107513, 0.47318944334983826, 0.7478335201740265)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5596.png: 640x512 1 Topwear, 2 Footwears, 80.1ms\n",
      "Speed: 1.9ms preprocess, 80.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_5596.png\n",
      "Annotations: [(2, 0.8661360740661621, 0.8865624666213989, 0.07302379608154297, 0.13565170764923096), (2, 0.6805505156517029, 0.8877909779548645, 0.07769417762756348, 0.14594316482543945), (1, 0.8231367766857147, 0.5577887892723083, 0.27772384881973267, 0.4463144540786743), (0, 0.8201456964015961, 0.4868483394384384, 0.29636555910110474, 0.6287393867969513)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_3279.png: 640x448 1 Topwear, 80.1ms\n",
      "Speed: 1.4ms preprocess, 80.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_sudaderas_3279.png\n",
      "Annotations: [(0, 0.482728804461658, 0.4979659952223301, 0.9208677504211664, 0.782782070338726)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_852.png: 640x512 1 Topwear, 79.3ms\n",
      "Speed: 2.1ms preprocess, 79.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_852.png\n",
      "Annotations: [(0, 0.2445538341999054, 0.5310009717941284, 0.4891076683998108, 0.714664101600647)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_3190.png: 640x480 1 Topwear, 70.5ms\n",
      "Speed: 1.9ms preprocess, 70.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisetas_3190.png\n",
      "Annotations: [(0, 0.4996730759739876, 0.3743247538805008, 0.8216457217931747, 0.5574842393398285)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_900.png: 640x512 1 Topwear, 1 Bottomwear, 76.3ms\n",
      "Speed: 1.9ms preprocess, 76.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_900.png\n",
      "Annotations: [(1, 0.5987204611301422, 0.8596068024635315, 0.5335363745689392, 0.2783539295196533), (0, 0.4824352264404297, 0.508829340338707, 0.5979213714599609, 0.6199052631855011)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_1146.png: 640x512 1 Bottomwear, 2 Footwears, 85.1ms\n",
      "Speed: 2.1ms preprocess, 85.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_1146.png\n",
      "Annotations: [(2, 0.5629241913557053, 0.810479462146759, 0.1610868275165558, 0.1821303367614746), (1, 0.5349304378032684, 0.4360990971326828, 0.4360653758049011, 0.6236206591129303)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_tacones_338.png: 640x544 1 Footwear, 85.8ms\n",
      "Speed: 1.8ms preprocess, 85.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_tacones_338.png\n",
      "Annotations: [(2, 0.5150594413280487, 0.7084767818450928, 0.5293669104576111, 0.17310214042663574)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5662.png: 640x640 1 Topwear, 98.0ms\n",
      "Speed: 2.5ms preprocess, 98.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_abrigos_5662.png\n",
      "Annotations: [(0, 0.49102190136909485, 0.4519333690404892, 0.6978916525840759, 0.8734319508075714)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_1798.png: 640x480 1 Topwear, 90.7ms\n",
      "Speed: 4.8ms preprocess, 90.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jerseys_1798.png\n",
      "Annotations: [(0, 0.48974764719605446, 0.39057670533657074, 0.8220457956194878, 0.6054555475711823)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1828.png: 640x512 1 Bottomwear, 2 Footwears, 77.2ms\n",
      "Speed: 2.0ms preprocess, 77.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_1828.png\n",
      "Annotations: [(2, 0.4999569356441498, 0.7049685716629028, 0.9999138712882996, 0.43234920501708984), (1, 0.5066794753074646, 0.24794498085975647, 0.923109769821167, 0.4825652241706848)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_730.png: 640x512 1 Topwear, 2 Footwears, 76.3ms\n",
      "Speed: 1.9ms preprocess, 76.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_730.png\n",
      "Annotations: [(2, 0.4902205169200897, 0.8319717049598694, 0.11142808198928833, 0.1520063877105713), (2, 0.36516450345516205, 0.8908862471580505, 0.143123596906662, 0.15182483196258545), (0, 0.4110632538795471, 0.4874337464570999, 0.34135591983795166, 0.6059242188930511)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_2978.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 93.9ms\n",
      "Speed: 1.8ms preprocess, 93.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_2978.png\n",
      "Annotations: [(2, 0.32813702523708344, 0.7903977632522583, 0.11682906746864319, 0.17290306091308594), (2, 0.36851391196250916, 0.8829808831214905, 0.16122448444366455, 0.17646467685699463), (0, 0.4742478281259537, 0.12700460525229573, 0.4214116036891937, 0.22340939100831747), (1, 0.4173252508044243, 0.5092793703079224, 0.39418913424015045, 0.6553829908370972)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_675.png: 640x512 1 Bottomwear, 2 Footwears, 73.5ms\n",
      "Speed: 1.9ms preprocess, 73.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_675.png\n",
      "Annotations: [(2, 0.6080577075481415, 0.8670644164085388, 0.1505776047706604, 0.19038963317871094), (2, 0.37515950202941895, 0.7970397174358368, 0.16712599992752075, 0.2336469292640686), (1, 0.49006665498018265, 0.28240030258893967, 0.5012053102254868, 0.3304871469736099)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_bodies_101.png: 640x544 1 Topwear, 81.8ms\n",
      "Speed: 2.7ms preprocess, 81.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_bodies_101.png\n",
      "Annotations: [(0, 0.5009675323963165, 0.6200687736272812, 0.45383697748184204, 0.6165330708026886)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_101.png: 640x640 1 Topwear, 113.8ms\n",
      "Speed: 4.4ms preprocess, 113.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_camisetas_101.png\n",
      "Annotations: [(0, 0.4976726770401001, 0.51865553855896, 0.5046509504318237, 0.9159364700317383)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1082.png: 640x512 1 Topwear, 2 Footwears, 76.5ms\n",
      "Speed: 2.0ms preprocess, 76.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_1082.png\n",
      "Annotations: [(2, 0.18704218789935112, 0.9892323911190033, 0.16100362688302994, 0.021535217761993408), (2, 0.42315469682216644, 0.9857397675514221, 0.1552450954914093, 0.02852046489715576), (0, 0.2726191282272339, 0.5226266533136368, 0.5452382564544678, 0.6929349601268768)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_251.png: 640x512 1 Bottomwear, 75.1ms\n",
      "Speed: 1.7ms preprocess, 75.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_251.png\n",
      "Annotations: [(1, 0.49597055464982986, 0.5060136169195175, 0.680257186293602, 0.8699953854084015)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5833.png: 640x512 1 Topwear, 82.2ms\n",
      "Speed: 12.7ms preprocess, 82.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_5833.png\n",
      "Annotations: [(0, 0.49486347287893295, 0.48220202326774597, 0.7944206744432449, 0.6901549696922302)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2487.png: 640x512 1 Bottomwear, 78.7ms\n",
      "Speed: 1.9ms preprocess, 78.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_2487.png\n",
      "Annotations: [(1, 0.4928199052810669, 0.5102015733718872, 0.6957002878189087, 0.4249781370162964)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_319.png: 640x512 1 Footwear, 75.0ms\n",
      "Speed: 1.8ms preprocess, 75.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_319.png\n",
      "Annotations: [(2, 0.5055599585175514, 0.7496203780174255, 0.6977049559354782, 0.19347155094146729)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1004.png: 640x512 1 Topwear, 1 Bottomwear, 98.1ms\n",
      "Speed: 1.9ms preprocess, 98.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_1004.png\n",
      "Annotations: [(1, 0.5205828845500946, 0.9009424448013306, 0.5061210989952087, 0.19811511039733887), (0, 0.5733785331249237, 0.5775005668401718, 0.6503984332084656, 0.6780472099781036)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_702.png: 640x640 1 Topwear, 99.8ms\n",
      "Speed: 2.6ms preprocess, 99.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_camisetas_702.png\n",
      "Annotations: [(0, 0.5019596815109253, 0.5017606019973755, 0.46033668518066406, 0.949378490447998)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_5311.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 95.7ms\n",
      "Speed: 1.9ms preprocess, 95.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_5311.png\n",
      "Annotations: [(2, 0.6087401211261749, 0.8750532865524292, 0.18269211053848267, 0.09829056262969971), (2, 0.3912156671285629, 0.8758572936058044, 0.1956121027469635, 0.09575879573822021), (0, 0.6574103981256485, 0.13370302319526672, 0.3322544991970062, 0.26740604639053345), (1, 0.5799275487661362, 0.550652027130127, 0.3941709101200104, 0.637346625328064)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botines_210.png: 640x544 1 Footwear, 90.2ms\n",
      "Speed: 1.7ms preprocess, 90.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_botines_210.png\n",
      "Annotations: [(2, 0.506049208343029, 0.6213727593421936, 0.5690616518259048, 0.35937821865081787)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5676.png: 640x544 1 Topwear, 1 Bottomwear, 80.9ms\n",
      "Speed: 1.7ms preprocess, 80.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisas-y-blusas_5676.png\n",
      "Annotations: [(1, 0.5002817064523697, 0.9341385662555695, 0.46417495608329773, 0.13172286748886108), (0, 0.49811258912086487, 0.5838177055120468, 0.4859173893928528, 0.6596038639545441)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_81.png: 640x512 1 Bottomwear, 81.0ms\n",
      "Speed: 1.8ms preprocess, 81.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_81.png\n",
      "Annotations: [(1, 0.509618803858757, 0.5006525367498398, 0.43838265538215637, 0.7720063030719757)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_4842.png: 640x512 1 Topwear, 104.0ms\n",
      "Speed: 1.8ms preprocess, 104.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_4842.png\n",
      "Annotations: [(0, 0.4969136454164982, 0.5143304616212845, 0.8620001599192619, 0.8945628106594086)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_1597.png: 640x448 1 Topwear, 68.8ms\n",
      "Speed: 1.2ms preprocess, 68.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_trajes_1597.png\n",
      "Annotations: [(0, 0.4974819179624319, 0.5048050582408905, 0.9131187684834003, 0.7907964587211609)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_cardigans_96.png: 640x448 1 Topwear, 70.0ms\n",
      "Speed: 1.2ms preprocess, 70.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_cardigans_96.png\n",
      "Annotations: [(0, 0.4993144478648901, 0.49974769353866577, 0.9129538126289845, 0.902830958366394)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_643.png: 640x480 1 Topwear, 71.9ms\n",
      "Speed: 1.8ms preprocess, 71.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_sudaderas_643.png\n",
      "Annotations: [(0, 0.48950370028615, 0.4531951993703842, 0.8273549899458885, 0.8516609966754913)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_69.png: 640x512 1 Topwear, 103.7ms\n",
      "Speed: 1.7ms preprocess, 103.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_69.png\n",
      "Annotations: [(0, 0.4916096031665802, 0.479225292801857, 0.6246795058250427, 0.6297983825206757)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_726.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 89.6ms\n",
      "Speed: 1.9ms preprocess, 89.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_726.png\n",
      "Annotations: [(2, 0.5383322834968567, 0.9138394296169281, 0.15960216522216797, 0.16263431310653687), (2, 0.35745304822921753, 0.7783416211605072, 0.13459563255310059, 0.21158748865127563), (1, 0.47744059562683105, 0.27428802847862244, 0.43912577629089355, 0.25401294231414795)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_1362.png: 640x640 1 Topwear, 1 Bottomwear, 2 Footwears, 110.1ms\n",
      "Speed: 2.2ms preprocess, 110.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_pantalones_1362.png\n",
      "Annotations: [(2, 0.5990875661373138, 0.9079428315162659, 0.1731739640235901, 0.1259084939956665), (2, 0.33482037484645844, 0.89528489112854, 0.2146708071231842, 0.11219561100006104), (1, 0.5027543157339096, 0.5550847202539444, 0.37264779210090637, 0.6645247638225555)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_466.png: 640x480 1 Topwear, 100.5ms\n",
      "Speed: 2.0ms preprocess, 100.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jerseys_466.png\n",
      "Annotations: [(0, 0.5015557035803795, 0.4344760328531265, 0.7093029767274857, 0.6546454131603241)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_polos_716.png: 640x512 1 Topwear, 90.0ms\n",
      "Speed: 1.9ms preprocess, 90.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_polos_716.png\n",
      "Annotations: [(0, 0.5109590850770473, 0.4998523145914078, 0.8123675659298897, 0.7071132361888885)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5764.png: 640x640 1 Topwear, 113.0ms\n",
      "Speed: 3.2ms preprocess, 113.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_abrigos_5764.png\n",
      "Annotations: [(0, 0.5002745315432549, 0.48666688799858093, 0.6906762272119522, 0.9150095582008362)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_1709.png: 640x544 1 Topwear, 1 Bottomwear, 104.4ms\n",
      "Speed: 2.3ms preprocess, 104.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_abrigos_1709.png\n",
      "Annotations: [(1, 0.43401137739419937, 0.9459385275840759, 0.47517184913158417, 0.10812294483184814), (0, 0.44572771713137627, 0.5767888873815536, 0.7623976245522499, 0.7420158684253693)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5177.png: 640x640 1 Topwear, 95.8ms\n",
      "Speed: 2.6ms preprocess, 95.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_sudaderas_5177.png\n",
      "Annotations: [(0, 0.4905197322368622, 0.4938494712114334, 0.6873610615730286, 0.9132071435451508)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4913.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 78.9ms\n",
      "Speed: 1.9ms preprocess, 78.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_4913.png\n",
      "Annotations: [(2, 0.28867582976818085, 0.926761269569397, 0.11993655562400818, 0.14152288436889648), (2, 0.6232127249240875, 0.8399879634380341, 0.16190892457962036, 0.11973363161087036), (0, 0.2407747209072113, 0.16725090146064758, 0.4815494418144226, 0.33114081621170044), (1, 0.33015350066125393, 0.544959083199501, 0.553400207310915, 0.6113362014293671)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_planos_31.png: 640x544 1 Footwear, 101.8ms\n",
      "Speed: 1.7ms preprocess, 101.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_planos_31.png\n",
      "Annotations: [(2, 0.4899284765124321, 0.6311377435922623, 0.5924641042947769, 0.300669401884079)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_1484.png: 640x512 1 Topwear, 1 Bottomwear, 79.8ms\n",
      "Speed: 1.9ms preprocess, 79.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_1484.png\n",
      "Annotations: [(1, 0.2534337639808655, 0.7401713728904724, 0.506867527961731, 0.4294837713241577), (0, 0.2737278938293457, 0.4268123582005501, 0.5283111333847046, 0.43593476712703705)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2181.png: 640x512 1 Topwear, 1 Bottomwear, 78.4ms\n",
      "Speed: 2.0ms preprocess, 78.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_2181.png\n",
      "Annotations: [(1, 0.19229194289073348, 0.8664271235466003, 0.3760753320530057, 0.26679790019989014), (0, 0.19944438571110368, 0.5217813849449158, 0.39383923541754484, 0.5790746212005615)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_2773.png: 640x480 1 Topwear, 87.8ms\n",
      "Speed: 1.7ms preprocess, 87.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_2773.png\n",
      "Annotations: [(0, 0.5130813717842102, 0.41823984682559967, 0.805374264717102, 0.6271539628505707)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4004.png: 640x448 1 Topwear, 2 Footwears, 75.5ms\n",
      "Speed: 2.1ms preprocess, 75.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_vestidos_4004.png\n",
      "Annotations: [(2, 0.5655030906200409, 0.9589354991912842, 0.1135130524635315, 0.07921671867370605), (2, 0.4334172159433365, 0.9461064040660858, 0.14991626143455505, 0.08585184812545776), (0, 0.4916401207447052, 0.401549831032753, 0.4102252125740051, 0.5050689876079559)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4346.png: 640x480 1 Bottomwear, 70.8ms\n",
      "Speed: 1.9ms preprocess, 70.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jeans_4346.png\n",
      "Annotations: [(1, 0.5021768361330032, 0.4510958790779114, 0.4882682263851166, 0.6600261926651001)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_2170.png: 640x480 1 Topwear, 68.8ms\n",
      "Speed: 1.9ms preprocess, 68.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_2170.png\n",
      "Annotations: [(0, 0.49143508076667786, 0.39977623522281647, 0.696159303188324, 0.5963825881481171)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_727.png: 640x640 1 Footwear, 104.3ms\n",
      "Speed: 1.9ms preprocess, 104.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_727.png\n",
      "Annotations: [(2, 0.495555579662323, 0.48311641812324524, 0.3256288766860962, 0.1556437611579895)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4824.png: 640x512 1 Topwear, 1 Bottomwear, 80.5ms\n",
      "Speed: 3.4ms preprocess, 80.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4824.png\n",
      "Annotations: [(1, 0.5642045140266418, 0.8696260750293732, 0.44076645374298096, 0.24805468320846558), (0, 0.5185805112123489, 0.47933385521173477, 0.5440784394741058, 0.5837747305631638)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_678.png: 640x480 1 Topwear, 72.0ms\n",
      "Speed: 1.9ms preprocess, 72.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jerseys_678.png\n",
      "Annotations: [(0, 0.5006469711661339, 0.4193139337003231, 0.674956277012825, 0.6098393872380257)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1543.png: 640x480 1 Topwear, 77.0ms\n",
      "Speed: 2.0ms preprocess, 77.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jeans_1543.png\n",
      "Annotations: [(0, 0.5029750429093838, 0.5210114382207394, 0.837249405682087, 0.8359204009175301)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_3952.png: 640x512 1 Topwear, 1 Bottomwear, 99.9ms\n",
      "Speed: 1.9ms preprocess, 99.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_3952.png\n",
      "Annotations: [(1, 0.7248302400112152, 0.8042277097702026, 0.5461317896842957, 0.38101744651794434), (0, 0.7228274047374725, 0.4480774700641632, 0.4427667260169983, 0.49437588453292847)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_605.png: 640x512 1 Topwear, 2 Footwears, 76.0ms\n",
      "Speed: 1.9ms preprocess, 76.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_605.png\n",
      "Annotations: [(2, 0.4772207736968994, 0.9265108406543732, 0.08532571792602539, 0.14697831869125366), (2, 0.37369030714035034, 0.9260306358337402, 0.08930402994155884, 0.14793872833251953), (1, 0.3029181621968746, 0.5466265380382538, 0.5042464211583138, 0.4804447293281555), (0, 0.319859704002738, 0.4313826858997345, 0.5203948803246021, 0.654874861240387)]\n",
      "Detections: ['original_image', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_406.png: 640x480 1 Topwear, 70.5ms\n",
      "Speed: 1.7ms preprocess, 70.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_sudaderas_406.png\n",
      "Annotations: [(0, 0.5030977837741375, 0.5101223029196262, 0.8717802539467812, 0.8210402652621269)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4298.png: 640x512 1 Topwear, 1 Bottomwear, 88.6ms\n",
      "Speed: 1.9ms preprocess, 88.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4298.png\n",
      "Annotations: [(1, 0.6050025224685669, 0.8607872724533081, 0.34689438343048096, 0.2751154899597168), (0, 0.6630606055259705, 0.5034833550453186, 0.581332802772522, 0.5835987329483032)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_4898.png: 640x512 1 Topwear, 1 Bottomwear, 83.2ms\n",
      "Speed: 1.8ms preprocess, 83.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_4898.png\n",
      "Annotations: [(1, 0.7658620178699493, 0.8961414694786072, 0.4682759642601013, 0.20771706104278564), (0, 0.6346141546964645, 0.5543944537639618, 0.7307716906070709, 0.5968349575996399)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4358.png: 640x448 1 Topwear, 1 Bottomwear, 1 Footwear, 73.2ms\n",
      "Speed: 2.0ms preprocess, 73.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jeans_4358.png\n",
      "Annotations: [(2, 0.41467125713825226, 0.8167876303195953, 0.09052053093910217, 0.17530018091201782), (2, 0.5020719617605209, 0.9148801565170288, 0.13408032059669495, 0.17023968696594238), (1, 0.52452152967453, 0.47215096466243267, 0.43140459060668945, 0.8271625377237797)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1517.png: 640x512 1 Bottomwear, 77.9ms\n",
      "Speed: 1.8ms preprocess, 77.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_1517.png\n",
      "Annotations: [(1, 0.4835694506764412, 0.4935179818421602, 0.622272714972496, 0.8649437688291073)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_525.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 90.4ms\n",
      "Speed: 1.9ms preprocess, 90.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_525.png\n",
      "Annotations: [(2, 0.47576187551021576, 0.8878782987594604, 0.11531499028205872, 0.14505040645599365), (2, 0.5745324790477753, 0.7788176834583282, 0.1247747540473938, 0.1868688464164734), (0, 0.4896589070558548, 0.1256013885140419, 0.4521302878856659, 0.24608825147151947), (1, 0.5089220702648163, 0.32130929827690125, 0.4090372920036316, 0.2981398105621338)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_2153.png: 640x544 1 Topwear, 2 Footwears, 85.6ms\n",
      "Speed: 1.8ms preprocess, 85.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_vestidos_2153.png\n",
      "Annotations: [(2, 0.6499749720096588, 0.9312743842601776, 0.18548208475112915, 0.10181599855422974), (2, 0.4093945175409317, 0.9058464765548706, 0.1344115436077118, 0.15210187435150146), (0, 0.5288935750722885, 0.5108274221420288, 0.2689787447452545, 0.596381425857544)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5746.png: 640x640 1 Topwear, 1 Bottomwear, 95.3ms\n",
      "Speed: 2.0ms preprocess, 95.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_abrigos_5746.png\n",
      "Annotations: [(1, 0.4814944565296173, 0.8791727423667908, 0.28803175687789917, 0.24116671085357666), (0, 0.5233900547027588, 0.526377946138382, 0.4407249689102173, 0.6085469126701355)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_374.png: 640x480 1 Topwear, 67.8ms\n",
      "Speed: 2.1ms preprocess, 67.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_vestidos_374.png\n",
      "Annotations: [(0, 0.4995845630764961, 0.5257577747106552, 0.5601473897695541, 0.804951936006546)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_648.png: 640x512 1 Topwear, 97.7ms\n",
      "Speed: 2.1ms preprocess, 97.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_648.png\n",
      "Annotations: [(0, 0.5320908948779106, 0.6346275955438614, 0.9358182102441788, 0.7059740722179413)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_2895.png: 640x512 1 Topwear, 77.3ms\n",
      "Speed: 1.8ms preprocess, 77.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_2895.png\n",
      "Annotations: [(0, 0.5120309367775917, 0.5178808569908142, 0.6041421145200729, 0.7053380012512207)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_771.png: 640x512 1 Topwear, 2 Bottomwears, 2 Footwears, 78.8ms\n",
      "Speed: 1.9ms preprocess, 78.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_771.png\n",
      "Annotations: [(2, 0.7152999937534332, 0.9378864765167236, 0.09093648195266724, 0.11705362796783447), (2, 0.46027398109436035, 0.9169053435325623, 0.11775898933410645, 0.1325913667678833), (0, 0.6638723462820053, 0.2596860006451607, 0.3760642111301422, 0.24733899533748627), (1, 0.6096670031547546, 0.6275709420442581, 0.3839164972305298, 0.5210621058940887), (1, 0.6204287260770798, 0.5118563622236252, 0.41992297768592834, 0.7357305586338043)]\n",
      "Detections: ['original_image', 'footwear', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatos_553.png: 640x512 1 Bottomwear, 2 Footwears, 91.5ms\n",
      "Speed: 1.9ms preprocess, 91.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatos_553.png\n",
      "Annotations: [(2, 0.665496826171875, 0.7265626192092896, 0.24912047386169434, 0.2817952632904053), (2, 0.3347635790705681, 0.5996329188346863, 0.30237026512622833, 0.33567559719085693), (1, 0.542329728603363, 0.28570443391799927, 0.7040574550628662, 0.5714088678359985)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3307.png: 640x512 1 Topwear, 90.8ms\n",
      "Speed: 2.3ms preprocess, 90.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_3307.png\n",
      "Annotations: [(0, 0.764940470457077, 0.6686772555112839, 0.4142712950706482, 0.5777005255222321)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2865.png: 640x512 1 Bottomwear, 82.9ms\n",
      "Speed: 1.8ms preprocess, 82.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_2865.png\n",
      "Annotations: [(1, 0.27331631258130074, 0.5202578455209732, 0.41945894807577133, 0.646975964307785)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_3450.png: 640x512 1 Topwear, 82.7ms\n",
      "Speed: 1.7ms preprocess, 82.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_3450.png\n",
      "Annotations: [(0, 0.4926215410232544, 0.4815588742494583, 0.7088466882705688, 0.6427300870418549)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_2436.png: 640x544 1 Topwear, 1 Bottomwear, 98.9ms\n",
      "Speed: 1.8ms preprocess, 98.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_abrigos_2436.png\n",
      "Annotations: [(1, 0.4906472861766815, 0.9480101466178894, 0.5221680998802185, 0.09094119071960449), (0, 0.4674256145954132, 0.5636729076504707, 0.7177175879478455, 0.7742585986852646)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_4113.png: 640x640 1 Footwear, 101.2ms\n",
      "Speed: 2.2ms preprocess, 101.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_4113.png\n",
      "Annotations: [(2, 0.495555579662323, 0.48311641812324524, 0.3256288766860962, 0.1556437611579895)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_1383.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 78.7ms\n",
      "Speed: 1.9ms preprocess, 78.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_1383.png\n",
      "Annotations: [(2, 0.432162806391716, 0.8732234239578247, 0.14641955494880676, 0.19709312915802002), (2, 0.5963690280914307, 0.7545321583747864, 0.15195143222808838, 0.20184266567230225), (1, 0.4916718006134033, 0.2626645229756832, 0.47509443759918213, 0.33547670394182205)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_tacones_891.png: 640x512 2 Footwears, 81.8ms\n",
      "Speed: 1.8ms preprocess, 81.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_tacones_891.png\n",
      "Annotations: [(2, 0.735331267118454, 0.5996781587600708, 0.2948797345161438, 0.43196678161621094), (2, 0.30574728175997734, 0.6651318669319153, 0.4427909627556801, 0.3096092939376831)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4914.png: 640x480 1 Topwear, 85.2ms\n",
      "Speed: 1.7ms preprocess, 85.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisetas_4914.png\n",
      "Annotations: [(0, 0.5057756081223488, 0.5165644288063049, 0.8739203661680222, 0.8547121286392212)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_1236.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 87.7ms\n",
      "Speed: 1.9ms preprocess, 87.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_1236.png\n",
      "Annotations: [(2, 0.44568538665771484, 0.8959154486656189, 0.12112224102020264, 0.1182401180267334), (2, 0.5741153061389923, 0.815917044878006, 0.11204952001571655, 0.14028722047805786), (0, 0.48827093839645386, 0.17669033352285624, 0.589476466178894, 0.30324758403003216), (1, 0.49320976436138153, 0.47425656020641327, 0.3531576693058014, 0.7589248716831207)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_3514.png: 640x448 1 Topwear, 70.7ms\n",
      "Speed: 2.7ms preprocess, 70.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_3514.png\n",
      "Annotations: [(0, 0.4972953051328659, 0.48684829473495483, 0.6931401789188385, 0.7054500579833984)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1546.png: 640x544 1 Topwear, 81.5ms\n",
      "Speed: 1.8ms preprocess, 81.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_vestidos_1546.png\n",
      "Annotations: [(0, 0.49614423513412476, 0.49506622552871704, 0.4339005947113037, 0.868306040763855)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_1807.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 77.9ms\n",
      "Speed: 1.9ms preprocess, 77.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_1807.png\n",
      "Annotations: [(2, 0.5163795948028564, 0.9089619517326355, 0.10426890850067139, 0.15129148960113525), (2, 0.7728144526481628, 0.9132668375968933, 0.09687376022338867, 0.1652604341506958), (0, 0.7251425087451935, 0.2839501053094864, 0.2437766194343567, 0.20742473006248474), (1, 0.7251341044902802, 0.4667305648326874, 0.2829667925834656, 0.24365490674972534)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1155.png: 640x480 1 Topwear, 88.3ms\n",
      "Speed: 1.5ms preprocess, 88.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jeans_1155.png\n",
      "Annotations: [(0, 0.4908670634031296, 0.5056339502334595, 0.739233523607254, 0.8835047483444214)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_3937.png: 640x512 1 Topwear, 1 Bottomwear, 74.7ms\n",
      "Speed: 2.3ms preprocess, 74.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_3937.png\n",
      "Annotations: [(0, 0.4678216502070427, 0.5755371004343033, 0.6125594526529312, 0.7090661227703094)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_71.png: 640x544 1 Topwear, 82.6ms\n",
      "Speed: 2.4ms preprocess, 82.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_monos_71.png\n",
      "Annotations: [(1, 0.4167238175868988, 0.5898060649633408, 0.3301829695701599, 0.6543939411640167)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_551.png: 640x512 1 Bottomwear, 2 Footwears, 76.8ms\n",
      "Speed: 1.9ms preprocess, 76.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_551.png\n",
      "Annotations: [(2, 0.3059809133410454, 0.8794107437133789, 0.17573101818561554, 0.16733479499816895), (2, 0.5577806979417801, 0.8735498785972595, 0.1713167130947113, 0.18179535865783691), (1, 0.4341055154800415, 0.2653930261731148, 0.5507845878601074, 0.35486309230327606)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_2264.png: 640x512 1 Topwear, 1 Bottomwear, 97.0ms\n",
      "Speed: 1.8ms preprocess, 97.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_2264.png\n",
      "Annotations: [(1, 0.5809967517852783, 0.8611943125724792, 0.5230840444564819, 0.2776113748550415), (0, 0.4327717162668705, 0.5553664416074753, 0.6484152600169182, 0.6562038958072662)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_2565.png: 640x448 1 Topwear, 68.2ms\n",
      "Speed: 1.5ms preprocess, 68.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_vestidos_2565.png\n",
      "Annotations: [(0, 0.4021851234138012, 0.5278394222259521, 0.6241922751069069, 0.7006052732467651)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1349.png: 640x512 2 Footwears, 78.3ms\n",
      "Speed: 1.8ms preprocess, 78.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_1349.png\n",
      "Annotations: [(2, 0.2738502025604248, 0.626124382019043, 0.5477004051208496, 0.2456984519958496), (2, 0.6293706446886063, 0.6812652349472046, 0.6760319173336029, 0.3318129777908325)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_3500.png: 640x512 1 Topwear, 1 Bottomwear, 83.5ms\n",
      "Speed: 1.8ms preprocess, 83.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_3500.png\n",
      "Annotations: [(1, 0.6168172359466553, 0.9458723068237305, 0.5036591291427612, 0.10825538635253906), (0, 0.5664662197232246, 0.575805053114891, 0.7272776216268539, 0.7449691593647003)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_3241.png: 640x512 1 Bottomwear, 2 Footwears, 95.1ms\n",
      "Speed: 1.9ms preprocess, 95.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_3241.png\n",
      "Annotations: [(2, 0.5847024321556091, 0.8526254594326019, 0.16237592697143555, 0.1823168396949768), (2, 0.40766242146492004, 0.8308226764202118, 0.14857298135757446, 0.20778816938400269), (1, 0.5349674075841904, 0.2048676311969757, 0.43085935711860657, 0.26441800594329834)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2527.png: 640x512 1 Bottomwear, 86.8ms\n",
      "Speed: 1.7ms preprocess, 86.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_2527.png\n",
      "Annotations: [(1, 0.4843996688723564, 0.5034057050943375, 0.7585061937570572, 0.4584481418132782)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_641.png: 640x640 1 Topwear, 97.8ms\n",
      "Speed: 3.0ms preprocess, 97.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_abrigos_641.png\n",
      "Annotations: [(0, 0.5019100904464722, 0.49932126700878143, 0.733163595199585, 0.9499246180057526)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_763.png: 640x640 1 Footwear, 104.6ms\n",
      "Speed: 1.8ms preprocess, 104.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_763.png\n",
      "Annotations: [(2, 0.495555579662323, 0.48311641812324524, 0.3256288766860962, 0.1556437611579895)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4365.png: 640x512 1 Topwear, 79.4ms\n",
      "Speed: 2.0ms preprocess, 79.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4365.png\n",
      "Annotations: [(0, 0.5656007677316666, 0.5115896314382553, 0.5864363610744476, 0.6029305756092072)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_1764.png: 640x512 1 Topwear, 1 Bottomwear, 1 Footwear, 102.8ms\n",
      "Speed: 1.9ms preprocess, 102.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_1764.png\n",
      "Annotations: [(2, 0.46384990215301514, 0.9780159890651703, 0.18975937366485596, 0.04380995035171509), (1, 0.20817524194717407, 0.5606488436460495, 0.41635048389434814, 0.8704740107059479)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatos_510.png: 640x512 1 Bottomwear, 2 Footwears, 78.9ms\n",
      "Speed: 1.9ms preprocess, 78.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatos_510.png\n",
      "Annotations: [(2, 0.2749837040901184, 0.6427527070045471, 0.5499674081802368, 0.22015511989593506), (2, 0.5763111412525177, 0.7366164326667786, 0.6466085314750671, 0.25523805618286133), (1, 0.5878389179706573, 0.29536963999271393, 0.8243221640586853, 0.5755095183849335)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_1683.png: 640x640 1 Topwear, 95.5ms\n",
      "Speed: 2.1ms preprocess, 95.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_trajes_1683.png\n",
      "Annotations: [(0, 0.5076618269085884, 0.5876463130116463, 0.6448500007390976, 0.8084153980016708)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_2109.png: 640x544 1 Topwear, 1 Bottomwear, 83.0ms\n",
      "Speed: 1.7ms preprocess, 83.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisas-y-blusas_2109.png\n",
      "Annotations: [(1, 0.5405063927173615, 0.8990390002727509, 0.4986775517463684, 0.18405967950820923), (0, 0.5225348919630051, 0.5826333612203598, 0.5144161283969879, 0.5852241814136505)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_419.png: 640x512 2 Footwears, 79.0ms\n",
      "Speed: 1.7ms preprocess, 79.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sandalias_419.png\n",
      "Annotations: [(2, 0.6088045537471771, 0.5478347539901733, 0.5031031966209412, 0.34906578063964844)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_3650.png: 640x544 1 Topwear, 96.7ms\n",
      "Speed: 2.0ms preprocess, 96.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_abrigos_3650.png\n",
      "Annotations: [(0, 0.4874589815735817, 0.4921826273202896, 0.6101359575986862, 0.6161670386791229)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_1962.png: 640x448 1 Topwear, 69.7ms\n",
      "Speed: 1.3ms preprocess, 69.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_abrigos_1962.png\n",
      "Annotations: [(0, 0.4900352284312248, 0.5491669327020645, 0.9336140304803848, 0.8201719224452972)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_3214.png: 640x544 1 Topwear, 84.2ms\n",
      "Speed: 1.8ms preprocess, 84.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisas_3214.png\n",
      "Annotations: [(0, 0.510984867811203, 0.5199883133172989, 0.70200115442276, 0.6489634215831757)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_alpargatas_126.png: 640x512 2 Bottomwears, 4 Footwears, 83.1ms\n",
      "Speed: 1.9ms preprocess, 83.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_alpargatas_126.png\n",
      "Annotations: [(2, 0.6095443964004517, 0.7483898401260376, 0.4717247486114502, 0.21435999870300293), (2, 0.33699672296643257, 0.6626848578453064, 0.49333813041448593, 0.27493393421173096), (2, 0.6146870851516724, 0.37265102565288544, 0.49702370166778564, 0.294119268655777), (2, 0.3415469452738762, 0.25387898087501526, 0.41021503508090973, 0.3669518828392029)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_807.png: 640x512 1 Bottomwear, 2 Footwears, 82.3ms\n",
      "Speed: 1.8ms preprocess, 82.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_807.png\n",
      "Annotations: [(2, 0.30327606201171875, 0.9337141215801239, 0.10224884748458862, 0.1325717568397522), (2, 0.50981006026268, 0.9319690763950348, 0.207475483417511, 0.1198912262916565), (1, 0.3669521287083626, 0.5117736607789993, 0.3865262120962143, 0.6756006181240082)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_2564.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 97.3ms\n",
      "Speed: 2.0ms preprocess, 97.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_2564.png\n",
      "Annotations: [(2, 0.2761016935110092, 0.7543104887008667, 0.0983065664768219, 0.18619489669799805), (2, 0.30945731699466705, 0.906364381313324, 0.18568018078804016, 0.1564539670944214), (0, 0.27849938394501805, 0.17527134716510773, 0.5391233777627349, 0.35054269433021545), (1, 0.241471940651536, 0.5106047317385674, 0.40832067653536797, 0.5877528339624405), (1, 0.2672357615083456, 0.4253869652748108, 0.4942352660000324, 0.7991869449615479)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_2620.png: 640x640 1 Footwear, 96.6ms\n",
      "Speed: 2.1ms preprocess, 96.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_2620.png\n",
      "Annotations: [(2, 0.495555579662323, 0.48311641812324524, 0.3256288766860962, 0.1556437611579895)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_867.png: 640x512 2 Footwears, 78.1ms\n",
      "Speed: 1.9ms preprocess, 78.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sandalias_867.png\n",
      "Annotations: [(2, 0.4106801748275757, 0.6303691416978836, 0.2763897180557251, 0.3737100064754486), (2, 0.6837247610092163, 0.6191301345825195, 0.2939629554748535, 0.36980271339416504)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1104.png: 640x480 1 Bottomwear, 73.8ms\n",
      "Speed: 1.8ms preprocess, 73.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jeans_1104.png\n",
      "Annotations: [(1, 0.49993325769901276, 0.4982897937297821, 0.5040553510189056, 0.9628477692604065)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_2039.png: 640x544 1 Topwear, 92.4ms\n",
      "Speed: 1.8ms preprocess, 92.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisas_2039.png\n",
      "Annotations: [(0, 0.5176063179969788, 0.4892445355653763, 0.49917447566986084, 0.5935553014278412)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_1217.png: 640x448 1 Topwear, 1 Bottomwear, 76.7ms\n",
      "Speed: 2.1ms preprocess, 76.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_1217.png\n",
      "Annotations: [(1, 0.4789644032716751, 0.8183629810810089, 0.34724387526512146, 0.3632740378379822), (0, 0.46857647597789764, 0.4486410990357399, 0.5340053141117096, 0.47065310180187225)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5017.png: 640x512 2 Topwears, 1 Bottomwear, 1 Footwear, 80.9ms\n",
      "Speed: 1.9ms preprocess, 80.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_5017.png\n",
      "Annotations: [(1, 0.219460042193532, 0.8145708441734314, 0.35470640286803246, 0.3708583116531372), (0, 0.27018602937459946, 0.4755595922470093, 0.33446677029132843, 0.4654572010040283)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1982.png: 640x512 1 Topwear, 1 Bottomwear, 80.5ms\n",
      "Speed: 2.1ms preprocess, 80.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_1982.png\n",
      "Annotations: [(0, 0.5793450325727463, 0.5755571871995926, 0.7898419201374054, 0.7209207713603973)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_3086.png: 640x512 1 Topwear, 1 Bottomwear, 80.7ms\n",
      "Speed: 1.9ms preprocess, 80.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_3086.png\n",
      "Annotations: [(1, 0.32398786023259163, 0.9065388143062592, 0.4169171676039696, 0.1869223713874817), (0, 0.34189390391111374, 0.5575888901948929, 0.5409765392541885, 0.6497417390346527)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_polos_861.png: 640x544 1 Topwear, 95.5ms\n",
      "Speed: 1.8ms preprocess, 95.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_polos_861.png\n",
      "Annotations: [(0, 0.5008173808455467, 0.4940466582775116, 0.7851086407899857, 0.7205706238746643)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_3512.png: 640x512 1 Topwear, 1 Bottomwear, 81.0ms\n",
      "Speed: 2.0ms preprocess, 81.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_3512.png\n",
      "Annotations: [(1, 0.384028360247612, 0.8361851871013641, 0.44050779938697815, 0.3204272389411926), (0, 0.46062469482421875, 0.44883841276168823, 0.5844528675079346, 0.6206408739089966)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_2290.png: 640x512 1 Topwear, 1 Bottomwear, 80.7ms\n",
      "Speed: 1.8ms preprocess, 80.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_2290.png\n",
      "Annotations: [(1, 0.41906559467315674, 0.8886027634143829, 0.4200195074081421, 0.22279447317123413), (0, 0.4122089445590973, 0.5007377564907074, 0.5570263266563416, 0.6923996806144714)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_3936.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 79.5ms\n",
      "Speed: 1.8ms preprocess, 79.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_3936.png\n",
      "Annotations: [(2, 0.2844179570674896, 0.8965941369533539, 0.08555364608764648, 0.1362094283103943), (2, 0.5634765625, 0.8886098861694336, 0.09542584419250488, 0.14508843421936035), (0, 0.400412455201149, 0.20081070065498352, 0.257453054189682, 0.2677761912345886), (1, 0.4346770793199539, 0.5671962946653366, 0.35589608550071716, 0.5456024706363678)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_976.png: 640x512 1 Topwear, 1 Bottomwear, 80.2ms\n",
      "Speed: 1.7ms preprocess, 80.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_976.png\n",
      "Annotations: [(1, 0.491586372256279, 0.9131357371807098, 0.47811320424079895, 0.17372852563858032), (0, 0.4741566851735115, 0.575434684753418, 0.7936979383230209, 0.7201194763183594)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4732.png: 640x512 1 Topwear, 1 Footwear, 99.5ms\n",
      "Speed: 1.8ms preprocess, 99.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4732.png\n",
      "Annotations: [(2, 0.4758196324110031, 0.8204582929611206, 0.11659744381904602, 0.08421039581298828), (2, 0.576871395111084, 0.8248361349105835, 0.10887348651885986, 0.09673595428466797), (0, 0.6203667670488358, 0.5266207754611969, 0.33922144770622253, 0.667747437953949)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botines_343.png: 640x544 1 Footwear, 84.4ms\n",
      "Speed: 2.4ms preprocess, 84.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_botines_343.png\n",
      "Annotations: [(2, 0.49603309482336044, 0.54890576004982, 0.5811821967363358, 0.4789409041404724)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_planos_82.png: 640x512 2 Footwears, 76.4ms\n",
      "Speed: 2.0ms preprocess, 76.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_planos_82.png\n",
      "Annotations: [(2, 0.3658144921064377, 0.6812112331390381, 0.19522151350975037, 0.2646474838256836), (2, 0.6694124490022659, 0.6820001602172852, 0.36542460322380066, 0.28328561782836914)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_tacones_352.png: 640x512 2 Footwears, 79.2ms\n",
      "Speed: 1.8ms preprocess, 79.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_tacones_352.png\n",
      "Annotations: [(2, 0.3183149918913841, 0.6626305133104324, 0.21068711578845978, 0.39166101813316345), (2, 0.6346040070056915, 0.6221398711204529, 0.3687909245491028, 0.419752836227417)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_4868.png: 640x544 1 Topwear, 81.8ms\n",
      "Speed: 1.7ms preprocess, 81.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_abrigos_4868.png\n",
      "Annotations: [(0, 0.4965081624686718, 0.4513013828545809, 0.7655144110321999, 0.8003200553357601)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2130.png: 640x512 1 Bottomwear, 92.4ms\n",
      "Speed: 1.7ms preprocess, 92.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_2130.png\n",
      "Annotations: [(1, 0.4997008591890335, 0.47650906443595886, 0.7136155068874359, 0.45543843507766724)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_chanclas_11.png: 640x512 1 Bottomwear, 2 Footwears, 82.1ms\n",
      "Speed: 2.3ms preprocess, 82.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_chanclas_11.png\n",
      "Annotations: [(2, 0.4935314394533634, 0.7821817398071289, 0.9408447071909904, 0.2974393367767334), (1, 0.5, 0.2931981086730957, 1.0, 0.5863962173461914)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_3221.png: 640x512 1 Bottomwear, 77.9ms\n",
      "Speed: 1.9ms preprocess, 77.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_3221.png\n",
      "Annotations: [(1, 0.49323366582393646, 0.49520835280418396, 0.6375626623630524, 0.8572145104408264)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_5315.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 80.8ms\n",
      "Speed: 1.7ms preprocess, 80.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_5315.png\n",
      "Annotations: [(2, 0.2309710532426834, 0.8279270529747009, 0.11026343703269958, 0.1469879150390625), (0, 0.27784377336502075, 0.27603432536125183, 0.40209782123565674, 0.3910641074180603), (1, 0.23832993675023317, 0.5987717062234879, 0.45410200022161007, 0.4889242351055145)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_821.png: 640x512 1 Topwear, 1 Bottomwear, 78.4ms\n",
      "Speed: 1.8ms preprocess, 78.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_821.png\n",
      "Annotations: [(1, 0.5160338804125786, 0.893546462059021, 0.5546244531869888, 0.20128560066223145), (0, 0.4325734116137028, 0.5526043176651001, 0.6844239756464958, 0.5736556053161621)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_309.png: 640x448 1 Footwear, 65.4ms\n",
      "Speed: 1.5ms preprocess, 65.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_zapatillas_309.png\n",
      "Annotations: [(2, 0.4922763709910214, 0.5070444196462631, 0.9658309211954474, 0.24640920758247375)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_3985.png: 640x544 1 Topwear, 103.4ms\n",
      "Speed: 2.2ms preprocess, 103.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisetas_3985.png\n",
      "Annotations: [(0, 0.5014022961258888, 0.49939103424549103, 0.7098123282194138, 0.6273411214351654)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_3326.png: 640x512 1 Topwear, 1 Bottomwear, 79.8ms\n",
      "Speed: 1.9ms preprocess, 79.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_3326.png\n",
      "Annotations: [(1, 0.674354687333107, 0.8041874170303345, 0.41454872488975525, 0.3865755796432495), (0, 0.6792528331279755, 0.46927693486213684, 0.4399992823600769, 0.48965948820114136)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_684.png: 640x480 1 Topwear, 1 Bottomwear, 2 Footwears, 74.4ms\n",
      "Speed: 1.8ms preprocess, 74.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jeans_684.png\n",
      "Annotations: [(2, 0.4196621775627136, 0.9389864206314087, 0.11310571432113647, 0.10466337203979492), (2, 0.6381092071533203, 0.937260091304779, 0.17210054397583008, 0.10114967823028564), (0, 0.43873514235019684, 0.334522120654583, 0.3780868947505951, 0.38385190069675446), (1, 0.499846488237381, 0.6715478897094727, 0.3432958722114563, 0.4329073429107666)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_3913.png: 640x448 1 Topwear, 1 Bottomwear, 67.6ms\n",
      "Speed: 1.5ms preprocess, 67.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisetas_3913.png\n",
      "Annotations: [(1, 0.5366326905786991, 0.831038773059845, 0.9267346188426018, 0.33792245388031006), (0, 0.4885948523879051, 0.4407957047224045, 0.8218757659196854, 0.5063556730747223)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_2222.png: 640x512 1 Topwear, 1 Bottomwear, 81.2ms\n",
      "Speed: 1.9ms preprocess, 81.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_2222.png\n",
      "Annotations: [(1, 0.5340823233127594, 0.8049718141555786, 0.5053032040596008, 0.36775946617126465), (0, 0.48542530834674835, 0.48582689464092255, 0.4797745645046234, 0.5750927031040192)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2384.png: 640x512 1 Bottomwear, 2 Footwears, 103.3ms\n",
      "Speed: 1.9ms preprocess, 103.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_2384.png\n",
      "Annotations: [(2, 0.3602522164583206, 0.9126647710800171, 0.13460513949394226, 0.121124267578125), (2, 0.5576412379741669, 0.9190148711204529, 0.160244882106781, 0.1400444507598877), (1, 0.419939361512661, 0.4700780212879181, 0.3880174905061722, 0.7068045735359192)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4671.png: 640x544 1 Bottomwear, 78.2ms\n",
      "Speed: 1.9ms preprocess, 78.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_jeans_4671.png\n",
      "Annotations: [(1, 0.5010645985603333, 0.5077860355377197, 0.3923715353012085, 0.7343935966491699)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_1882.png: 640x480 1 Topwear, 69.8ms\n",
      "Speed: 1.9ms preprocess, 69.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_1882.png\n",
      "Annotations: [(0, 0.491340646520257, 0.4555051028728485, 0.9013610891997814, 0.826442539691925)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_2303.png: 640x512 1 Bottomwear, 2 Footwears, 76.4ms\n",
      "Speed: 1.8ms preprocess, 76.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_2303.png\n",
      "Annotations: [(2, 0.6771474778652191, 0.7051277756690979, 0.3384203314781189, 0.2832549810409546), (2, 0.27690671873278916, 0.6409191191196442, 0.5428046188317239, 0.2775023579597473), (1, 0.6247657537460327, 0.2854986786842346, 0.7167590856552124, 0.5709973573684692)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1356.png: 640x512 1 Topwear, 74.7ms\n",
      "Speed: 1.6ms preprocess, 74.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_1356.png\n",
      "Annotations: [(0, 0.7049483060836792, 0.5513334423303604, 0.5901033878326416, 0.6657833755016327)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_48.png: 640x512 1 Topwear, 1 Bottomwear, 100.2ms\n",
      "Speed: 1.9ms preprocess, 100.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_48.png\n",
      "Annotations: [(1, 0.42316124588251114, 0.8738714158535004, 0.4609518498182297, 0.24276381731033325), (0, 0.5310803055763245, 0.5197414606809616, 0.6165237426757812, 0.6770385801792145)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botas_800.png: 640x512 1 Bottomwear, 1 Footwear, 78.0ms\n",
      "Speed: 1.8ms preprocess, 78.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_botas_800.png\n",
      "Annotations: [(2, 0.40632520988583565, 0.7317333817481995, 0.7051016315817833, 0.43913495540618896), (1, 0.47225088253617287, 0.25094348192214966, 0.7900926992297173, 0.5018869638442993)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_2711.png: 640x512 1 Topwear, 1 Bottomwear, 77.6ms\n",
      "Speed: 1.7ms preprocess, 77.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_2711.png\n",
      "Annotations: [(0, 0.7083882689476013, 0.3714289516210556, 0.44106578826904297, 0.32149890065193176), (1, 0.733880802989006, 0.7498801946640015, 0.5307436287403107, 0.48267531394958496)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1722.png: 640x512 1 Bottomwear, 2 Footwears, 78.0ms\n",
      "Speed: 1.8ms preprocess, 78.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_1722.png\n",
      "Annotations: [(2, 0.7171591520309448, 0.6989501118659973, 0.27946972846984863, 0.3230830430984497), (2, 0.402637280523777, 0.5789166986942291, 0.3517374247312546, 0.3768081068992615), (1, 0.5668211951851845, 0.24974807351827621, 0.866357609629631, 0.4919269233942032)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_901.png: 640x512 1 Bottomwear, 2 Footwears, 77.7ms\n",
      "Speed: 1.9ms preprocess, 77.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_901.png\n",
      "Annotations: [(2, 0.46420280635356903, 0.9323670864105225, 0.15195408463478088, 0.09747004508972168), (2, 0.17234881222248077, 0.9381512403488159, 0.16930481791496277, 0.09224081039428711), (1, 0.38041073828935623, 0.5016031712293625, 0.34708522260189056, 0.7279651463031769)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_3610.png: 640x512 1 Topwear, 1 Bottomwear, 102.0ms\n",
      "Speed: 1.9ms preprocess, 102.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_3610.png\n",
      "Annotations: [(1, 0.5272931903600693, 0.9118003845214844, 0.4574533998966217, 0.14976489543914795), (0, 0.49889861792325974, 0.5540726184844971, 0.7072845846414566, 0.6272317171096802)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_1582.png: 640x512 1 Topwear, 1 Bottomwear, 78.3ms\n",
      "Speed: 1.9ms preprocess, 78.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_1582.png\n",
      "Annotations: [(1, 0.4440538287162781, 0.8165131211280823, 0.41166651248931885, 0.3556288480758667), (0, 0.46443768590688705, 0.557529054582119, 0.6130859404802322, 0.6608275920152664)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5339.png: 640x448 1 Topwear, 64.6ms\n",
      "Speed: 1.6ms preprocess, 64.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_sudaderas_5339.png\n",
      "Annotations: [(0, 0.4465683791786432, 0.6508060544729233, 0.8454687409102917, 0.6502518951892853)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_798.png: 640x544 1 Topwear, 1 Bottomwear, 82.2ms\n",
      "Speed: 1.7ms preprocess, 82.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_abrigos_798.png\n",
      "Annotations: [(1, 0.5580993443727493, 0.9501922428607941, 0.49186763167381287, 0.09961551427841187), (0, 0.5613407716155052, 0.5914264917373657, 0.6649733334779739, 0.7271773815155029)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_3902.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 80.2ms\n",
      "Speed: 2.0ms preprocess, 80.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_3902.png\n",
      "Annotations: [(2, 0.6062600910663605, 0.8187265396118164, 0.11368066072463989, 0.15992844104766846), (2, 0.3739788681268692, 0.8939694762229919, 0.16773846745491028, 0.15828704833984375), (1, 0.513588085770607, 0.3596714437007904, 0.3957466781139374, 0.2546461820602417), (0, 0.5594308748841286, 0.14337998628616333, 0.7423935383558273, 0.27056682109832764)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1603.png: 640x512 1 Bottomwear, 2 Footwears, 98.3ms\n",
      "Speed: 1.9ms preprocess, 98.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_1603.png\n",
      "Annotations: [(2, 0.4871145603246987, 0.7111075520515442, 0.9473036294803023, 0.32606709003448486), (1, 0.5, 0.2859671711921692, 1.0, 0.5719343423843384)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1203.png: 640x512 1 Bottomwear, 2 Footwears, 79.0ms\n",
      "Speed: 2.2ms preprocess, 79.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_1203.png\n",
      "Annotations: [(2, 0.6841803193092346, 0.7096551656723022, 0.2594541311264038, 0.306740403175354), (2, 0.3714156001806259, 0.5939426720142365, 0.3431439697742462, 0.3764340281486511), (1, 0.5323773175477982, 0.26129840314388275, 0.7614642083644867, 0.5041318237781525)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_574.png: 640x512 1 Topwear, 76.0ms\n",
      "Speed: 1.7ms preprocess, 76.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_574.png\n",
      "Annotations: [(0, 0.5019207149744034, 0.4565909206867218, 0.5622393786907196, 0.6492554545402527)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_2157.png: 640x640 1 Bottomwear, 96.8ms\n",
      "Speed: 2.7ms preprocess, 96.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_faldas_2157.png\n",
      "Annotations: [(1, 0.5005396455526352, 0.6037865281105042, 0.8687961399555206, 0.7134721279144287)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_1227.png: 640x512 1 Topwear, 1 Bottomwear, 77.8ms\n",
      "Speed: 1.8ms preprocess, 77.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_1227.png\n",
      "Annotations: [(1, 0.4346465468406677, 0.9068486392498016, 0.35924291610717773, 0.18630272150039673), (0, 0.4344961494207382, 0.5549325346946716, 0.49069204926490784, 0.6587228775024414)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_1565.png: 640x512 1 Topwear, 1 Bottomwear, 103.8ms\n",
      "Speed: 1.6ms preprocess, 103.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_1565.png\n",
      "Annotations: [(1, 0.722817450761795, 0.8393815159797668, 0.4264151453971863, 0.31852781772613525), (0, 0.6860239803791046, 0.5579913407564163, 0.5284218192100525, 0.5851255357265472)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_2609.png: 640x480 1 Topwear, 72.1ms\n",
      "Speed: 1.7ms preprocess, 72.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_2609.png\n",
      "Annotations: [(0, 0.5044607613235712, 0.5492199510335922, 0.9281258396804333, 0.8758683502674103)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3445.png: 640x512 2 Topwears, 1 Bottomwear, 2 Footwears, 75.6ms\n",
      "Speed: 1.9ms preprocess, 75.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_3445.png\n",
      "Annotations: [(2, 0.5256239622831345, 0.8946042358875275, 0.08472338318824768, 0.14571458101272583), (2, 0.7576334178447723, 0.8534616529941559, 0.12254375219345093, 0.15153366327285767), (0, 0.6881940364837646, 0.4814586341381073, 0.3748903274536133, 0.5503024458885193)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_3087.png: 640x512 1 Topwear, 1 Bottomwear, 77.7ms\n",
      "Speed: 2.1ms preprocess, 77.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_3087.png\n",
      "Annotations: [(1, 0.34273730404675007, 0.8744197487831116, 0.6083578132092953, 0.25116050243377686), (0, 0.3718656247947365, 0.511149451136589, 0.7285908567719162, 0.7224642336368561)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_5206.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 83.1ms\n",
      "Speed: 2.3ms preprocess, 83.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_5206.png\n",
      "Annotations: [(2, 0.6920645236968994, 0.8548586964607239, 0.09512495994567871, 0.1273505687713623), (2, 0.46213793754577637, 0.8944610357284546, 0.143393874168396, 0.15046429634094238), (0, 0.7316607534885406, 0.14335891604423523, 0.37560874223709106, 0.28671783208847046), (1, 0.6582584530115128, 0.5185380578041077, 0.3973306119441986, 0.5806571245193481)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_278.png: 640x512 1 Topwear, 104.6ms\n",
      "Speed: 1.8ms preprocess, 104.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_278.png\n",
      "Annotations: [(0, 0.5036219581961632, 0.49362973123788834, 0.6926394253969193, 0.643198773264885)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_1778.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 80.3ms\n",
      "Speed: 2.2ms preprocess, 80.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_1778.png\n",
      "Annotations: [(2, 0.3459918797016144, 0.9329462647438049, 0.11221003532409668, 0.10147762298583984), (2, 0.6256055533885956, 0.9149357080459595, 0.1647281050682068, 0.09456944465637207), (1, 0.45476560294628143, 0.4498775899410248, 0.28745976090431213, 0.23652523756027222), (0, 0.43996700644493103, 0.2524664178490639, 0.26775437593460083, 0.26098357141017914)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5879.png: 640x480 1 Topwear, 69.9ms\n",
      "Speed: 1.8ms preprocess, 69.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisetas_5879.png\n",
      "Annotations: [(0, 0.4479138255119324, 0.48755279183387756, 0.8958276510238647, 0.9751055836677551)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_polos_69.png: 640x512 1 Topwear, 82.1ms\n",
      "Speed: 1.7ms preprocess, 82.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_polos_69.png\n",
      "Annotations: [(0, 0.4991983324289322, 0.44295233488082886, 0.584974855184555, 0.6459935903549194)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4933.png: 640x512 1 Topwear, 78.5ms\n",
      "Speed: 1.8ms preprocess, 78.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4933.png\n",
      "Annotations: [(0, 0.4753132164478302, 0.5580133199691772, 0.35793834924697876, 0.8245677947998047)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_1040.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 92.1ms\n",
      "Speed: 1.8ms preprocess, 92.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_1040.png\n",
      "Annotations: [(2, 0.6007399260997772, 0.8609522581100464, 0.1205701231956482, 0.1613328456878662), (2, 0.4614569693803787, 0.746506929397583, 0.13975068926811218, 0.21119952201843262), (1, 0.5143787711858749, 0.31662745773792267, 0.48392000794410706, 0.41787561774253845)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_2485.png: 640x512 1 Bottomwear, 2 Footwears, 89.7ms\n",
      "Speed: 2.0ms preprocess, 89.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_2485.png\n",
      "Annotations: [(2, 0.6363056898117065, 0.7025019526481628, 0.39347243309020996, 0.2877906560897827), (2, 0.2471638321876526, 0.6315842717885971, 0.4943276643753052, 0.2758517563343048), (1, 0.5777260661125183, 0.2940645068883896, 0.7730773687362671, 0.5741317570209503)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_2181.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 80.6ms\n",
      "Speed: 1.9ms preprocess, 80.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_2181.png\n",
      "Annotations: [(2, 0.6348948776721954, 0.9163941144943237, 0.08767729997634888, 0.13049018383026123), (0, 0.6334707885980606, 0.3186188265681267, 0.33957716822624207, 0.15802361071109772), (1, 0.6313265413045883, 0.5945380479097366, 0.3322315514087677, 0.369114488363266)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_338.png: 640x640 1 Bottomwear, 102.8ms\n",
      "Speed: 2.7ms preprocess, 102.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_shorts_338.png\n",
      "Annotations: [(1, 0.5113939568400383, 0.4951804280281067, 0.6156708151102066, 0.9602310657501221)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_576.png: 640x512 1 Bottomwear, 2 Footwears, 77.8ms\n",
      "Speed: 2.4ms preprocess, 77.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sandalias_576.png\n",
      "Annotations: [(2, 0.382407009601593, 0.7079107463359833, 0.30879247188568115, 0.16817647218704224), (2, 0.6216799020767212, 0.6873790323734283, 0.35862433910369873, 0.1793474555015564), (1, 0.4184999652206898, 0.2568085789680481, 0.5991769656538963, 0.5136171579360962)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_90.png: 640x544 1 Bottomwear, 105.4ms\n",
      "Speed: 1.4ms preprocess, 105.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_shorts_90.png\n",
      "Annotations: [(1, 0.5188972316682339, 0.45086799561977386, 0.8151928260922432, 0.7561066448688507)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_4971.png: 640x480 1 Topwear, 78.7ms\n",
      "Speed: 1.8ms preprocess, 78.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas-y-blusas_4971.png\n",
      "Annotations: [(0, 0.481748528778553, 0.3929422050714493, 0.6725027412176132, 0.548171728849411)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1634.png: 640x640 1 Footwear, 96.4ms\n",
      "Speed: 2.1ms preprocess, 96.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_1634.png\n",
      "Annotations: [(2, 0.5013609379529953, 0.5280242264270782, 0.8543929159641266, 0.4786784052848816)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_4440.png: 640x512 1 Topwear, 1 Bottomwear, 73.8ms\n",
      "Speed: 1.9ms preprocess, 73.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_4440.png\n",
      "Annotations: [(1, 0.433330699801445, 0.8776121437549591, 0.34284868836402893, 0.20059186220169067), (0, 0.43607454374432564, 0.5041405707597733, 0.7064234241843224, 0.6403473317623138)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1748.png: 640x480 1 Topwear, 69.9ms\n",
      "Speed: 1.7ms preprocess, 69.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_jeans_1748.png\n",
      "Annotations: [(0, 0.502558022737503, 0.4905539285391569, 0.8699730038642883, 0.8649102188646793)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_224.png: 640x448 1 Topwear, 66.4ms\n",
      "Speed: 1.2ms preprocess, 66.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jerseys_224.png\n",
      "Annotations: [(0, 0.5035121422261, 0.4983780235052109, 0.9163204468786716, 0.8420596420764923)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_3826.png: 640x512 1 Topwear, 1 Bottomwear, 84.6ms\n",
      "Speed: 2.0ms preprocess, 84.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_3826.png\n",
      "Annotations: [(1, 0.44055934250354767, 0.880133718252182, 0.3743431270122528, 0.23115390539169312), (0, 0.4707200452685356, 0.5271520465612411, 0.616546168923378, 0.617367297410965)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_294.png: 640x544 1 Footwear, 87.3ms\n",
      "Speed: 1.8ms preprocess, 87.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sandalias_294.png\n",
      "Annotations: [(2, 0.4903525784611702, 0.5929821282625198, 0.5613958686590195, 0.4008394181728363)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_3786.png: 640x448 1 Topwear, 1 Bottomwear, 69.6ms\n",
      "Speed: 1.9ms preprocess, 69.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_3786.png\n",
      "Annotations: [(1, 0.4595473036170006, 0.8791284561157227, 0.5879854708909988, 0.23288726806640625), (0, 0.5087540000677109, 0.558682456612587, 0.6309446394443512, 0.6265743672847748)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_156.png: 640x448 1 Topwear, 1 Bottomwear, 2 Footwears, 67.1ms\n",
      "Speed: 1.4ms preprocess, 67.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_pantalones_156.png\n",
      "Annotations: [(2, 0.6100578010082245, 0.9138031005859375, 0.11677604913711548, 0.09408128261566162), (2, 0.2897663787007332, 0.9354220032691956, 0.2113044708967209, 0.09351170063018799), (0, 0.5707936584949493, 0.3331163823604584, 0.3878169655799866, 0.3566367030143738), (1, 0.497470498085022, 0.6987669765949249, 0.39471864700317383, 0.4795611500740051)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4261.png: 640x512 1 Topwear, 1 Bottomwear, 77.3ms\n",
      "Speed: 2.0ms preprocess, 77.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4261.png\n",
      "Annotations: [(1, 0.408773735165596, 0.8897339105606079, 0.349366158246994, 0.22053217887878418), (0, 0.44202491641044617, 0.5212092995643616, 0.4758750796318054, 0.6082836389541626)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_724.png: 640x512 2 Bottomwears, 2 Footwears, 102.1ms\n",
      "Speed: 1.9ms preprocess, 102.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_724.png\n",
      "Annotations: [(2, 0.6005258560180664, 0.8174879550933838, 0.1575605869293213, 0.2127692699432373), (2, 0.2906971275806427, 0.8931799530982971, 0.22290641069412231, 0.17683100700378418), (1, 0.39764709770679474, 0.33385831117630005, 0.43108412623405457, 0.43992435932159424)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_2636.png: 640x512 1 Bottomwear, 79.0ms\n",
      "Speed: 1.9ms preprocess, 79.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_2636.png\n",
      "Annotations: [(1, 0.5026338249444962, 0.4782421924173832, 0.4248661696910858, 0.7252585217356682)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3168.png: 640x448 1 Topwear, 67.9ms\n",
      "Speed: 1.9ms preprocess, 67.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_vestidos_3168.png\n",
      "Annotations: [(0, 0.5077990368008614, 0.5130172520875931, 0.6999473422765732, 0.6727391183376312)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4089.png: 640x512 1 Topwear, 82.4ms\n",
      "Speed: 1.9ms preprocess, 82.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4089.png\n",
      "Annotations: [(0, 0.7646114528179169, 0.6051186248660088, 0.4590991139411926, 0.7594132572412491)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_1008.png: 640x544 1 Topwear, 81.0ms\n",
      "Speed: 1.8ms preprocess, 81.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisas-y-blusas_1008.png\n",
      "Annotations: [(0, 0.47972553968429565, 0.5010667741298676, 0.779503583908081, 0.574679434299469)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_4252.png: 640x512 1 Topwear, 1 Bottomwear, 87.1ms\n",
      "Speed: 1.8ms preprocess, 87.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_4252.png\n",
      "Annotations: [(1, 0.3898886442184448, 0.8713950216770172, 0.532193660736084, 0.2457541823387146), (0, 0.4256807416677475, 0.5227855294942856, 0.6960965692996979, 0.6079681217670441)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1147.png: 640x512 1 Topwear, 1 Bottomwear, 84.8ms\n",
      "Speed: 2.0ms preprocess, 84.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_1147.png\n",
      "Annotations: [(1, 0.4911181777715683, 0.8754984736442566, 0.455595999956131, 0.24900305271148682), (0, 0.40357832273002714, 0.5563085228204727, 0.8018452294636518, 0.7433666884899139)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_1218.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 79.2ms\n",
      "Speed: 1.9ms preprocess, 79.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_1218.png\n",
      "Annotations: [(2, 0.6895600855350494, 0.8293723165988922, 0.1698477864265442, 0.17145341634750366), (2, 0.5105763971805573, 0.9147007465362549, 0.2935907244682312, 0.1368544101715088), (1, 0.593620553612709, 0.44853843562304974, 0.35604891180992126, 0.7994069792330265)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_3210.png: 640x512 1 Topwear, 76.2ms\n",
      "Speed: 1.7ms preprocess, 76.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_3210.png\n",
      "Annotations: [(0, 0.49023931473493576, 0.47626838088035583, 0.7253326326608658, 0.6659536957740784)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4054.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 85.5ms\n",
      "Speed: 1.7ms preprocess, 85.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_4054.png\n",
      "Annotations: [(2, 0.6738044619560242, 0.8998376131057739, 0.09965598583221436, 0.14613008499145508), (2, 0.789497047662735, 0.8990192413330078, 0.09871441125869751, 0.15428423881530762), (0, 0.7511433660984039, 0.18448927998542786, 0.49771326780319214, 0.3689785599708557), (1, 0.7382487058639526, 0.5514779910445213, 0.35274946689605713, 0.6126498728990555)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2057.png: 640x512 1 Topwear, 1 Bottomwear, 85.4ms\n",
      "Speed: 1.9ms preprocess, 85.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_2057.png\n",
      "Annotations: [(1, 0.7191215604543686, 0.9278087615966797, 0.5110320150852203, 0.14438247680664062), (0, 0.7247489094734192, 0.5886871367692947, 0.5505021810531616, 0.6687718331813812)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatos_92.png: 640x448 2 Footwears, 83.6ms\n",
      "Speed: 1.7ms preprocess, 83.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_zapatos_92.png\n",
      "Annotations: [(2, 0.2722562551498413, 0.49644722044467926, 0.3986717462539673, 0.512900322675705), (2, 0.7358424663543701, 0.48620449006557465, 0.4242701530456543, 0.5180992186069489)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_193.png: 640x640 1 Bottomwear, 2 Footwears, 104.8ms\n",
      "Speed: 2.3ms preprocess, 104.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_pantalones_193.png\n",
      "Annotations: [(2, 0.8563863933086395, 0.8635363280773163, 0.17241686582565308, 0.21876031160354614), (2, 0.36015620827674866, 0.815621942281723, 0.27758973836898804, 0.22093826532363892), (1, 0.5622422844171524, 0.4093482196331024, 0.6250350177288055, 0.7688623070716858)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3041.png: 640x512 1 Topwear, 76.5ms\n",
      "Speed: 1.9ms preprocess, 76.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_3041.png\n",
      "Annotations: [(0, 0.3188709979876876, 0.576350674033165, 0.5766230095177889, 0.7214515507221222)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_729.png: 640x448 1 Footwear, 67.5ms\n",
      "Speed: 1.4ms preprocess, 67.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_zapatillas_729.png\n",
      "Annotations: [(2, 0.49658691114746034, 0.4925816059112549, 0.9885070477612317, 0.2582648992538452)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5065.png: 640x480 1 Topwear, 69.3ms\n",
      "Speed: 2.0ms preprocess, 69.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_5065.png\n",
      "Annotations: [(0, 0.4992264322936535, 0.40250343084335327, 0.7838549986481667, 0.6000570058822632)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_447.png: 640x640 1 Topwear, 99.7ms\n",
      "Speed: 1.7ms preprocess, 99.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_camisetas_447.png\n",
      "Annotations: [(0, 0.5023894906044006, 0.48918384313583374, 0.6158428192138672, 0.9396756887435913)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_1563.png: 640x512 1 Topwear, 1 Bottomwear, 98.3ms\n",
      "Speed: 2.0ms preprocess, 98.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_1563.png\n",
      "Annotations: [(1, 0.26953679250436835, 0.8254097998142242, 0.5372258439310826, 0.3235960602760315), (0, 0.3354494608938694, 0.489273339509964, 0.516024224460125, 0.6223954558372498)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5495.png: 640x544 1 Topwear, 84.8ms\n",
      "Speed: 2.2ms preprocess, 84.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisas-y-blusas_5495.png\n",
      "Annotations: [(0, 0.4909261390566826, 0.5117498636245728, 0.7219728380441666, 0.5169613361358643)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_19.png: 640x480 1 Bottomwear, 78.6ms\n",
      "Speed: 1.9ms preprocess, 78.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_pantalones_19.png\n",
      "Annotations: [(1, 0.5058584213256836, 0.5059656798839569, 0.5026377439498901, 0.9762452244758606)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1039.png: 640x512 1 Bottomwear, 2 Footwears, 79.7ms\n",
      "Speed: 2.0ms preprocess, 79.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_1039.png\n",
      "Annotations: [(2, 0.19696974754333496, 0.6229116916656494, 0.3939394950866699, 0.2098637819290161), (2, 0.5177373066544533, 0.6681925058364868, 0.620980903506279, 0.311873197555542), (1, 0.3823328008875251, 0.2869453430175781, 0.7067302484065294, 0.572115421295166)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_98.png: 640x640 1 Topwear, 2 Bottomwears, 2 Footwears, 95.8ms\n",
      "Speed: 2.0ms preprocess, 95.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_pantalones_98.png\n",
      "Annotations: [(2, 0.5455698221921921, 0.9265877306461334, 0.14465561509132385, 0.12777096033096313), (2, 0.45431801676750183, 0.8570671379566193, 0.11540466547012329, 0.16567152738571167), (1, 0.532473087310791, 0.663598507642746, 0.2236870527267456, 0.42693787813186646), (0, 0.5160247832536697, 0.2963247075676918, 0.32062384486198425, 0.3705637902021408)]\n",
      "Detections: ['original_image', 'footwear', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_126.png: 640x512 1 Topwear, 98.6ms\n",
      "Speed: 1.9ms preprocess, 98.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_126.png\n",
      "Annotations: [(0, 0.4906572960317135, 0.4837469607591629, 0.8167391493916512, 0.6630280911922455)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4422.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 114.9ms\n",
      "Speed: 1.9ms preprocess, 114.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_4422.png\n",
      "Annotations: [(2, 0.09001255128532648, 0.7844691872596741, 0.14745196513831615, 0.12924408912658691), (2, 0.296247236430645, 0.8015168905258179, 0.14739467203617096, 0.12955141067504883), (0, 0.21713828667998314, 0.16632001288235188, 0.20537615567445755, 0.25489726290106773), (1, 0.20543882995843887, 0.507005587220192, 0.30024902522563934, 0.5190171897411346)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_1718.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 88.6ms\n",
      "Speed: 2.1ms preprocess, 88.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_1718.png\n",
      "Annotations: [(2, 0.13255773857235909, 0.8793376684188843, 0.14864321798086166, 0.09377574920654297), (2, 0.30714308470487595, 0.9297187626361847, 0.16244234144687653, 0.10987263917922974), (1, 0.17026598379015923, 0.4405847638845444, 0.2295520082116127, 0.2099020779132843), (0, 0.2163006290793419, 0.2623860090970993, 0.24291391670703888, 0.23402073979377747)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_1401.png: 640x480 1 Topwear, 82.7ms\n",
      "Speed: 2.1ms preprocess, 82.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas_1401.png\n",
      "Annotations: [(0, 0.501033827662468, 0.37335461378097534, 0.4562813341617584, 0.456510066986084)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_1979.png: 640x512 1 Topwear, 1 Bottomwear, 91.0ms\n",
      "Speed: 1.9ms preprocess, 91.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_1979.png\n",
      "Annotations: [(0, 0.7695192992687225, 0.3515821769833565, 0.44294482469558716, 0.419606551527977), (1, 0.761176198720932, 0.7316022664308548, 0.474504292011261, 0.516920655965805)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5289.png: 640x512 1 Topwear, 2 Footwears, 85.7ms\n",
      "Speed: 2.0ms preprocess, 85.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_5289.png\n",
      "Annotations: [(2, 0.38573454320430756, 0.9122441411018372, 0.09551247954368591, 0.11368453502655029), (2, 0.06016649305820465, 0.9319831132888794, 0.1203329861164093, 0.12097358703613281), (0, 0.27936939895153046, 0.5143951028585434, 0.2977205812931061, 0.5428967773914337)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_872.png: 640x448 1 Topwear, 1 Bottomwear, 81.4ms\n",
      "Speed: 1.7ms preprocess, 81.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas_872.png\n",
      "Annotations: [(0, 0.5427378714084625, 0.6208679378032684, 0.8835638165473938, 0.7582641243934631)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_1888.png: 640x480 1 Topwear, 98.4ms\n",
      "Speed: 1.9ms preprocess, 98.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_1888.png\n",
      "Annotations: [(0, 0.5014508552849293, 0.44890719652175903, 0.8372131213545799, 0.769240140914917)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_2382.png: 640x512 1 Topwear, 1 Bottomwear, 79.5ms\n",
      "Speed: 2.0ms preprocess, 79.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_2382.png\n",
      "Annotations: [(1, 0.48389216512441635, 0.8539590239524841, 0.48538370430469513, 0.28505444526672363), (0, 0.4664042890071869, 0.5130117982625961, 0.7242575287818909, 0.6078311502933502)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5402.png: 640x640 1 Topwear, 98.9ms\n",
      "Speed: 2.6ms preprocess, 98.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_abrigos_5402.png\n",
      "Annotations: [(0, 0.501338392496109, 0.5059430748224258, 0.6950893998146057, 0.8833210170269012)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_2151.png: 640x512 1 Topwear, 76.7ms\n",
      "Speed: 1.9ms preprocess, 76.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_2151.png\n",
      "Annotations: [(0, 0.5, 0.5832559019327164, 1.0, 0.8254078328609467)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_2512.png: 640x512 1 Topwear, 78.8ms\n",
      "Speed: 1.9ms preprocess, 78.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_2512.png\n",
      "Annotations: [(0, 0.40970854088664055, 0.6559527516365051, 0.5862540379166603, 0.6645287275314331)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_153.png: 640x448 1 Footwear, 81.7ms\n",
      "Speed: 1.8ms preprocess, 81.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_zapatillas_153.png\n",
      "Annotations: [(2, 0.47341887652873993, 0.5028552412986755, 0.8041714727878571, 0.24427151679992676)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_472.png: 640x512 2 Topwears, 2 Bottomwears, 89.8ms\n",
      "Speed: 1.9ms preprocess, 89.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_472.png\n",
      "Annotations: [(1, 0.30799032375216484, 0.8742855787277222, 0.40849313884973526, 0.2238250970840454), (0, 0.745979517698288, 0.4856785386800766, 0.5080409646034241, 0.5999739468097687), (0, 0.26941826939582825, 0.49956007301807404, 0.5388365387916565, 0.6066647469997406)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1961.png: 640x512 1 Bottomwear, 79.6ms\n",
      "Speed: 1.8ms preprocess, 79.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_1961.png\n",
      "Annotations: [(1, 0.4809788689017296, 0.5613349676132202, 0.579317644238472, 0.7985813617706299)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_4913.png: 640x512 1 Topwear, 80.8ms\n",
      "Speed: 1.8ms preprocess, 80.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_4913.png\n",
      "Annotations: [(0, 0.49487945437431335, 0.48248322308063507, 0.7113154530525208, 0.6336731612682343)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2393.png: 640x640 1 Bottomwear, 2 Footwears, 95.7ms\n",
      "Speed: 2.1ms preprocess, 95.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_shorts_2393.png\n",
      "Annotations: [(2, 0.44015632569789886, 0.893555223941803, 0.14068391919136047, 0.1540052890777588), (2, 0.7387189865112305, 0.9017783105373383, 0.14805400371551514, 0.15010708570480347), (1, 0.49319952726364136, 0.17955040745437145, 0.34937524795532227, 0.2779840864241123)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_2469.png: 640x512 1 Bottomwear, 2 Footwears, 77.4ms\n",
      "Speed: 1.8ms preprocess, 77.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_2469.png\n",
      "Annotations: [(2, 0.18909281492233276, 0.6032181680202484, 0.3781856298446655, 0.21643787622451782), (2, 0.5144934579730034, 0.684275209903717, 0.6606686264276505, 0.3702749013900757), (1, 0.3359041213989258, 0.2804104834794998, 0.6329734325408936, 0.5281339585781097)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_3296.png: 640x512 1 Topwear, 1 Bottomwear, 95.5ms\n",
      "Speed: 1.8ms preprocess, 95.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_3296.png\n",
      "Annotations: [(1, 0.4984130784869194, 0.8204330205917358, 0.5231572538614273, 0.32407093048095703), (0, 0.5246778950095177, 0.44150683283805847, 0.5823783427476883, 0.5137658715248108)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_polos_693.png: 640x544 1 Topwear, 85.0ms\n",
      "Speed: 2.8ms preprocess, 85.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_polos_693.png\n",
      "Annotations: [(0, 0.5009188205003738, 0.45206218957901, 0.5984202325344086, 0.6296248435974121)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_3518.png: 640x512 1 Bottomwear, 2 Footwears, 78.4ms\n",
      "Speed: 2.0ms preprocess, 78.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_3518.png\n",
      "Annotations: [(2, 0.29484108090400696, 0.6665200591087341, 0.2529882788658142, 0.2574279308319092), (2, 0.5737437605857849, 0.6213598102331161, 0.31511199474334717, 0.36909225583076477), (1, 0.5102561265230179, 0.2799757719039917, 0.7654909789562225, 0.5599515438079834)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_3361.png: 640x544 1 Topwear, 1 Bottomwear, 2 Footwears, 82.2ms\n",
      "Speed: 3.6ms preprocess, 82.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_jeans_3361.png\n",
      "Annotations: [(2, 0.26815132796764374, 0.9025198221206665, 0.10645344853401184, 0.14034199714660645), (2, 0.49156735837459564, 0.929607480764389, 0.12636056542396545, 0.13486677408218384), (0, 0.3221964165568352, 0.06503049656748772, 0.4958543926477432, 0.12985119968652725), (1, 0.3495047762989998, 0.4730529226362705, 0.36385856568813324, 0.7095518037676811)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_180.png: 640x512 1 Bottomwear, 2 Footwears, 78.3ms\n",
      "Speed: 1.9ms preprocess, 78.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_180.png\n",
      "Annotations: [(2, 0.26990697532892227, 0.7532228231430054, 0.13467322289943695, 0.20923280715942383), (2, 0.437132865190506, 0.8811533451080322, 0.14872342348098755, 0.1990419626235962), (1, 0.3789653703570366, 0.2685275375843048, 0.4310361295938492, 0.35111427307128906)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5779.png: 640x448 1 Bottomwear, 66.1ms\n",
      "Speed: 1.2ms preprocess, 66.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_pantalones_5779.png\n",
      "Annotations: [(1, 0.4997129961848259, 0.49685192108154297, 0.6031910330057144, 0.9263894557952881)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_883.png: 640x512 2 Footwears, 104.9ms\n",
      "Speed: 1.9ms preprocess, 104.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sandalias_883.png\n",
      "Annotations: [(2, 0.7171943485736847, 0.6586369276046753, 0.4598010182380676, 0.3108876943588257), (2, 0.3147759512066841, 0.661779522895813, 0.49827931821346283, 0.37008965015411377)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_3554.png: 640x544 1 Topwear, 1 Bottomwear, 80.7ms\n",
      "Speed: 2.1ms preprocess, 80.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sudaderas_3554.png\n",
      "Annotations: [(1, 0.5079391747713089, 0.9643575847148895, 0.5080399215221405, 0.07128483057022095), (0, 0.5068623647093773, 0.5997906476259232, 0.7678979188203812, 0.7471955716609955)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4179.png: 640x544 1 Topwear, 80.5ms\n",
      "Speed: 1.7ms preprocess, 80.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisetas_4179.png\n",
      "Annotations: [(0, 0.5052075423300266, 0.4995761662721634, 0.9072322770953178, 0.8073700368404388)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4659.png: 640x512 1 Topwear, 1 Bottomwear, 78.6ms\n",
      "Speed: 1.8ms preprocess, 78.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4659.png\n",
      "Annotations: [(1, 0.6334458440542221, 0.8836767673492432, 0.41038385033607483, 0.2196035385131836), (0, 0.612993523478508, 0.5099216848611832, 0.6500132381916046, 0.6164672076702118)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_106.png: 640x512 1 Bottomwear, 75.4ms\n",
      "Speed: 1.5ms preprocess, 75.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_106.png\n",
      "Annotations: [(1, 0.49829065799713135, 0.5, 0.3801940679550171, 1.0)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_3372.png: 640x640 1 Topwear, 101.3ms\n",
      "Speed: 3.0ms preprocess, 101.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_camisetas_3372.png\n",
      "Annotations: [(0, 0.493532195687294, 0.4937087744474411, 0.649360865354538, 0.950676828622818)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_992.png: 640x512 1 Topwear, 1 Bottomwear, 104.1ms\n",
      "Speed: 1.9ms preprocess, 104.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_992.png\n",
      "Annotations: [(1, 0.510074719786644, 0.86922687292099, 0.428948312997818, 0.26154625415802), (0, 0.4074253113940358, 0.5775156170129776, 0.764059966430068, 0.7147087752819061)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_3417.png: 640x544 1 Topwear, 83.8ms\n",
      "Speed: 1.8ms preprocess, 83.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sudaderas_3417.png\n",
      "Annotations: [(0, 0.5, 0.5871192067861557, 1.0, 0.8257615864276886)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_2203.png: 640x512 1 Bottomwear, 83.3ms\n",
      "Speed: 2.0ms preprocess, 83.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_2203.png\n",
      "Annotations: [(1, 0.4974290207028389, 0.49897968769073486, 0.5589899867773056, 0.9285216331481934)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_93.png: 640x512 1 Topwear, 78.6ms\n",
      "Speed: 1.8ms preprocess, 78.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_93.png\n",
      "Annotations: [(0, 0.49688608199357986, 0.5076990127563477, 0.6765990108251572, 0.7452539205551147)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_832.png: 640x512 1 Topwear, 76.9ms\n",
      "Speed: 2.4ms preprocess, 76.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_832.png\n",
      "Annotations: [(0, 0.43366456031799316, 0.5491111427545547, 0.4435594081878662, 0.6959676444530487)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5573.png: 640x512 2 Topwears, 1 Bottomwear, 80.1ms\n",
      "Speed: 1.6ms preprocess, 80.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_5573.png\n",
      "Annotations: [(0, 0.769173800945282, 0.5716159641742706, 0.46165239810943604, 0.6702672839164734), (0, 0.32111968053504825, 0.578221321105957, 0.6263415524736047, 0.6379055976867676)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botas_481.png: 640x512 1 Bottomwear, 2 Footwears, 105.8ms\n",
      "Speed: 1.8ms preprocess, 105.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_botas_481.png\n",
      "Annotations: [(2, 0.36685383319854736, 0.6435731649398804, 0.4671316146850586, 0.31552767753601074), (2, 0.7648185789585114, 0.5280680656433105, 0.3806536793708801, 0.4214446544647217), (1, 0.40796077251434326, 0.25930024683475494, 0.5245265960693359, 0.5044586360454559)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_1798.png: 640x512 1 Topwear, 1 Bottomwear, 79.4ms\n",
      "Speed: 2.0ms preprocess, 79.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_1798.png\n",
      "Annotations: [(1, 0.48984745889902115, 0.8990953266620636, 0.490359827876091, 0.2018093466758728), (0, 0.5592239946126938, 0.5598639994859695, 0.4746040403842926, 0.6088450849056244)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_631.png: 640x416 1 Topwear, 66.0ms\n",
      "Speed: 1.5ms preprocess, 66.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 416)\n",
      "Processing dataset_trajes_631.png\n",
      "Annotations: [(0, 0.4937422163784504, 0.4991178512573242, 0.8960057720541954, 0.7545199394226074)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_356.png: 640x640 1 Bottomwear, 98.5ms\n",
      "Speed: 2.6ms preprocess, 98.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_shorts_356.png\n",
      "Annotations: [(1, 0.500824324786663, 0.49785497784614563, 0.679935947060585, 0.910767138004303)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_3602.png: 640x640 1 Topwear, 102.7ms\n",
      "Speed: 2.0ms preprocess, 102.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_sudaderas_3602.png\n",
      "Annotations: [(0, 0.4949636608362198, 0.4993270933628082, 0.6204441487789154, 0.9483512043952942)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5397.png: 640x512 1 Topwear, 94.0ms\n",
      "Speed: 1.9ms preprocess, 94.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_5397.png\n",
      "Annotations: [(0, 0.6591404676437378, 0.521819680929184, 0.588287353515625, 0.8424682021141052)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_1037.png: 640x512 1 Bottomwear, 2 Footwears, 88.5ms\n",
      "Speed: 1.9ms preprocess, 88.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_1037.png\n",
      "Annotations: [(2, 0.49525175988674164, 0.9081140160560608, 0.09934428334236145, 0.11613428592681885), (2, 0.21720629185438156, 0.9069401621818542, 0.08733303844928741, 0.1361769437789917), (1, 0.36600983887910843, 0.48767954111099243, 0.36036454141139984, 0.736716628074646)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4228.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 79.6ms\n",
      "Speed: 2.0ms preprocess, 79.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4228.png\n",
      "Annotations: [(2, 0.40792839229106903, 0.8603380024433136, 0.12454041838645935, 0.15273326635360718), (2, 0.5271403044462204, 0.7190487384796143, 0.13574627041816711, 0.19755709171295166), (1, 0.4635334759950638, 0.4899807795882225, 0.39091214537620544, 0.6603498011827469)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1213.png: 640x448 1 Bottomwear, 70.8ms\n",
      "Speed: 1.8ms preprocess, 70.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jeans_1213.png\n",
      "Annotations: [(1, 0.49393510073423386, 0.49317009933292866, 0.5049151331186295, 0.8752824924886227)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_5023.png: 640x480 1 Bottomwear, 2 Footwears, 73.2ms\n",
      "Speed: 1.8ms preprocess, 73.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_pantalones_5023.png\n",
      "Annotations: [(2, 0.7250404953956604, 0.9492969512939453, 0.15000689029693604, 0.08678460121154785), (2, 0.4636378288269043, 0.9447816908359528, 0.16240334510803223, 0.08264631032943726), (1, 0.5899887681007385, 0.5317234396934509, 0.355204701423645, 0.7046663761138916)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5983.png: 640x544 1 Topwear, 1 Bottomwear, 85.2ms\n",
      "Speed: 2.1ms preprocess, 85.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sudaderas_5983.png\n",
      "Annotations: [(1, 0.4719465672969818, 0.9282140731811523, 0.5624848008155823, 0.1435718536376953), (0, 0.5077569857239723, 0.5719893574714661, 0.6004697531461716, 0.6476993560791016)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_582.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 102.3ms\n",
      "Speed: 1.9ms preprocess, 102.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_582.png\n",
      "Annotations: [(2, 0.4422798305749893, 0.8673810660839081, 0.07984951138496399, 0.1328851580619812), (2, 0.650736004114151, 0.860319972038269, 0.09120851755142212, 0.15048134326934814), (1, 0.6155680418014526, 0.5159094929695129, 0.34714508056640625, 0.40709996223449707), (0, 0.6247899830341339, 0.29110055416822433, 0.45094484090805054, 0.4026072174310684)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1591.png: 640x512 1 Bottomwear, 2 Footwears, 87.5ms\n",
      "Speed: 2.1ms preprocess, 87.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_1591.png\n",
      "Annotations: [(2, 0.6551996469497681, 0.6698047071695328, 0.25430285930633545, 0.37896808981895447), (2, 0.3317597508430481, 0.5874691158533096, 0.38298237323760986, 0.36067959666252136), (1, 0.4842195324599743, 0.2774120420217514, 0.7530509606003761, 0.5425582230091095)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_1718.png: 640x480 1 Topwear, 74.9ms\n",
      "Speed: 1.7ms preprocess, 74.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_pantalones_1718.png\n",
      "Annotations: [(0, 0.5029797628521919, 0.48372748494148254, 0.8236702531576157, 0.8462182879447937)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatos_24.png: 640x448 2 Footwears, 67.4ms\n",
      "Speed: 1.6ms preprocess, 67.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_zapatos_24.png\n",
      "Annotations: [(2, 0.2948894426226616, 0.5064270496368408, 0.3993128091096878, 0.49827003479003906), (2, 0.6986077576875687, 0.506719708442688, 0.4144655168056488, 0.506140947341919)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_104.png: 640x512 1 Bottomwear, 2 Footwears, 82.2ms\n",
      "Speed: 1.9ms preprocess, 82.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sandalias_104.png\n",
      "Annotations: [(2, 0.7169162631034851, 0.6881685256958008, 0.3069971799850464, 0.3375821113586426), (2, 0.3130284808576107, 0.6434853076934814, 0.5250303223729134, 0.2695193290710449), (1, 0.6006737425923347, 0.28494974970817566, 0.7071634382009506, 0.5411811470985413)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4522.png: 640x544 1 Topwear, 83.1ms\n",
      "Speed: 1.6ms preprocess, 83.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_vestidos_4522.png\n",
      "Annotations: [(0, 0.5029127970337868, 0.517418697476387, 0.5556725710630417, 0.6841376721858978)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_1370.png: 640x544 1 Topwear, 80.5ms\n",
      "Speed: 2.8ms preprocess, 80.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_abrigos_1370.png\n",
      "Annotations: [(0, 0.4888085201382637, 0.49760885536670685, 0.6634781211614609, 0.6263066232204437)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_2812.png: 416x640 1 Topwear, 82.6ms\n",
      "Speed: 3.9ms preprocess, 82.6ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Processing dataset_camisetas_2812.png\n",
      "Annotations: [(0, 0.4933589845895767, 0.5309076681733131, 0.47593924403190613, 0.8832270354032516)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4296.png: 640x512 1 Topwear, 1 Bottomwear, 79.9ms\n",
      "Speed: 2.0ms preprocess, 79.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_4296.png\n",
      "Annotations: [(0, 0.4956439584493637, 0.5806531459093094, 0.5682672560214996, 0.6801044642925262)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_1528.png: 640x480 1 Topwear, 75.4ms\n",
      "Speed: 1.7ms preprocess, 75.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_pantalones_1528.png\n",
      "Annotations: [(0, 0.49327751249074936, 0.4902981072664261, 0.74053855240345, 0.9298573434352875)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_1795.png: 640x512 1 Topwear, 1 Bottomwear, 82.9ms\n",
      "Speed: 1.9ms preprocess, 82.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_1795.png\n",
      "Annotations: [(1, 0.4793452173471451, 0.934083104133606, 0.5130474269390106, 0.12488508224487305), (0, 0.4329366832971573, 0.622017428278923, 0.7341038882732391, 0.7089301645755768)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_2378.png: 640x512 1 Topwear, 1 Bottomwear, 83.1ms\n",
      "Speed: 2.0ms preprocess, 83.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_2378.png\n",
      "Annotations: [(1, 0.38949981331825256, 0.8796785175800323, 0.44092410802841187, 0.2406429648399353), (0, 0.388113709166646, 0.511932872235775, 0.723872359842062, 0.6242941170930862)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_547.png: 640x512 1 Bottomwear, 84.8ms\n",
      "Speed: 1.9ms preprocess, 84.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_547.png\n",
      "Annotations: [(1, 0.5293387770652771, 0.4960775040090084, 0.6731749773025513, 0.7880633547902107)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_738.png: 640x512 2 Topwears, 111.5ms\n",
      "Speed: 2.0ms preprocess, 111.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_738.png\n",
      "Annotations: [(0, 0.32699716091156006, 0.35409076511859894, 0.45343172550201416, 0.3708542287349701), (1, 0.2805117219686508, 0.6400293707847595, 0.40060779452323914, 0.4282560348510742), (0, 0.3058897778391838, 0.5111463218927383, 0.4523848444223404, 0.6934106051921844)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_757.png: 640x640 1 Bottomwear, 101.7ms\n",
      "Speed: 2.7ms preprocess, 101.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_pantalones_757.png\n",
      "Annotations: [(1, 0.5035315155982971, 0.5079731941223145, 0.3422210216522217, 0.9343196153640747)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1350.png: 640x448 1 Topwear, 75.3ms\n",
      "Speed: 1.5ms preprocess, 75.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_sudaderas_1350.png\n",
      "Annotations: [(0, 0.4951173048466444, 0.5083446651697159, 0.9500622786581516, 0.8045570552349091)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_1514.png: 640x512 1 Topwear, 1 Bottomwear, 82.0ms\n",
      "Speed: 1.9ms preprocess, 82.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_1514.png\n",
      "Annotations: [(1, 0.21765471994876862, 0.861562967300415, 0.43530943989753723, 0.27022838592529297), (0, 0.315191388130188, 0.5058432146906853, 0.630382776260376, 0.5905264765024185)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_3091.png: 640x544 1 Topwear, 87.2ms\n",
      "Speed: 1.7ms preprocess, 87.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_abrigos_3091.png\n",
      "Annotations: [(0, 0.49261125922203064, 0.4807470738887787, 0.7397032380104065, 0.7029573321342468)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_5528.png: 640x640 1 Topwear, 106.9ms\n",
      "Speed: 3.1ms preprocess, 106.9ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_abrigos_5528.png\n",
      "Annotations: [(0, 0.5017896890640259, 0.49286394007503986, 0.629538893699646, 0.8974303267896175)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5162.png: 640x512 1 Topwear, 91.5ms\n",
      "Speed: 1.8ms preprocess, 91.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_5162.png\n",
      "Annotations: [(0, 0.5002349093556404, 0.47948965430259705, 0.7925999015569687, 0.7012311816215515)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_1014.png: 640x480 1 Topwear, 73.1ms\n",
      "Speed: 1.9ms preprocess, 73.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas_1014.png\n",
      "Annotations: [(0, 0.49771130084991455, 0.3987218588590622, 0.48660600185394287, 0.4496125280857086)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_tacones_455.png: 640x544 1 Footwear, 78.7ms\n",
      "Speed: 1.8ms preprocess, 78.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_tacones_455.png\n",
      "Annotations: [(2, 0.49979396164417267, 0.5837165713310242, 0.5493106544017792, 0.45286285877227783)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1986.png: 640x512 1 Bottomwear, 80.1ms\n",
      "Speed: 1.8ms preprocess, 80.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_1986.png\n",
      "Annotations: [(1, 0.4978488087654114, 0.5029662977904081, 0.6226681470870972, 0.897209856659174)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_824.png: 640x640 1 Topwear, 112.8ms\n",
      "Speed: 2.4ms preprocess, 112.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_abrigos_824.png\n",
      "Annotations: [(0, 0.49797892570495605, 0.5499183535575867, 0.7329485416412354, 0.8743575811386108)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botines_219.png: 640x480 1 Footwear, 92.9ms\n",
      "Speed: 1.8ms preprocess, 92.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_botines_219.png\n",
      "Annotations: [(2, 0.518885649740696, 0.642747551202774, 0.62344591319561, 0.41424649953842163)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_4224.png: 640x512 1 Topwear, 1 Bottomwear, 88.0ms\n",
      "Speed: 2.2ms preprocess, 88.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_4224.png\n",
      "Annotations: [(1, 0.4771200269460678, 0.8518480062484741, 0.41029372811317444, 0.28062891960144043), (0, 0.48579104244709015, 0.4926271438598633, 0.5990470349788666, 0.4866856336593628)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_4317.png: 640x512 1 Topwear, 1 Bottomwear, 83.2ms\n",
      "Speed: 1.8ms preprocess, 83.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_4317.png\n",
      "Annotations: [(1, 0.3898230716586113, 0.8908470869064331, 0.4801623970270157, 0.2183058261871338), (0, 0.41629739850759506, 0.5234755352139473, 0.5524707585573196, 0.6758117526769638)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_1598.png: 640x448 1 Topwear, 1 Bottomwear, 69.8ms\n",
      "Speed: 1.5ms preprocess, 69.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_abrigos_1598.png\n",
      "Annotations: [(1, 0.5668255537748337, 0.9111706912517548, 0.5093232691287994, 0.17427366971969604), (0, 0.5732885673642159, 0.5765419453382492, 0.8150985091924667, 0.7847954332828522)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_3192.png: 640x544 1 Topwear, 1 Bottomwear, 80.5ms\n",
      "Speed: 2.4ms preprocess, 80.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisas-y-blusas_3192.png\n",
      "Annotations: [(1, 0.7171181291341782, 0.8168134987354279, 0.48077717423439026, 0.3663730025291443), (0, 0.7215017229318619, 0.44740030169487, 0.52066370844841, 0.4871283173561096)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_4256.png: 640x512 1 Topwear, 1 Bottomwear, 81.2ms\n",
      "Speed: 1.8ms preprocess, 81.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_4256.png\n",
      "Annotations: [(1, 0.3662632927298546, 0.9156186580657959, 0.4015605002641678, 0.160933256149292), (0, 0.34528759121894836, 0.5709803774952888, 0.6905751824378967, 0.6683891862630844)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_1274.png: 640x512 2 Topwears, 1 Bottomwear, 1 Footwear, 91.3ms\n",
      "Speed: 1.9ms preprocess, 91.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_1274.png\n",
      "Annotations: [(2, 0.7302228212356567, 0.8831619620323181, 0.12962067127227783, 0.1378566026687622), (0, 0.5731165409088135, 0.31988805532455444, 0.24218571186065674, 0.34994739294052124), (1, 0.5760326534509659, 0.6382904052734375, 0.2859480082988739, 0.5996502637863159)]\n",
      "Detections: ['original_image', 'footwear', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_2109.png: 640x512 1 Topwear, 1 Bottomwear, 88.4ms\n",
      "Speed: 2.0ms preprocess, 88.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_2109.png\n",
      "Annotations: [(1, 0.41742462664842606, 0.9112389981746674, 0.521545872092247, 0.17752200365066528), (0, 0.4694943353533745, 0.5649967342615128, 0.6037666946649551, 0.6920208632946014)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_467.png: 640x480 1 Topwear, 70.9ms\n",
      "Speed: 1.8ms preprocess, 70.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_abrigos_467.png\n",
      "Annotations: [(0, 0.5053559150546789, 0.5045405030250549, 0.8966413326561451, 0.8851972818374634)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_3202.png: 640x544 1 Topwear, 82.5ms\n",
      "Speed: 1.7ms preprocess, 82.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisas_3202.png\n",
      "Annotations: [(0, 0.515686884522438, 0.48787739872932434, 0.4718814790248871, 0.5793343186378479)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_3479.png: 640x512 2 Topwears, 1 Bottomwear, 76.6ms\n",
      "Speed: 1.9ms preprocess, 76.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_3479.png\n",
      "Annotations: [(0, 0.2716663274914026, 0.5637772232294083, 0.5024385862052441, 0.70755335688591)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1486.png: 640x512 1 Bottomwear, 2 Footwears, 77.3ms\n",
      "Speed: 1.9ms preprocess, 77.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_1486.png\n",
      "Annotations: [(2, 0.23446257691830397, 0.5881639122962952, 0.4221054557710886, 0.1690601110458374), (2, 0.524701714515686, 0.7206055521965027, 0.6917595863342285, 0.27546560764312744), (1, 0.4177047424018383, 0.3192071467638016, 0.7143117561936378, 0.6187864243984222)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5452.png: 640x544 1 Topwear, 82.2ms\n",
      "Speed: 1.8ms preprocess, 82.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sudaderas_5452.png\n",
      "Annotations: [(0, 0.5180346593260765, 0.4971159100532532, 0.6286029368638992, 0.6639658212661743)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_753.png: 640x640 1 Footwear, 120.0ms\n",
      "Speed: 2.0ms preprocess, 120.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_753.png\n",
      "Annotations: [(2, 0.5033582746982574, 0.5695195496082306, 0.8305378556251526, 0.42246145009994507)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_762.png: 640x544 1 Topwear, 82.5ms\n",
      "Speed: 1.7ms preprocess, 82.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_abrigos_762.png\n",
      "Annotations: [(0, 0.5000416412949562, 0.5147518664598465, 0.7721577137708664, 0.7092836797237396)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_1871.png: 640x640 1 Topwear, 98.0ms\n",
      "Speed: 2.7ms preprocess, 98.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_abrigos_1871.png\n",
      "Annotations: [(0, 0.490605890750885, 0.48969320952892303, 0.6719894409179688, 0.9093761742115021)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4177.png: 640x512 1 Topwear, 80.1ms\n",
      "Speed: 1.8ms preprocess, 80.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_4177.png\n",
      "Annotations: [(0, 0.367657795548439, 0.5964645147323608, 0.46855685114860535, 0.599297285079956)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_513.png: 640x480 1 Footwear, 69.8ms\n",
      "Speed: 1.7ms preprocess, 69.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_zapatillas_513.png\n",
      "Annotations: [(2, 0.505676968023181, 0.5033254027366638, 0.9743788577616215, 0.3122140169143677)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_bodies_105.png: 640x544 1 Bottomwear, 82.0ms\n",
      "Speed: 2.0ms preprocess, 82.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_bodies_105.png\n",
      "Annotations: [(0, 0.531944990158081, 0.5814186185598373, 0.5467617511749268, 0.7316990196704865)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_3954.png: 640x512 1 Topwear, 1 Bottomwear, 105.3ms\n",
      "Speed: 2.0ms preprocess, 105.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_3954.png\n",
      "Annotations: [(1, 0.38512803614139557, 0.7916720807552338, 0.3502417504787445, 0.40153223276138306), (0, 0.4356791004538536, 0.5911896228790283, 0.498040035367012, 0.7002681493759155)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_4825.png: 640x448 1 Topwear, 73.3ms\n",
      "Speed: 2.5ms preprocess, 73.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_vestidos_4825.png\n",
      "Annotations: [(0, 0.48934071511030197, 0.4768117815256119, 0.7123173624277115, 0.9344355762004852)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_2322.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 84.2ms\n",
      "Speed: 2.1ms preprocess, 84.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_2322.png\n",
      "Annotations: [(2, 0.47232338786125183, 0.8998512625694275, 0.09054356813430786, 0.11062943935394287), (2, 0.27270662039518356, 0.9142927527427673, 0.09748370945453644, 0.11602485179901123), (0, 0.36502084881067276, 0.2907371520996094, 0.25900326669216156, 0.23968833684921265), (1, 0.28042393922805786, 0.5329822599887848, 0.34240978956222534, 0.38056081533432007)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_702.png: 640x512 1 Topwear, 88.5ms\n",
      "Speed: 2.0ms preprocess, 88.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_702.png\n",
      "Annotations: [(0, 0.4902863912284374, 0.4980529099702835, 0.9337154999375343, 0.7560902535915375)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_1169.png: 640x544 1 Bottomwear, 82.6ms\n",
      "Speed: 1.9ms preprocess, 82.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_jeans_1169.png\n",
      "Annotations: [(1, 0.504540391266346, 0.5225721970200539, 0.5092270225286484, 0.7067714184522629)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5092.png: 640x544 1 Topwear, 87.2ms\n",
      "Speed: 1.9ms preprocess, 87.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sudaderas_5092.png\n",
      "Annotations: [(0, 0.49821527674794197, 0.5151861310005188, 0.8023025617003441, 0.5849859714508057)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1284.png: 640x512 1 Topwear, 2 Footwears, 104.8ms\n",
      "Speed: 1.9ms preprocess, 104.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_1284.png\n",
      "Annotations: [(2, 0.8327632248401642, 0.8871502578258514, 0.08532696962356567, 0.14316731691360474), (2, 0.5642097890377045, 0.886773407459259, 0.09327107667922974, 0.13657760620117188), (0, 0.7702175974845886, 0.39954356849193573, 0.4367208480834961, 0.5286780893802643)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_3714.png: 640x544 1 Topwear, 84.5ms\n",
      "Speed: 1.8ms preprocess, 84.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisas_3714.png\n",
      "Annotations: [(0, 0.49653254449367523, 0.4966873526573181, 0.463860422372818, 0.5830153226852417)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_2177.png: 640x448 1 Topwear, 1 Bottomwear, 2 Footwears, 73.2ms\n",
      "Speed: 2.6ms preprocess, 73.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_jeans_2177.png\n",
      "Annotations: [(2, 0.5338098555803299, 0.9280740022659302, 0.1702786386013031, 0.1306629180908203), (2, 0.3424242436885834, 0.8824575245380402, 0.15912765264511108, 0.18176692724227905), (1, 0.43339380621910095, 0.44902272522449493, 0.4998179078102112, 0.7491607367992401)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_760.png: 640x480 1 Bottomwear, 73.7ms\n",
      "Speed: 1.8ms preprocess, 73.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_pantalones_760.png\n",
      "Annotations: [(1, 0.5023085474967957, 0.5035721957683563, 0.4820772409439087, 0.9928556084632874)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_3209.png: 640x480 1 Topwear, 76.6ms\n",
      "Speed: 1.8ms preprocess, 76.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisetas_3209.png\n",
      "Annotations: [(0, 0.500269927084446, 0.5138834863901138, 0.8238573521375656, 0.826621025800705)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5658.png: 640x544 1 Topwear, 85.7ms\n",
      "Speed: 1.7ms preprocess, 85.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sudaderas_5658.png\n",
      "Annotations: [(0, 0.5001687780022621, 0.5024295523762703, 0.6787388771772385, 0.6000465005636215)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5554.png: 640x512 1 Topwear, 100.4ms\n",
      "Speed: 1.9ms preprocess, 100.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_5554.png\n",
      "Annotations: [(0, 0.4997435435652733, 0.5158075541257858, 0.5860335379838943, 0.5444709360599518)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_652.png: 640x512 1 Bottomwear, 2 Footwears, 82.6ms\n",
      "Speed: 2.3ms preprocess, 82.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_652.png\n",
      "Annotations: [(2, 0.49727822840213776, 0.8901866972446442, 0.1030409038066864, 0.0996437668800354), (2, 0.321116641163826, 0.87691730260849, 0.10884889960289001, 0.09910714626312256), (1, 0.46361593902111053, 0.5773691684007645, 0.3558044731616974, 0.6094752252101898), (1, 0.44376859068870544, 0.4867449998855591, 0.3771288990974426, 0.7853577136993408)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4113.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 85.6ms\n",
      "Speed: 2.1ms preprocess, 85.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4113.png\n",
      "Annotations: [(2, 0.7777690589427948, 0.7926615178585052, 0.17474430799484253, 0.22500938177108765), (2, 0.5935797840356827, 0.8924447298049927, 0.3321288526058197, 0.1579657793045044), (0, 0.6905753463506699, 0.10166984423995018, 0.39049842953681946, 0.19520694762468338), (1, 0.6055845320224762, 0.4867068976163864, 0.44957906007766724, 0.7705532610416412)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2098.png: 640x512 1 Topwear, 81.8ms\n",
      "Speed: 1.9ms preprocess, 81.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_2098.png\n",
      "Annotations: [(0, 0.4983022417873144, 0.5049944967031479, 0.8877670355141163, 0.778241902589798)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_2053.png: 640x512 1 Topwear, 1 Bottomwear, 78.6ms\n",
      "Speed: 2.0ms preprocess, 78.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_2053.png\n",
      "Annotations: [(1, 0.36126959323883057, 0.8646416366100311, 0.3910977840423584, 0.217573344707489), (0, 0.3929753638803959, 0.5171069949865341, 0.5686651989817619, 0.6294852793216705)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5058.png: 640x512 1 Topwear, 1 Bottomwear, 80.5ms\n",
      "Speed: 2.1ms preprocess, 80.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_5058.png\n",
      "Annotations: [(0, 0.7708386480808258, 0.4092799499630928, 0.34144526720046997, 0.3714711517095566), (1, 0.7283158898353577, 0.80045086145401, 0.439799427986145, 0.39909827709198)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5714.png: 640x544 1 Topwear, 94.7ms\n",
      "Speed: 2.5ms preprocess, 94.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sudaderas_5714.png\n",
      "Annotations: [(0, 0.4937361404299736, 0.5027855634689331, 0.7373455911874771, 0.6990010738372803)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_1308.png: 640x512 2 Bottomwears, 2 Footwears, 94.2ms\n",
      "Speed: 2.0ms preprocess, 94.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_1308.png\n",
      "Annotations: [(2, 0.7205466032028198, 0.8158120512962341, 0.12964749336242676, 0.13290345668792725), (2, 0.5590270459651947, 0.8701851963996887, 0.17453902959823608, 0.16347134113311768), (1, 0.7035518139600754, 0.31864960491657257, 0.47643545269966125, 0.29854461550712585)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_bodies_116.png: 640x512 1 Topwear, 1 Bottomwear, 82.9ms\n",
      "Speed: 2.0ms preprocess, 82.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_bodies_116.png\n",
      "Annotations: [(1, 0.3742194250226021, 0.795963853597641, 0.4609938710927963, 0.387218177318573), (0, 0.2929629348218441, 0.5753002613782883, 0.5040528252720833, 0.54886594414711)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_1632.png: 640x480 1 Topwear, 73.3ms\n",
      "Speed: 1.9ms preprocess, 73.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas-y-blusas_1632.png\n",
      "Annotations: [(0, 0.502336174249649, 0.40076494216918945, 0.6420761942863464, 0.5615620613098145)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_abrigos_3685.png: 640x512 1 Topwear, 1 Bottomwear, 78.4ms\n",
      "Speed: 2.0ms preprocess, 78.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_abrigos_3685.png\n",
      "Annotations: [(1, 0.31610023230314255, 0.9042955040931702, 0.45138980448246, 0.16409361362457275), (0, 0.3919817730784416, 0.5747008770704269, 0.6216783672571182, 0.6336127817630768)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_1267.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 78.6ms\n",
      "Speed: 1.8ms preprocess, 78.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_1267.png\n",
      "Annotations: [(2, 0.4197080433368683, 0.9425713419914246, 0.09230571985244751, 0.11410188674926758), (2, 0.4918083995580673, 0.8935164511203766, 0.09920576214790344, 0.1582736372947693), (0, 0.4667133390903473, 0.23906678706407547, 0.2719760537147522, 0.19268105924129486), (1, 0.3413206748664379, 0.5142883062362671, 0.5312570706009865, 0.37818217277526855)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_botas_742.png: 640x512 1 Bottomwear, 2 Footwears, 79.6ms\n",
      "Speed: 2.2ms preprocess, 79.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_botas_742.png\n",
      "Annotations: [(2, 0.625398576259613, 0.6487124264240265, 0.22639381885528564, 0.3892342448234558), (2, 0.2809045948088169, 0.576896458864212, 0.31669097393751144, 0.458753764629364), (1, 0.5675178021192551, 0.24997727572917938, 0.5257214605808258, 0.49995455145835876)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_86.png: 640x480 1 Topwear, 94.9ms\n",
      "Speed: 1.7ms preprocess, 94.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_vestidos_86.png\n",
      "Annotations: [(0, 0.49188312888145447, 0.5277159065008163, 0.48378878831863403, 0.7947277128696442)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1256.png: 640x512 1 Bottomwear, 2 Footwears, 81.9ms\n",
      "Speed: 1.9ms preprocess, 81.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_1256.png\n",
      "Annotations: [(1, 0.5544732920825481, 0.21717668324708939, 0.8910534158349037, 0.41895733773708344), (2, 0.48395130038261414, 0.6524685323238373, 0.9679026007652283, 0.42858272790908813)]\n",
      "Detections: ['original_image', 'footwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5705.png: 640x544 1 Topwear, 85.5ms\n",
      "Speed: 1.9ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_sudaderas_5705.png\n",
      "Annotations: [(0, 0.49542544037103653, 0.5112927034497261, 0.6849158257246017, 0.6277415603399277)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_5332.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 81.6ms\n",
      "Speed: 2.1ms preprocess, 81.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_5332.png\n",
      "Annotations: [(2, 0.5176417082548141, 0.8825637102127075, 0.18556657433509827, 0.08888661861419678), (2, 0.7656532526016235, 0.8370676636695862, 0.14410400390625, 0.19398152828216553), (0, 0.6131599843502045, 0.1381242498755455, 0.40909498929977417, 0.2539842873811722), (1, 0.6269226372241974, 0.501117005944252, 0.3643341660499573, 0.6677720248699188)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_bodies_23.png: 640x512 1 Topwear, 81.0ms\n",
      "Speed: 1.8ms preprocess, 81.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_bodies_23.png\n",
      "Annotations: [(0, 0.4980443939566612, 0.49155189096927643, 0.5015737563371658, 0.6121146380901337)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4441.png: 640x512 1 Bottomwear, 77.5ms\n",
      "Speed: 1.7ms preprocess, 77.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4441.png\n",
      "Annotations: [(1, 0.48693494498729706, 0.5583620667457581, 0.43823757767677307, 0.7252416610717773)]\n",
      "Detections: ['original_image', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2492.png: 640x512 1 Topwear, 1 Bottomwear, 101.2ms\n",
      "Speed: 1.9ms preprocess, 101.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_2492.png\n",
      "Annotations: [(1, 0.31109901145100594, 0.8180052042007446, 0.47057386487722397, 0.3180980682373047), (0, 0.29261040687561035, 0.5021999031305313, 0.5852208137512207, 0.6169906556606293)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_1283.png: 640x544 1 Topwear, 81.6ms\n",
      "Speed: 2.2ms preprocess, 81.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing dataset_camisas_1283.png\n",
      "Annotations: [(0, 0.49398791044950485, 0.5251944288611412, 0.6946659237146378, 0.6421283036470413)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_2948.png: 640x640 1 Footwear, 100.2ms\n",
      "Speed: 1.9ms preprocess, 100.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_2948.png\n",
      "Annotations: [(2, 0.5025465041399002, 0.5968281328678131, 0.822922557592392, 0.37952131032943726)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_5974.png: 640x640 1 Topwear, 96.4ms\n",
      "Speed: 2.0ms preprocess, 96.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_sudaderas_5974.png\n",
      "Annotations: [(0, 0.49357302486896515, 0.5052831768989563, 0.6113464534282684, 0.940963625907898)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_3811.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 86.2ms\n",
      "Speed: 1.8ms preprocess, 86.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_3811.png\n",
      "Annotations: [(2, 0.594251424074173, 0.9048379063606262, 0.15748602151870728, 0.17309319972991943), (2, 0.3657635748386383, 0.8377600908279419, 0.154449462890625, 0.18568658828735352), (1, 0.500229686498642, 0.5008262544870377, 0.4180755019187927, 0.6922799050807953)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_5238.png: 640x448 1 Topwear, 74.2ms\n",
      "Speed: 1.8ms preprocess, 74.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisas-y-blusas_5238.png\n",
      "Annotations: [(0, 0.4946360047906637, 0.4894370585680008, 0.9094563610851765, 0.6505697667598724)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_faldas_2696.png: 640x512 1 Topwear, 2 Footwears, 103.2ms\n",
      "Speed: 2.1ms preprocess, 103.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_faldas_2696.png\n",
      "Annotations: [(2, 0.6779151856899261, 0.9049310982227325, 0.08609753847122192, 0.10398465394973755), (2, 0.921505331993103, 0.9041122794151306, 0.1057664155960083, 0.10869491100311279), (0, 0.7659768164157867, 0.512946255505085, 0.3975549340248108, 0.7000927776098251)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_2564.png: 640x640 1 Footwear, 102.3ms\n",
      "Speed: 2.2ms preprocess, 102.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_2564.png\n",
      "Annotations: [(2, 0.5060627460479736, 0.578949511051178, 0.8463847637176514, 0.3928689956665039)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_775.png: 640x512 1 Topwear, 1 Bottomwear, 84.4ms\n",
      "Speed: 2.0ms preprocess, 84.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sudaderas_775.png\n",
      "Annotations: [(1, 0.5291228741407394, 0.8919003307819366, 0.461055189371109, 0.2161993384361267), (0, 0.5643504410982132, 0.5326607301831245, 0.5489254891872406, 0.6034142822027206)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_125.png: 640x640 1 Topwear, 97.0ms\n",
      "Speed: 2.8ms preprocess, 97.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_camisetas_125.png\n",
      "Annotations: [(0, 0.4875015914440155, 0.48820169270038605, 0.43485361337661743, 0.9306643903255463)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_5371.png: 640x512 1 Topwear, 1 Bottomwear, 83.5ms\n",
      "Speed: 1.9ms preprocess, 83.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisetas_5371.png\n",
      "Annotations: [(1, 0.6778154224157333, 0.9438075423240662, 0.48637154698371887, 0.11238491535186768), (0, 0.7078350931406021, 0.6096455752849579, 0.5771969258785248, 0.6184261441230774)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_5265.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 79.3ms\n",
      "Speed: 1.9ms preprocess, 79.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_5265.png\n",
      "Annotations: [(2, 0.41013163328170776, 0.8412277698516846, 0.11175847053527832, 0.11659491062164307), (2, 0.5354927331209183, 0.8186187744140625, 0.146954745054245, 0.15704596042633057), (1, 0.4666536748409271, 0.5513215065002441, 0.3755820393562317, 0.5007824897766113), (0, 0.37814416736364365, 0.2162727639079094, 0.44570429623126984, 0.4231364279985428)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jerseys_2000.png: 640x512 1 Topwear, 1 Bottomwear, 100.4ms\n",
      "Speed: 1.5ms preprocess, 100.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jerseys_2000.png\n",
      "Annotations: [(1, 0.4667608514428139, 0.80284184217453, 0.5276924818754196, 0.3846879005432129), (0, 0.4668457433581352, 0.4960460513830185, 0.5625778585672379, 0.5991028845310211)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_572.png: 640x512 2 Footwears, 80.8ms\n",
      "Speed: 2.9ms preprocess, 80.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sandalias_572.png\n",
      "Annotations: [(2, 0.2797377370297909, 0.6484347283840179, 0.4007144644856453, 0.27982527017593384), (2, 0.6721545159816742, 0.6529050469398499, 0.5656526684761047, 0.3364773988723755)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_1251.png: 640x480 1 Topwear, 73.5ms\n",
      "Speed: 1.7ms preprocess, 73.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisas_1251.png\n",
      "Annotations: [(0, 0.5090165175497532, 0.49424946308135986, 0.8229203149676323, 0.8275585174560547)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_4167.png: 640x640 1 Footwear, 97.4ms\n",
      "Speed: 2.0ms preprocess, 97.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_4167.png\n",
      "Annotations: [(2, 0.49274003505706787, 0.6009033024311066, 0.8653138875961304, 0.37439173460006714)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_jeans_4172.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 82.9ms\n",
      "Speed: 1.9ms preprocess, 82.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_jeans_4172.png\n",
      "Annotations: [(2, 0.7369121611118317, 0.8394167423248291, 0.10584372282028198, 0.13240396976470947), (2, 0.5158887356519699, 0.9158366620540619, 0.10945847630500793, 0.1629127860069275), (0, 0.6670325249433517, 0.1868566945195198, 0.45447924733161926, 0.36316637694835663), (1, 0.6360891461372375, 0.5081001371145248, 0.3894106149673462, 0.6276088058948517)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_5624.png: 640x512 1 Topwear, 1 Bottomwear, 80.0ms\n",
      "Speed: 1.9ms preprocess, 80.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_5624.png\n",
      "Annotations: [(1, 0.2011523051187396, 0.6531111598014832, 0.38996497727930546, 0.36808252334594727), (0, 0.28531893715262413, 0.4211833253502846, 0.49129659682512283, 0.36573486030101776)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4826.png: 640x480 1 Topwear, 83.8ms\n",
      "Speed: 2.0ms preprocess, 83.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_camisetas_4826.png\n",
      "Annotations: [(0, 0.5053974147886038, 0.5088309198617935, 0.8992521055042744, 0.8045293986797333)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_monos_736.png: 640x512 1 Bottomwear, 2 Footwears, 94.4ms\n",
      "Speed: 2.0ms preprocess, 94.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_monos_736.png\n",
      "Annotations: [(2, 0.9477929770946503, 0.8599799275398254, 0.0837051272392273, 0.14808905124664307), (2, 0.6625407040119171, 0.8537600934505463, 0.08403235673904419, 0.1497228741645813), (1, 0.7332049608230591, 0.47956113517284393, 0.4076319932937622, 0.6124846041202545)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_559.png: 640x512 1 Topwear, 2 Footwears, 79.7ms\n",
      "Speed: 2.0ms preprocess, 79.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_559.png\n",
      "Annotations: [(2, 0.6094507575035095, 0.9398752450942993, 0.11255013942718506, 0.10786151885986328), (2, 0.4624965339899063, 0.9168419241905212, 0.1796996295452118, 0.14319634437561035), (0, 0.5889808237552643, 0.5292645841836929, 0.33439821004867554, 0.7586357295513153)]\n",
      "Detections: ['original_image', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_cardigans_295.png: 640x512 1 Topwear, 1 Bottomwear, 88.0ms\n",
      "Speed: 1.9ms preprocess, 88.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_cardigans_295.png\n",
      "Annotations: [(1, 0.3726055696606636, 0.7596668004989624, 0.5012881606817245, 0.480631947517395), (0, 0.2923038201406598, 0.4800935983657837, 0.5610751714557409, 0.5611988306045532)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_3131.png: 640x640 1 Footwear, 103.4ms\n",
      "Speed: 2.1ms preprocess, 103.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_zapatillas_3131.png\n",
      "Annotations: [(2, 0.4985562711954117, 0.5638894289731979, 0.8515766561031342, 0.4489244520664215)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1660.png: 640x640 1 Topwear, 1 Bottomwear, 104.8ms\n",
      "Speed: 2.3ms preprocess, 104.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_sudaderas_1660.png\n",
      "Annotations: [(1, 0.47897082567214966, 0.9417387545108795, 0.3903435468673706, 0.11652249097824097), (0, 0.5191412270069122, 0.5931140184402466, 0.45794016122817993, 0.6627106666564941)]\n",
      "Detections: ['original_image', 'topwear', 'bottomwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4187.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 85.2ms\n",
      "Speed: 2.0ms preprocess, 85.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4187.png\n",
      "Annotations: [(2, 0.8372629284858704, 0.7925999760627747, 0.10922765731811523, 0.17161870002746582), (2, 0.4889884293079376, 0.8636220991611481, 0.2100808024406433, 0.14140349626541138), (0, 0.5888174325227737, 0.1339932233095169, 0.435703843832016, 0.25417789816856384), (1, 0.6535095870494843, 0.495284341275692, 0.48703116178512573, 0.6362403184175491)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4314.png: 640x512 2 Topwears, 2 Bottomwears, 4 Footwears, 101.7ms\n",
      "Speed: 2.0ms preprocess, 101.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4314.png\n",
      "Annotations: [(2, 0.15021352097392082, 0.8174269199371338, 0.09966597706079483, 0.11743581295013428), (2, 0.7391862273216248, 0.8223657011985779, 0.11261558532714844, 0.12426912784576416), (2, 0.6381151676177979, 0.7184406518936157, 0.11389780044555664, 0.16668438911437988), (2, 0.3038950562477112, 0.8035744726657867, 0.1637578010559082, 0.13347238302230835), (0, 0.26937370002269745, 0.11978594958782196, 0.3734561502933502, 0.23957189917564392), (0, 0.7269081175327301, 0.12481630221009254, 0.39437252283096313, 0.24753021448850632), (1, 0.24413026869297028, 0.4763650447130203, 0.3283214271068573, 0.5685146749019623), (1, 0.7221461534500122, 0.47651007771492004, 0.33462071418762207, 0.5715723633766174)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_61.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 84.1ms\n",
      "Speed: 1.9ms preprocess, 84.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_61.png\n",
      "Annotations: [(2, 0.40954290330410004, 0.8961831033229828, 0.13450035452842712, 0.1414673924446106), (2, 0.21600236743688583, 0.8351460695266724, 0.13812662661075592, 0.16311752796173096), (0, 0.39953143894672394, 0.12005379796028137, 0.668098658323288, 0.24010759592056274), (1, 0.36078354716300964, 0.4509023278951645, 0.4083481431007385, 0.7690980732440948)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_shorts_2689.png: 640x512 1 Topwear, 2 Footwears, 87.2ms\n",
      "Speed: 2.0ms preprocess, 87.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_shorts_2689.png\n",
      "Annotations: [(2, 0.4254001975059509, 0.96058589220047, 0.1071121096611023, 0.07882821559906006), (2, 0.16640577837824821, 0.9460362792015076, 0.14779631048440933, 0.1026383638381958), (1, 0.24965322017669678, 0.5255764871835709, 0.49930644035339355, 0.7267415225505829)]\n",
      "Detections: ['original_image', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_2925.png: 640x512 1 Topwear, 81.3ms\n",
      "Speed: 2.0ms preprocess, 81.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_2925.png\n",
      "Annotations: [(0, 0.29550956934690475, 0.45087718963623047, 0.3694755584001541, 0.6228362321853638)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camiseta-interior_5.png: 640x448 3 Topwears, 75.0ms\n",
      "Speed: 2.7ms preprocess, 75.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camiseta-interior_5.png\n",
      "Annotations: [(0, 0.1878812424838543, 0.6351202726364136, 0.27783624082803726, 0.35176801681518555)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas_530.png: 640x512 1 Topwear, 84.4ms\n",
      "Speed: 2.4ms preprocess, 84.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas_530.png\n",
      "Annotations: [(0, 0.4289257675409317, 0.5021286755800247, 0.5900227725505829, 0.6206847131252289)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_1608.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 96.7ms\n",
      "Speed: 2.1ms preprocess, 96.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_1608.png\n",
      "Annotations: [(2, 0.5091029703617096, 0.8747508525848389, 0.12148779630661011, 0.1423189640045166), (2, 0.4354194551706314, 0.7628749012947083, 0.15346595644950867, 0.13086211681365967), (1, 0.4951280951499939, 0.40043625235557556, 0.34081435203552246, 0.8008725047111511)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisetas_4071.png: 640x448 1 Topwear, 69.4ms\n",
      "Speed: 3.1ms preprocess, 69.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Processing dataset_camisetas_4071.png\n",
      "Annotations: [(0, 0.5, 0.6975904256105423, 1.0, 0.6048191487789154)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_zapatillas_1888.png: 640x512 1 Bottomwear, 2 Footwears, 81.6ms\n",
      "Speed: 1.9ms preprocess, 81.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_zapatillas_1888.png\n",
      "Annotations: [(2, 0.238642618060112, 0.6347455084323883, 0.477285236120224, 0.20849734544754028), (2, 0.5238184407353401, 0.7277740836143494, 0.6873848289251328, 0.2799680233001709), (1, 0.4791835732758045, 0.2899860739707947, 0.7392257079482079, 0.5799721479415894)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_846.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 80.8ms\n",
      "Speed: 1.9ms preprocess, 80.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_846.png\n",
      "Annotations: [(2, 0.41497068107128143, 0.9473130106925964, 0.09633174538612366, 0.08898270130157471), (2, 0.5203161984682083, 0.8651703596115112, 0.09893032908439636, 0.12322890758514404), (1, 0.4446932524442673, 0.679040253162384, 0.2653222382068634, 0.46264612674713135), (0, 0.4242958128452301, 0.31877341866493225, 0.410086452960968, 0.3857176899909973)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_pantalones_4972.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 84.0ms\n",
      "Speed: 2.0ms preprocess, 84.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_pantalones_4972.png\n",
      "Annotations: [(2, 0.5594550371170044, 0.9067769944667816, 0.09340691566467285, 0.10809606313705444), (2, 0.293477863073349, 0.8987837135791779, 0.09856271743774414, 0.11709040403366089), (0, 0.46368803083896637, 0.2510071098804474, 0.2544398009777069, 0.2084411382675171), (1, 0.4378155916929245, 0.5852032899856567, 0.3527858555316925, 0.49783480167388916)]\n",
      "Detections: ['original_image', 'bottomwear', 'footwear', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_trajes_1113.png: 640x512 1 Topwear, 1 Bottomwear, 2 Footwears, 76.3ms\n",
      "Speed: 1.9ms preprocess, 76.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_trajes_1113.png\n",
      "Annotations: [(2, 0.5941160619258881, 0.9023463726043701, 0.11525768041610718, 0.12869226932525635), (2, 0.4681232422590256, 0.7964271605014801, 0.13575831055641174, 0.19675666093826294), (1, 0.49215705692768097, 0.4926940053701401, 0.3744334876537323, 0.7339159548282623)]\n",
      "Detections: ['original_image', 'bottomwear', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_456.png: 640x480 1 Topwear, 78.5ms\n",
      "Speed: 1.8ms preprocess, 78.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processing dataset_vestidos_456.png\n",
      "Annotations: [(0, 0.4906453341245651, 0.47789060696959496, 0.5319109261035919, 0.7472721412777901)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sandalias_755.png: 640x512 2 Footwears, 103.6ms\n",
      "Speed: 2.0ms preprocess, 103.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_sandalias_755.png\n",
      "Annotations: [(2, 0.2728241663426161, 0.6319039463996887, 0.5111339129507542, 0.4695030450820923), (2, 0.6666847467422485, 0.636137530207634, 0.5231434106826782, 0.557232528924942)]\n",
      "Detections: ['original_image', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_camisas-y-blusas_3579.png: 640x512 1 Topwear, 80.1ms\n",
      "Speed: 1.7ms preprocess, 80.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_camisas-y-blusas_3579.png\n",
      "Annotations: [(0, 0.5070772767066956, 0.2671666443347931, 0.4906902313232422, 0.40447694063186646)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1424.png: 640x512 1 Topwear, 76.0ms\n",
      "Speed: 1.9ms preprocess, 76.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_1424.png\n",
      "Annotations: [(0, 0.2992795251775533, 0.4754602015018463, 0.5900515033863485, 0.7092130780220032)]\n",
      "Detections: ['original_image', 'topwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_vestidos_1576.png: 640x512 1 Topwear, 2 Footwears, 81.1ms\n",
      "Speed: 1.7ms preprocess, 81.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processing dataset_vestidos_1576.png\n",
      "Annotations: [(2, 0.5076861530542374, 0.9357095062732697, 0.10534664988517761, 0.1285809874534607), (2, 0.3985610455274582, 0.9010398089885712, 0.10516080260276794, 0.14511793851852417), (0, 0.50436732172966, 0.44450438022613525, 0.3201943039894104, 0.5952653884887695)]\n",
      "Detections: ['original_image', 'topwear', 'footwear']\n",
      "\n",
      "image 1/1 /Users/hanae/Desktop/Study/3. Third year/FinalProject/ecommerce_dataset/test/images/dataset_sudaderas_1473.png: 640x640 1 Topwear, 108.2ms\n",
      "Speed: 2.5ms preprocess, 108.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processing dataset_sudaderas_1473.png\n",
      "Annotations: [(0, 0.5010015964508057, 0.506134569644928, 0.701467752456665, 0.9047574996948242)]\n",
      "Detections: ['original_image', 'topwear']\n"
     ]
    }
   ],
   "source": [
    "# Test the model accuracy\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Initialize paths and model\n",
    "trained_model_path = 'best.pt'\n",
    "model = YOLO(trained_model_path)\n",
    "test_images_dir = 'ecommerce_dataset/test/images'\n",
    "test_annotations_dir = 'ecommerce_dataset/test/labels'\n",
    "\n",
    "# Sample half the images\n",
    "image_files = [f for f in os.listdir(test_images_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "random.seed(42)\n",
    "sampled_files = random.sample(image_files, len(image_files) // 6)\n",
    "\n",
    "# Functions to process images\n",
    "def extract_clothes(img_path: str):\n",
    "    image = cv2.imread(img_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = model(img_path, conf=0.3)\n",
    "    outputs = {\"original_image\": image_rgb}\n",
    "    category_scores = {'Topwear': 0, 'Bottomwear': 0, 'Footwear': 0}\n",
    "\n",
    "    for result in results:\n",
    "        for res in result.boxes:\n",
    "            category = result.names[int(res.cls[0])]\n",
    "            conf = res.conf[0]\n",
    "            xmin, ymin, xmax, ymax = map(int, res.xyxy[0])\n",
    "            if conf > category_scores[category]:\n",
    "                category_scores[category] = conf\n",
    "                outputs[category.lower()] = image_rgb[ymin:ymax, xmin:xmax]\n",
    "\n",
    "    return outputs\n",
    "\n",
    "def load_annotations(annotation_file):\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        annotations = []\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            class_id, x_center, y_center, width, height = map(float, parts)\n",
    "            annotations.append((int(class_id), x_center, y_center, width, height))\n",
    "    return annotations\n",
    "\n",
    "# Counters for accuracy\n",
    "correct_counts = {'topwear': 0, 'bottomwear': 0, 'footwear': 0}\n",
    "total_counts = {'topwear': 0, 'bottomwear': 0, 'footwear': 0}\n",
    "\n",
    "# Main loop to process images\n",
    "for file in sampled_files:\n",
    "    img_path = os.path.join(test_images_dir, file)\n",
    "    annotation_path = os.path.join(test_annotations_dir, os.path.splitext(file)[0] + '.txt')\n",
    "\n",
    "    if not os.path.exists(annotation_path):\n",
    "        print(f\"No annotation file for {file}\")\n",
    "        continue\n",
    "\n",
    "    annotations = load_annotations(annotation_path)\n",
    "    detections = extract_clothes(img_path)\n",
    "\n",
    "    print(f\"Processing {file}\")\n",
    "    print(\"Annotations:\", annotations)\n",
    "    print(\"Detections:\", list(detections.keys()))\n",
    "\n",
    "    for class_id, _, _, _, _ in annotations:\n",
    "        category = ['topwear', 'bottomwear', 'footwear'][class_id]\n",
    "        total_counts[category] += 1\n",
    "        if category in detections:\n",
    "            correct_counts[category] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf70cbe9-f9db-4e9b-92ed-3261ddf5b462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set for topwear: 99.48%\n",
      "Accuracy on the test set for bottomwear: 97.54%\n",
      "Accuracy on the test set for footwear: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display accuracy\n",
    "for category in total_counts:\n",
    "    if total_counts[category] > 0:\n",
    "        accuracy = (correct_counts[category] / total_counts[category]) * 100\n",
    "    else:\n",
    "        accuracy = 0\n",
    "    print(f\"Accuracy on the test set for {category}: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc21ba9-12de-41d8-b5f0-4b7a178cf060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
